<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
        content="MLG 2020, 16th International Workshop on Mining and Learning with Graphs, co-located with KDD 2020, San Diego, CA, USA">
    <meta name="author" content="Shobeir Fakhraei">

    <title>MLG 2020 - 16th International Workshop on Mining and Learning with Graphs</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/agency.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet'
        type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
        .tg {
            border-collapse: collapse;
            border-spacing: 0;
            width: 520px
        }

        .tg td {
            font-family: Arial, sans-serif;
            font-size: 14px;
            padding: 12px 12px;
            border-style: solid;
            border-width: 0px;
            overflow: hidden;
            word-break: normal;
            border-top-width: 1px;
            border-bottom-width: 1px;
        }

        .tg th {
            font-family: Arial, sans-serif;
            font-size: 14px;
            font-weight: normal;
            padding: 12px 12px;
            border-style: solid;
            border-width: 0px;
            overflow: hidden;
            word-break: normal;
            border-top-width: 1px;
            border-bottom-width: 1px;
        }

        .tg .tg-lqy6 {
            text-align: right;
            vertical-align: top;
            width: 100px
        }

        .tg .tg-odj0 {
            font-weight: bold;
            background-color: #ffcb2f;
            vertical-align: top
        }

        .tg .tg-yw4l {
            vertical-align: top
        }

        .tg .tg-l2oz {
            font-weight: bold;
            text-align: right;
            vertical-align: top
        }

        .tg .tg-9hbo {
            font-weight: bold;
            vertical-align: top
        }

        .tg .tg-xr8r {
            background-color: #ffffc7;
            text-align: right;
            vertical-align: top;
            width: 100px
        }

        .tg .tg-kjho {
            background-color: #ffffc7;
            vertical-align: top
        }
    </style>


</head>

<body id="page-top" class="index">
    <!-- Google Analytics -->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-75238067-1', 'auto');
        ga('require', 'linkid');
        ga('send', 'pageview');

    </script>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse"
                    data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top"><img src="img/mlg-logo.gif"
                        style="margin:0px; padding:0px; height:30px" /></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#introduction">Intro</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#program">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#keynote">Keynotes</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#papers">Accepted Papers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#call">CFP</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#organization">Organization</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#history">History</a>
                    </li>
                    <li>
                        <a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter"
                                style="font-size:20px;"></i></a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="intro-text">
                <div class="intro-lead-in">Held in conjunction with <a href="http://www.kdd.org/kdd2020/"
                        target=_blank>KDD'20</a></br>
                    Aug 24, 2020 - Virtual</div>
                <div class="intro-heading">16th International Workshop on<br />Mining and Learning with Graphs</div>
                <a href="#program" target=_blank class="page-scroll btn btn-xl">Schedule</a>
            </div>
        </div>
    </header>

    <!-- Introduction Section -->
    <section id="introduction">
        <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-8 text-center">
                    <h2 class="section-heading">Introduction</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">

                <div class="row text-justify">

                    <div class="col-md-8">
                        <p class="large text-muted">
                            There is a great deal of interest in analyzing data that is best represented as a graph.
                            Examples include the WWW, social networks, biological networks, communication networks,
                            transportation networks, energy grids, and many others. These graphs are typically
                            multi-modal, multi-relational and dynamic. In the era of big data, the importance of being
                            able to effectively mine and learn from such data is growing, as more and more structured
                            and semi-structured data is becoming available. The workshop serves as a forum for
                            researchers from a variety of fields working on mining and learning from graphs to share and
                            discuss their latest findings.
                            <br />
                            There are many challenges involved in effectively mining and learning from this kind of
                            data, including:
                        </p>
                        <ul class="large text-muted">
                            <li>Understanding the different techniques applicable, including graph mining algorithms,
                                network embeddings, graphical models, latent variable models, matrix factorization
                                methods and more.</li>
                            <li>Dealing with the heterogeneity of the data.</li>
                            <li>The common need for information integration and alignment.</li>
                            <li>Handling dynamic and changing data.</li>
                            <li>Addressing each of these issues at scale.</li>
                        </ul>
                        <p class="large text-muted">
                            Traditionally, a number of subareas have contributed to this space: communities in graph
                            mining, learning from structured data, statistical relational learning, inductive logic
                            programming, and, moving beyond subdisciplines in computer science, social network analysis,
                            and, more broadly network science.
                        </p>
                    </div>


                    <div class="col-md-4 text-right">
                        <p class="large text-muted">
                            <a href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw" class="twitter-follow-button"
                                data-show-count="false">Follow @mlgworkshop</a>
                            <a class="twitter-timeline" data-lang="en" data-height="600"
                                data-chrome="nofooter; noheader; transparent" data-link-color="#FAB81E"
                                href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw"></a>
                            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                        </p>
                    </div>

                </div>
            </div>
    </section>

    <!-- Program Section -->
    <section id="program" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Schedule</h2>
                    <h3 class="section-subheading text-muted"><strong>Virtual (All times are <a
                                href='https://time.is/PT' target=_blank>Pacific Time</a>)</strong>
                                <br /><br />
                        All accepted papers will be presented in the poster session.<br />
                        Based on scheduling constraints, some papers are selected as contributed talks or spotlight
                        presentations.<br />
                        -Held jointly with <a href='https://deep-learning-graphs.bitbucket.io/dlg-kdd20/'
                            target=_blank>International Workshop on Deep Learning on Graphs (KDD-DLG)</a>-
                    </h3>
                </div>
            </div>

            <div class="row">
                <div class="col-lg-6 text-left">
                    <table class="tg">
                        <tr>
                            <th class="tg-odj0"></th>
                            <th class="tg-odj0">Morning Sessions</th>
                        </tr>
                        <tr>
                            <th class="tg-lqy6">8:00 am</th>
                            <th class="tg-yw4l">
                                Opening Remarks</th>
                        </tr>
                        <tr>
                            <td class="tg-l2oz">8:15 am<br />
                                <img src="img/speakers/jure.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">

                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Jure Leskovec<br />
                                Graph Structure of Neural Networks: Good Neural Networks Are Alike
                                <!--a href="https://deep-learning-graphs.bitbucket.io/dlg-kdd20/keynote_slides/Jure-Leskovec-kdd20.pdf" target=_blank class="btn btn-primary btn-xs" role="button">Slides</a-->
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Video</a-->
                            </td>
                        </tr>
                        <tr>
                            <td class="tg-l2oz">8:45 am<br />
                                <img src="img/speakers/philip.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Philip Yu<br />
                                Broad Learning Via Heterogenous Information Networks
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Slides</a-->
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Video</a-->
                            </td>
                        </tr>

                        <tr>
                            <td class="tg-lqy6">9:15 am</td>
                            <td class="tg-yw4l">Parallel Contributed Talks</br><br/>
                                Junchen Jin<br/>  
                                Understanding and Evaluating Structural Node Embeddings<br/><br/>
                                Caleb Belth<br/>
                                Mining Persistent Activity in Continually Evolving Networks
                                <br />
                        </tr>

                        <tr>
                            <td class="tg-l2oz">9:45 am<br />
                                <img src="img/speakers/fei_wang.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Fei Wang<br />
                                Deep Graph Mining for Healthcare
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Slides</a-->
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Video</a-->
                            </td>
                        </tr>

                        <tr>
                            <td class="tg-xr8r">10:15 am</td>
                            <td class="tg-kjho">Coffee Break/Social Networking</td>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">10:30 am<br />
                                <img src="img/speakers/danai.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Danai Koutra<br />
                                The Power of Summarization in Network Analysis<br/>
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Slides</a-->
                                <a href="https://youtu.be/2EZmLBoMLMM" target=_blank class="btn btn-primary btn-xs" role="button">Video</a>
                            </td>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">11:00 am<br />
                                <img src="img/speakers/petar.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Petar Veličković<br />
                                Algorithmic Inductive Biases
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Slides</a-->
                                <!--a href="#" target=_blank class="btn btn-primary btn-xs" role="button">Video</a-->
                            </td>
                        </tr>

                        <tr style="background-color:#ffffff">
                            <td class="tg-lqy6">11:30 am</td>
                            <td class="tg-yw4l">
                                Parallel Poster Session (Spotlight Talks + Live Q/A) <br />Breakout Z-rooms for both DLG
                                and MLG
                                <!--a target=_blank href='slides/mlg_spotlight_talks.pdf'>[slides]</a!-->
                            </td>
                        </tr>

                        </tr>
                        <td class="tg-xr8r">12:00 pm</td>
                        <td class="tg-kjho">Lunch Break<br /></td>
                        </tr>

                    </table>


                </div>
                <div class="col-lg-6 text-left">
                    <table class="tg">
                        <tr>
                            <th class="tg-odj0"></th>
                            <th class="tg-odj0">Afternoon Sessions</th>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">1:00 pm<br />
                                <img src="img/speakers/jimeng_sun.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Jimeng Sun<br />
                                Deep Learning for Drug Development</td>
                        </tr>

                        <tr>
                            <td class="tg-lqy6">1:30 pm</td>
                            <td class="tg-yw4l">Parallel Contributed Talks<br/><br/>
                                William Shiao<br/>
                                BRGAN: Generating Graphs of Bounded Rank<br/><br/>
                                Christopher Tran<br/>
                                Heterogeneous Threshold Estimation for Linear Threshold Modeling
                                <br />
                        </tr>

                        <tr>
                            <td class="tg-l2oz">2:00 pm<br />
                                <img src="img/speakers/tyler.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Tyler Derr<br />
                                Self-supervised Learning on Graphs: Deep Insights and New Directions</td>
                        </tr>

                        <tr>
                            <td class="tg-xr8r">2:30 pm</td>
                            <td class="tg-kjho">Coffee Break/Social Networking</td>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">2:45 pm<br />
                                <img src="img/speakers/muhan.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Muhan Zhang<br />
                                Learning Graph Strcuture Features for Inductive Link Prediction and Matrix Completion
                            </td>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">3:15 pm<br />
                                <img src="img/speakers/le_song.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;">
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Le Song<br />
                                Cybersecurity with Graph Neural Networks
                            </td>
                        </tr>

                        <tr>
                            <td class="tg-lqy6">3:45 pm</td>
                            <td class="tg-yw4l">
                                Best Paper Award Ceremony + Closing Remarks
                            </td>
                        </tr>

                        <tr style="background-color:#ffffff">
                            <td class="tg-lqy6">4:00 pm</td>
                            <td class="tg-yw4l">
                                Parallel Poster Session (Spotlight Talks + Live Q/A) <br />Breakout Z-rooms for both DLG
                                and MLG
                            </td>
                        </tr>
                    </table>
                </div>

                <div class="col-lg-3 text-left">
                    &nbsp;
                </div>
            </div>

        </div>
    </section>

    <!-- Keynote Section no abstract -->

    <section id="keynote" class="bg-mid">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Keynote Speakers</h2>
                    <h3 class="section-subheading text-muted">Jointly with the International Workshop on Deep Learning
                        on Graphs (KDD-DLG)</h3>
                </div>
            </div>
            <div class="row">

                <div class="col-md-1">
                    &nbsp;
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/danai.jpg" class="img-responsive img-circle" alt="Danai Koutra">
                        <h4>Danai Koutra</h4>
                        <p class="text-muted">University of Michigan Ann Arbor</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/jure.jpg" class="img-responsive img-circle" alt="Jure Leskovec">
                        <h4>Jure Leskovec</h4>
                        <p class="text-muted">Stanford University</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/fei_wang.jpg" class="img-responsive img-circle" alt="Fei Wang">
                        <h4>Fei Wang</h4>
                        <p class="text-muted">Cornell University</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/philip.jpg" class="img-responsive img-circle" alt="Philip Yu">
                        <h4>Philip Yu</h4>
                        <p class="text-muted">University of Illinois at Chicago</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/le_song.jpg" class="img-responsive img-circle" alt="Le Song">
                        <h4>Le Song</h4>
                        <p class="text-muted">Georgia Institute of Technology</p>
                    </div>
                </div>                

                <div class="col-md-1">
                    &nbsp;
                </div>

            </div>
            <div class="row">

                <div class="col-md-1">
                    &nbsp;
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/jimeng_sun.jpg" class="img-responsive img-circle" alt="Jimeng Sun">
                        <h4>Jimeng Sun</h4>
                        <p class="text-muted">University of Illinois Urbana-Champaign</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/petar.jpg" class="img-responsive img-circle" alt="Petar Velickovic">
                        <h4>Petar Velickovic</h4>
                        <p class="text-muted">Deepmind</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/muhan.jpg" class="img-responsive img-circle" alt="Muhan Zhang">
                        <h4>Muhan Zhang</h4>
                        <p class="text-muted">Facebook AI</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/tyler.jpg" class="img-responsive img-circle" alt="Tyler Derr">
                        <h4>Tyler Derr</h4>
                        <p class="text-muted">Vanderbilt University</p>
                    </div>
                </div>

                <div class="col-md-1">
                    &nbsp;
                </div>

            </div>

            <!--div class="row">

                <div class="col-md-2">
                    &nbsp;
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/jiliang.jpg" class="img-responsive img-circle" alt="Jiliang Tang">
                        <h4>Jiliang Tang</h4>
                        <p class="text-muted">Michigan State University</p>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/jian.jpg" class="img-responsive img-circle" alt="Jian Tang">
                        <h4>Jian Tang</h4>
                        <p class="text-muted">Mila-Quebec AI Institute</p>
                    </div>
                </div>



                <div class="col-md-8">
                    &nbsp;
                </div>

            </div-->

        </div>
    </section>

    <!-- Accepted Papers Section -->
    <section id="papers" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Accepted Papers</h2>
                    <!--h3 class="section-subheading text-muted">
                    All accepted papers will present a poster
                    </h3-->
                </div>
            </div>
            <div class="row">

                <div class="col-lg-1 text-center">
                    &nbsp;
                </div>

                <div class="col-lg-11 text-justify">
                    <!-- Begin Paper List -->

                    <p class="large text-muted">
                        <strong>A Scalable Parallel Hypergraph Generator (HyGen)</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid5">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib5">BibTex</button>
                        <a href="papers/MLG2020_paper_5.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=5ipeJJcAcCc" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>S.M.Shamimul Hasan, Neena Imam and Ramakrishnan Kannan</i><br />

                    <div id="pid5" class="collapse">
                        <strong>Abstract:</strong> Graphs are extensively used to model real-world complex systems. An
                        edge in a graph can model pairwise relationships. However, multiway relationships (connections
                        between three or more vertices) are common in many complex systems such as cellular process,
                        image segmentation, and circuit design. A graph edge cannot model multiway relationships. A
                        hypergraph, which can connect more than two vertices, is thus a better option to model multiway
                        relationships. A large-scale hypergraph analysis has the potential to find useful insights from
                        a complex system and assist in knowledge discovery. Currently a limited number of hypergraphs
                        exists that are representative of real-world datasets. Moreover, real-world hypergraph datasets
                        are small in size and inadequate to incorporate future needs. A graph generator that can produce
                        large-scale synthetic hypergraphs can solve the above mentioned problems. In this paper, we
                        present a scalable parallel hypergraph generator (HyGen) based on the Message Passing Interface
                        (MPI) standard. To generate hypergraphs, HyGen takes the following parameter values as inputs:
                        i) number of vertices, ii) number of hyperedges, iii) number of clusters, iv) vertex
                        distribution, v) hyperedge distribution, vi) local cluster cardinality, and vii) global cluster
                        cardinality. We have demonstrated that HyGen can generate hypergraphs of various sizes in a
                        scalable fashion. HyGen takes approximately four minutes to generate a hypergraph with 4.8
                        million vertices, 1.6 million hyperedges, and 800 clusters using 1,024 processes on a leadership
                        class computing platform. Our strong and weak scaling experiments on supercomputers demonstrate
                        that HyGen can quickly create large-scale hypergraphs in a parallel manner, thus providing a
                        useful capability for hypergraph analysis.
                        <br /><br /><strong>Keywords:</strong> Hypergraph, MPI, C++, OLCF, Rhea
                        <hr />
                    </div>

                    <div id="bib5" class="collapse">
                        @inproceedings{mlg2020_5,<br />
                        title={A Scalable Parallel Hypergraph Generator (HyGen)},<br />
                        author={S.M.Shamimul Hasan, Neena Imam and Ramakrishnan Kannan},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Active Learning on Graphs with Geodesically Convex Classes</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid40">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib40">BibTex</button>
                        <a href="papers/MLG2020_paper_40.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=MsxJT2cP8yg" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Maximilian Thiessen and Thomas Gärtner</i><br />

                    <div id="pid40" class="collapse">
                        <strong>Abstract:</strong> We study the problem of actively learning the vertex labels of a
                        graph, assuming the classes form geodesically convex subgraphs, which is related to linear
                        separability in the Euclidean setting. The main result of this paper is a novel query-efficient
                        active learning algorithm with label-independent upper bounds on the number of queries needed to
                        learn all labels. For that, we use shortest path covers and provide a logarithmic approximation
                        for the subproblem of computing a shortest path cover of minimum size. We extend the approach to
                        arbitrarily labeled graphs using a convexity-based selection criterion. Finally, we discuss
                        whether the convexity assumption holds on real-world data and give some first preliminary
                        results on citation and image benchmark datasets.
                        <br /><br /><strong>Keywords:</strong> active learning, graphs, geodesic convexity, node
                        classification, multi-class, path cover
                        <hr />
                    </div>

                    <div id="bib40" class="collapse">
                        @inproceedings{mlg2020_40,<br />
                        title={Active Learning on Graphs with Geodesically Convex Classes},<br />
                        author={Maximilian Thiessen and Thomas Gärtner},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Adaptive Granularity in Time Evolving Graphs as Tensors</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid35">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib35">BibTex</button>
                        <a href="papers/MLG2020_paper_35.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=gKAFQeO4Mtg" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Ravdeep Pasricha, Ekta Gujral and Evangelos Papalexakis</i><br />

                    <div id="pid35" class="collapse">
                        <strong>Abstract:</strong> Data collected at very frequent intervals is usually extremely sparse
                        and has no structure that is exploitable by modern tensor decomposition algorithms. Thus the
                        utility of such tensors is low, in terms of the amount of interpretable and exploitable
                        structure that one can extract from them. In this paper, we introduce the problem of finding a
                        tensor of adaptive aggregated granularity that can be decomposed to reveal meaningful latent
                        concepts (structures) from datasets that, in their original form, are not amenable to tensor
                        analysis. Such datasets fall under the broad category of sparse point processes that evolve over
                        space and/or time. To the best of our knowledge, this is the first work that explores adaptive
                        granularity aggregation in tensors. Furthermore, we formally define the problem and discuss what
                        different definitions of “good structure” can be in practice, and show that optimal solution is
                        of prohibitive combinatorial complexity. Subsequently, we propose an efficient and effective
                        greedy algorithm which follows a number of intuitive decision criteria that locally maximize the
                        “goodness of structure”, resulting in high-quality tensors. We evaluate our method on synthetic
                        and semi-synthetic data where ground truth is known. Our proposed method constructs tensors that
                        have very high structure quality.
                        <br /><br /><strong>Keywords:</strong> Tensor analysis, unsupervised learning, time-evolving
                        graphs
                        <hr />
                    </div>

                    <div id="bib35" class="collapse">
                        @inproceedings{mlg2020_35,<br />
                        title={Adaptive Granularity in Time Evolving Graphs as Tensors},<br />
                        author={Ravdeep Pasricha, Ekta Gujral and Evangelos Papalexakis},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Adversarial Learning for Debiasing Knowledge Graph Embeddings</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid39">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib39">BibTex</button>
                        <a href="papers/MLG2020_paper_39.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=a5fFOKc5os8" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Mario Arduini, Lorenzo Noci, Federico Pirovano, Ce Zhang, Yash Raj Shrestha and Bibek
                            Paudel</i><br />

                    <div id="pid39" class="collapse">
                        <strong>Abstract:</strong> Knowledge Graphs (KG) are gaining increasing attention in both
                        academia and industry. Despite their diverse benefits, recent research have identified social
                        and cultural biases embedded in the representations learned from KGs.
                        Such biases can have detrimental consequences on different population and minority groups as
                        applications of KG begin to intersect and interact with social spheres.
                        This paper describes our work-in-progress, which aims at identifying and mitigating such biases
                        in Knowledge Graph (KG) embeddings.
                        As a first step, we explore popularity bias --- the relationship between node popularity and
                        link prediction accuracy.
                        In case of node2vec graph embeddings, we find that prediction accuracy of the embedding is
                        negatively correlated with the degree of the node.
                        However, in case of knowledge-graph embeddings (KGE), we observe an opposite trend.
                        As a second step, we explore gender bias in KGE, and a careful examination of popular KGE
                        algorithms suggest that sensitive attribute like the gender of a person can be predicted from
                        the embedding.
                        This implies that such biases in popular KGs is captured by the structural properties of the
                        embedding.
                        As a preliminary solution to debiasing KGs, we introduce a novel framework to filter out the
                        sensitive attribute information from the KG embeddings, which we call FAN (Filtering Adversarial
                        Network).
                        We also suggest the applicability of FAN for debiasing other network embeddings which could be
                        explored in future work.
                        <br /><br /><strong>Keywords:</strong> knowledge graph embedding, network embedding, adversarial
                        network, bias in machine learning
                        <hr />
                    </div>

                    <div id="bib39" class="collapse">
                        @inproceedings{mlg2020_39,<br />
                        title={Adversarial Learning for Debiasing Knowledge Graph Embeddings},<br />
                        author={Mario Arduini, Lorenzo Noci, Federico Pirovano, Ce Zhang, Yash Raj Shrestha and Bibek
                        Paudel},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>BRGAN: Generating Graphs of Bounded Rank</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid3">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib3">BibTex</button>
                        <a href="papers/MLG2020_paper_3.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=PXcd2VKPNbA" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>William Shiao and Evangelos Papalexakis</i><br />

                    <div id="pid3" class="collapse">
                        <strong>Abstract:</strong> Graph generation is a task that has been explored with a wide variety
                        of methods. Recently, several papers have applied Generative Adversarial Networks (GANs) to this
                        task, but most of these methods result in graphs of full or unknown rank. Many real-world graphs
                        have low rank, which roughly translates to the number of communities in that graph. Furthermore,
                        it has been shown that taking the low rank approximation of a graph can defend against
                        adversarial attacks. This suggests that testing models against graphs of different rank may be
                        useful.

                        However, current methods provide no way to control the rank of generated graphs. In this paper,
                        we propose BRGAN: a GAN architecture that generates synthetic graphs, which in addition to
                        having realistic graph features, also have bounded (low) rank. We extensively evaluate BRGAN and
                        show that it is able to generate synthetic graphs competitive with state-of-the-art models, with
                        rank equal to or lower than the desired rank.
                        <br /><br /><strong>Keywords:</strong> graph generation, generative adversarial networks, graph
                        rank
                        <hr />
                    </div>

                    <div id="bib3" class="collapse">
                        @inproceedings{mlg2020_3,<br />
                        title={BRGAN: Generating Graphs of Bounded Rank},<br />
                        author={William Shiao and Evangelos Papalexakis},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>CONE-Align: Consistent Network Alignment with Proximity-Preserving Node
                            Embedding</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid4">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib4">BibTex</button>
                        <a href="papers/MLG2020_paper_4.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=27I2fCRSWu0" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Xiyuan Chen, Mark Heimann, Fatemeh Vahedian and Danai Koutra</i><br />

                    <div id="pid4" class="collapse">
                        <strong>Abstract:</strong> Network alignment, the process of finding correspondences between
                        nodes in different graphs, has many scientific and industrial applications. Existing
                        unsupervised network alignment methods find suboptimal alignments that break up node
                        neighborhoods, i.e. do not preserve matched neighborhood consistency. To improve this, we
                        propose CONE-Align, which models intra-network proximity with node embeddings and matches nodes
                        across networks by comparing the embeddings after aligning their subspaces. Experiments on
                        diverse, challenging datasets show that CONE-Align is robust and obtains up to 49% greater
                        accuracy than the state-of-the-art graph alignment algorithms.
                        <br /><br /><strong>Keywords:</strong> network alignment, graph mining, node embeddings,
                        neighborhood consistency
                        <hr />
                    </div>

                    <div id="bib4" class="collapse">
                        @inproceedings{mlg2020_4,<br />
                        title={CONE-Align: Consistent Network Alignment with Proximity-Preserving Node Embedding},<br />
                        author={Xiyuan Chen, Mark Heimann, Fatemeh Vahedian and Danai Koutra},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Characterising the atomic structure of mono-metallic nanoparticles from x-ray scattering
                            data using conditional generative models</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid22">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib22">BibTex</button>
                        <a href="papers/MLG2020_paper_22.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=t3SsWfy6DF0" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Andy S. Anker, Emil T. S. Kjær, Erik B. Dam, Simon J. L. Billinge, Kirsten M. Ø. Jensen and
                            Raghavendra Selvan</i><br />

                    <div id="pid22" class="collapse">
                        <strong>Abstract:</strong> The development of new nanomaterials for energy technologies is
                        dependent on understanding the intricate relation between material properties and atomic
                        structure. It is, therefore, crucial to be able to routinely characterise the atomic structure
                        in nanomaterials, and a promising method for this task is Pair Distribution Function (PDF)
                        analysis. The PDF can be obtained through Fourier transformation of x-ray total scattering data,
                        and represents a histogram of all interatomic distances in the sample. Going from the distance
                        information in the PDF to a chemical structure is an unassigned distance geometry problem
                        (uDGP), and solving this is often the bottleneck in nanostructure analysis. In this work, we
                        propose to use a Conditional Variational Autoencoder (CVAE) to automatically solve the uDGP to
                        obtain valid chemical structures from PDFs. We use a simple model system of hypothetical
                        mono-metallic nanoparticles containing up to 100 atoms in the face centered cubic (FCC)
                        structure as a proof of concept. The model is trained to predict the assigned distance matrix
                        (aDM) from a simulated PDF of the structure as the conditional input. We introduce a novel
                        representation of structures by projecting them inside a unit sphere and adding additional
                        anchor points or satellites to help in the reconstruction of the chemical structure. The
                        performance of the CVAE model is compared to a Deterministic Autoencoder (DAE) showing that both
                        models are able to solve the uDGP reasonably well. We further show that the CVAE learns a
                        structured and meaningful latent embedding space which can be used to predict new chemical
                        structures.
                        <br /><br /><strong>Keywords:</strong> generative modeling, mono-metallic nanoparticles, CVAE,
                        Pair Distribution Function
                        <hr />
                    </div>

                    <div id="bib22" class="collapse">
                        @inproceedings{mlg2020_22,<br />
                        title={Characterising the atomic structure of mono-metallic nanoparticles from x-ray scattering
                        data using conditional generative models},<br />
                        author={Andy S. Anker, Emil T. S. Kjær, Erik B. Dam, Simon J. L. Billinge, Kirsten M. Ø. Jensen
                        and Raghavendra Selvan},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Collective Bio-Entity Recognition in Scientific Documents using Hinge-Loss Markov Random
                            Fields</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid28">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib28">BibTex</button>
                        <a href="papers/MLG2020_paper_28.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=u1VWK70BlbY" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Alexander Miller, Naum Markenzon, Varun Embar and Lise Getoor</i><br />

                    <div id="pid28" class="collapse">
                        <strong>Abstract:</strong> Identifying biological entities such as genes and proteins from
                        scientific documents is crucial for further downstream tasks such as question answering and
                        information retrieval. This task is challenging because the same surface text can refer either
                        to a gene or a protein based on the context. Traditional approaches such as Huang et al.
                        consider the words present in the surrounding text to infer the context. However, they fail to
                        consider the semantics of these words which are better represented by contextual word embeddings
                        such as BERT. Deep learning based approaches, on the other hand, fail to make use of the
                        relational structure of scientific documents. We introduce a novel probabilistic approach that
                        jointly classifies all entity references using a class of undirected graphical models called
                        hinge-loss Markov random fields. Our approach can combine relational information with
                        embedding-based word semantics. Further, our approach can be easily extended to incorporate new
                        sources of information. Our initial evaluation on the JNLPBA shared task corpus shows that our
                        joint classification approach outperforms both traditional machine learning approaches and
                        semantic models based on word embeddings by up to 7.5% on F1 score.
                        <br /><br /><strong>Keywords:</strong> probabilistic graphical models, embeddings, information
                        extraction, word sense disambiguation, graphs, collective inference
                        <hr />
                    </div>

                    <div id="bib28" class="collapse">
                        @inproceedings{mlg2020_28,<br />
                        title={Collective Bio-Entity Recognition in Scientific Documents using Hinge-Loss Markov Random
                        Fields},<br />
                        author={Alexander Miller, Naum Markenzon, Varun Embar and Lise Getoor},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Comparison of Graph Generation Models focusing on Accuracy and Variation</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid2">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib2">BibTex</button>
                        <a href="papers/MLG2020_paper_2.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=sP_xFH0b9Oo" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Mei Fukuda, Kazuki Nakajima and Kazuyuki Shudo</i><br />

                    <div id="pid2" class="collapse">
                        <strong>Abstract:</strong> Generation models of graphs have been used to compare and analyze the
                        properties of graph structures and to produce graphs that resemble real-world networks. When
                        using a generation model to mimic a real-world network, it is desirable for the error in the
                        properties between the target graph and the generated graph and the variation of the errors
                        between generated graphs are small. However, since many existing generation models generate
                        graphs by adding edges at random, the extent of the error and its variation for each generated
                        graph is unclear.
                        This paper studies the error and the variation of properties of graphs generated using the
                        dK-series framework, which has been proposed to analyze the topology of a network based on the
                        degree of nodes. In addition, we propose a new graph generation model that takes the degree
                        distribution and degree-dependent clustering coefficient as inputs. We show that the proposed
                        model is able to reduce the error to a greater extent than other generation models.
                        <br /><br /><strong>Keywords:</strong> network analysis, graph generation models, estimation,
                        sampling, social networks
                        <hr />
                    </div>

                    <div id="bib2" class="collapse">
                        @inproceedings{mlg2020_2,<br />
                        title={Comparison of Graph Generation Models focusing on Accuracy and Variation},<br />
                        author={Mei Fukuda, Kazuki Nakajima and Kazuyuki Shudo},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Decoupled Smoothing in Probabilistic Soft Logic</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid31">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib31">BibTex</button>
                        <a href="papers/MLG2020_paper_31.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=icXAvFtF_dE" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Yatong Chen, Bryan Tor, Eriq Augustine and Lise Getoor</i><br />

                    <div id="pid31" class="collapse">
                        <strong>Abstract:</strong> Node classification in networks is a common graph mining task. In
                        this paper, we examine how separating identity(a node’s attribute)and preference(the kind of
                        identities to which a node prefers to link)is useful for node classification in social networks.
                        Building upon recent work by Chin et al., where the separation of identity and preference is
                        accomplished through a technique called “decoupled smoothing”, we show how models that
                        characterize both identity and preference are able to capture the underlying structure in a
                        network, which leads to performance improvement in node classification tasks. Specifically, we
                        use probabilistic soft logic (PSL), a flexible and declarative statistical reasoning framework,
                        to model identity and preference. We compare our method with the original decoupled smoothing
                        method and other node classification methods implemented in PSL, and show that our approach
                        outperforms the state-of-the-art decoupled smoothing method as well as the other node
                        classification methods across all evaluation metrics on a real-world Facebook Dataset.
                        <br /><br /><strong>Keywords:</strong> Node Classification, Social Network Analysis, Decoupled
                        Smoothing, Statistical Relational Learning
                        <hr />
                    </div>

                    <div id="bib31" class="collapse">
                        @inproceedings{mlg2020_31,<br />
                        title={Decoupled Smoothing in Probabilistic Soft Logic},<br />
                        author={Yatong Chen, Bryan Tor, Eriq Augustine and Lise Getoor},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Effectiveness of Sampling Strategies for One-shot Active Learning from Relational
                            Data</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid30">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib30">BibTex</button>
                        <a href="papers/MLG2020_paper_30.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=_XeHurAjVOs" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Ragib Ahsan and Elena Zheleva</i><br />

                    <div id="pid30" class="collapse">
                        <strong>Abstract:</strong> Relational classification exploits structural information in network
                        data to improve predictive performance. However, the large size of real-world networks causes
                        two main scalability issues for relational classification. First, training supervised models on
                        large networks is computationally expensive. Second, label acquisition for large samples can be
                        costly and unrealistic. The goal of Active learning is to query informative labels and reduce
                        labeling cost. However, state-of-the-art active learning strategies require multiple iterations
                        of learning, in order to pick the best labels at each iteration, which incurs higher
                        computational cost. In this work, we focus on a constrained version of the problem, named
                        one-shot active learning where the active learner has to decide which nodes to sample in one
                        shot, rather than iteratively. We consider several simple and network-based sampling strategies
                        as potential solutions to this problem. In our experiments, we show a comprehensive evaluation
                        of eleven different sampling methods on four real world network datasets using four relational
                        classifiers (wvRN, ICA, SGC, GraphSage), offering the first comparison between collective
                        classification and neural network approaches for one-shot active learning. Moreover, we propose
                        a novel sampling method based on Weisfeiler-Lehman graph labeling algorithm which shows overall
                        best performance across all classifiers and datasets. We empirically show that some of the
                        computationally cheaper one-shot active learning approaches can achieve comparable Micro-F1
                        scores to existing active learning methods that require multiple iterations.
                        <br /><br /><strong>Keywords:</strong> Graph sampling, Active learning, Relational
                        classification
                        <hr />
                    </div>

                    <div id="bib30" class="collapse">
                        @inproceedings{mlg2020_30,<br />
                        title={Effectiveness of Sampling Strategies for One-shot Active Learning from Relational
                        Data},<br />
                        author={Ragib Ahsan and Elena Zheleva},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Efficient Algorithms to Mine Maximal Span-Trusses From Temporal Graphs</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid11">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib11">BibTex</button>
                        <a href="papers/MLG2020_paper_11.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=GoMzFp_-ilU" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Quintino Francesco Lotito and Alberto Montresor</i><br />

                    <div id="pid11" class="collapse">
                        <strong>Abstract:</strong> Over the last decade, there has been an increasing interest in
                        temporal graphs, pushed by a growing availability of temporally-annotated network data coming
                        from social, biological and financial networks.
                        Despite the importance of analyzing complex temporal networks, there is a huge gap between the
                        set of definitions, algorithms and tools available to study large static graphs and the ones
                        available for temporal graphs.
                        An important task in temporal graph analysis is mining dense structures, i.e., identifying
                        high-density subgraphs together with the span in which this high density is observed.
                        In this paper, we introduce the concept of (k, \Delta)-truss (span-truss) in temporal graphs, a
                        temporal generalization of the k-truss, in which k captures the information about the density
                        and \Delta captures the time span in which this density holds. We then propose novel and
                        efficient algorithms to identify maximal span-trusses, namely the ones not dominated by any
                        other span-truss neither in the order k nor in the interval \Delta, and evaluate them on a
                        number of public available datasets.
                        <br /><br /><strong>Keywords:</strong> temporal graphs, graph mining, dense structures,
                        community detection, social networks analysis
                        <hr />
                    </div>

                    <div id="bib11" class="collapse">
                        @inproceedings{mlg2020_11,<br />
                        title={Efficient Algorithms to Mine Maximal Span-Trusses From Temporal Graphs},<br />
                        author={Quintino Francesco Lotito and Alberto Montresor},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Examining COVID-19 Forecasting using Spatio-Temporal GNNs</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid26">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib26">BibTex</button>
                        <a href="papers/MLG2020_paper_26.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=phYf15A5A50" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Amol Kapoor, Xue Ben, Luyang Liu, Bryan Perozzi, Matt Barnes, Martin Blais and Shawn
                            O'Banion</i><br />

                    <div id="pid26" class="collapse">
                        <strong>Abstract:</strong> In this work, we examine a novel forecasting approach for COVID-19
                        that uses Graph Neural Networks and mobility data. In contrast to existing time series
                        forecasting models, the proposed approach learns from a single large-scale spatio-temporal
                        graph, where nodes represent the region-level human mobility, spatial edges represent the human
                        mobility based inter-region connectivity, and temporal edges represent node features through
                        time. We evaluate initial experiments on the US county level COVID-19 dataset, and show that the
                        rich spatial and temporal information unified by the graph neural network allows the model to
                        learn complex dynamics and make more accurate forecasts compared to autoregressive statistical
                        learning and sequence deep learning approaches. We believe this novel source of information
                        combined with graph based deep learning approaches can be a powerful tool to understand the
                        spread and evolution of COVID-19. We encourage others to further develop a novel modeling
                        paradigm for infectious disease based on this high resolution mobility data.

                        <br /><br /><strong>Keywords:</strong> machine learning, graph learning, covid-19
                        <hr />
                    </div>

                    <div id="bib26" class="collapse">
                        @inproceedings{mlg2020_26,<br />
                        title={Examining COVID-19 Forecasting using Spatio-Temporal GNNs},<br />
                        author={Amol Kapoor, Xue Ben, Luyang Liu, Bryan Perozzi, Matt Barnes, Martin Blais and Shawn
                        O'Banion},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>First and Higher-Order Bipartite Embeddings</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid15">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib15">BibTex</button>
                        <a href="papers/MLG2020_paper_15.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=_lXLnlNDWfI" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Justin Sybrandt and Ilya Safro</i><br />

                    <div id="pid15" class="collapse">
                        <strong>Abstract:</strong> Typical graph embeddings may not capture type-specific bipartite
                        graph features that arise in such areas as recommender systems, data visualization, and drug
                        discovery. Machine learning methods utilized in these applications would be better served with
                        specialized embedding techniques. We propose two embeddings for bipartite graphs that decompose
                        edges into sets of indirect relationships between node neighborhoods. When sampling higher-order
                        relationships, we reinforce similarities through algebraic distance on graphs. We also introduce
                        ensemble embeddings to combine both into a "best of both worlds" embedding. The proposed methods
                        are evaluated on link prediction and recommendation tasks and compared with other
                        state-of-the-art embeddings. Our embeddings are found to perform better on recommendation tasks
                        and equally competitive in link prediction. Although all considered embeddings are beneficial in
                        particular applications, we demonstrate that none of those considered is clearly superior (in
                        contrast to what is claimed in many papers). Therefore, we discuss the trade offs among them,
                        noting that the methods proposed here are robust for applications relying on same-typed
                        comparisons.

                        Reproducibility: Our code, data sets, and results are all publicly available online at:
                        sybrandt.com/2020/fobe_hobe.
                        <br /><br /><strong>Keywords:</strong> bipartite graphs, hypergraphs, graph embedding, algebraic
                        distance on graphs, recommendation, link prediction
                        <hr />
                    </div>

                    <div id="bib15" class="collapse">
                        @inproceedings{mlg2020_15,<br />
                        title={First and Higher-Order Bipartite Embeddings},<br />
                        author={Justin Sybrandt and Ilya Safro},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>GATCheck: A Detailed Analysis of Graph Attention Networks</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid21">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib21">BibTex</button>
                        <a href="papers/MLG2020_paper_21.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=w6ea75UkfP0" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Lovish Madaan and Siddhant Arora</i><br />

                    <div id="pid21" class="collapse">
                        <strong>Abstract:</strong> Graph Attention Networks (GATs) are widely used for Representation
                        Learning in Graphs, but there is no proper study highlighting on what tasks GATs perform better
                        than other models and why. In this appraisal paper, we aim to improve our understanding of GATs
                        on a variety of tasks, including link prediction, multi-class node classification, and pairwise
                        node classification on benchmark datasets. We also perform ablation studies on the various
                        hyperparameters of GATs and try to reason about the importance of each of these in node
                        classification and link prediction tasks. Our study offers insights into the effectiveness of
                        GATs as compared to other techniques, and we make our code public so as to facilitate future
                        exploration.
                        <br /><br /><strong>Keywords:</strong> representation learning, node embeddings in graph
                        networks, machine learning for graphs, graph attention networks
                        <hr />
                    </div>

                    <div id="bib21" class="collapse">
                        @inproceedings{mlg2020_21,<br />
                        title={GATCheck: A Detailed Analysis of Graph Attention Networks},<br />
                        author={Lovish Madaan and Siddhant Arora},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Graph Clustering with Graph Neural Networks</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid42">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib42">BibTex</button>
                        <a href="papers/MLG2020_paper_42.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=-zT0DHB6eW0" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Anton Tsitsulin, John Palowitch, Bryan Perozzi and Emmanuel Müller</i><br />

                    <div id="pid42" class="collapse">
                        <strong>Abstract:</strong> Graph Neural Networks (GNNs) have achieved state-of-the-art results
                        on many graph analysis tasks such as node classification and link prediction. However, important
                        unsupervised problems on graphs, such as graph clustering, have proved more resistant to
                        advances in GNNs. In this paper, we study unsupervised training of GNN pooling in terms of their
                        clustering capabilities.

                        We start by drawing a connection between graph clustering and graph pooling: intuitively, a good
                        graph clustering is what one would expect from a GNN pooling layer. Counterintuitively, we show
                        that this is not true for state-of-the-art pooling methods, such as MinCut pooling. To address
                        these deficiencies, we introduce Deep Modularity Networks (DMoN), an unsupervised pooling method
                        inspired by the modularity measure of clustering quality, and show how it tackles recovery of
                        the challenging clustering structure of real-world graphs. In order to clarify the regimes where
                        existing methods fail, we carefully design a set of experiments on synthetic data which show
                        that DMoN is able to jointly leverage the signal from the graph structure and node attributes.
                        Similarly, on real-world data, we show that DMoN produces high quality clusters which correlate
                        strongly with ground truth labels, achieving state-of-the-art results.
                        <br /><br /><strong>Keywords:</strong> graph clustering, graph neural networks, graph
                        convolutional networks, deep learning, attributed graph clustering
                        <hr />
                    </div>

                    <div id="bib42" class="collapse">
                        @inproceedings{mlg2020_42,<br />
                        title={Graph Clustering with Graph Neural Networks},<br />
                        author={Anton Tsitsulin, John Palowitch, Bryan Perozzi and Emmanuel Müller},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Graph Frequency Analysis of COVID-19 Incidence in the United States</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid24">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib24">BibTex</button>
                        <a href="papers/MLG2020_paper_24.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=YalBH6WpS3w" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Yang Li and Gonzalo Mateos</i><br />

                    <div id="pid24" class="collapse">
                        <strong>Abstract:</strong> The COVID-19 pandemic markedly changed the way of life in the United
                        States (US). From early isolated regional outbreaks to ongoing country-wise spread, the
                        contagion exhibits different patterns at various timescales and locations. Thus, a close study
                        of the COVID-19 spread patterns can offer valuable insights on how counties were affected by the
                        virus. In the present work, a graph frequency analysis was conducted to investigate the spread
                        pattern of COVID-19 in the US. A geographical graph was constructed by computing the geodesic
                        distance between 3142 US counties. The numbers of daily confirmed COVID-19 cases per county were
                        collected and represented as graph signals, then mapped into the frequency domain via the graph
                        Fourier transform. The concept of graph frequency in Graph Signal Processing (GSP) enables the
                        decomposition of graph signals (i.e. daily confirmed cases) into modes with smooth or rapid
                        variations with respect to the underlying graph connectivity. Follow-up analysis revealed the
                        relationship between graph frequency components and the COVID-19 spread pattern within and
                        across counties. Specifically, our preliminary graph frequency analysis mined (and learned from)
                        confirmed case counts to unveil spatio-temporal contagion patterns of COVID-19 incidence for
                        each US county. Overall, results here support the promising prospect of using GSP tools for
                        epidemiology knowledge discovery on graphs.
                        <br /><br /><strong>Keywords:</strong> Graph data mining, graph signal processing, frequency
                        analysis, contagion pattern recognition
                        <hr />
                    </div>

                    <div id="bib24" class="collapse">
                        @inproceedings{mlg2020_24,<br />
                        title={Graph Frequency Analysis of COVID-19 Incidence in the United States},<br />
                        author={Yang Li and Gonzalo Mateos},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Graph Summarization and Graph Embeddings: Towards A Spectral Connection</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid17">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib17">BibTex</button>
                        <a href="papers/MLG2020_paper_17.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=laFmO6Jn-Q4" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Arpit Merchant and Michael Mathioudakis</i><br />

                    <div id="pid17" class="collapse">
                        <strong>Abstract:</strong> The graph summarization problem is to define a compressed data
                        structure that can concisely describe the original graph. A standard class of techniques for
                        summarization involves grouping nodes into supernodes via aggregation or clustering such that
                        the lp-reconstruction error, i.e. the p-norm between the original adjacency matrix and the
                        adjacency matrix recovered from the compressed summary, is minimized. Our main result shows that
                        graph summarization can be reformulated as a trace maximization problem, the relaxed version of
                        which can be solved exactly by all the eigenvectors of the adjacency matrix. We also prove a
                        lower bound on the optimal solution which uses k eigenvectors for a summary with k supernodes.
                        Our results motivate a simple spectral clustering algorithm that can yield excellent summaries.
                        Our experiments validate the quality of the resultant summaries.
                        <br /><br /><strong>Keywords:</strong> graph summarization, graph embeddings, spectral graph
                        theory
                        <hr />
                    </div>

                    <div id="bib17" class="collapse">
                        @inproceedings{mlg2020_17,<br />
                        title={Graph Summarization and Graph Embeddings: Towards A Spectral Connection},<br />
                        author={Arpit Merchant and Michael Mathioudakis},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Graph-based State Representation for Deep Reinforcement Learning</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid20">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib20">BibTex</button>
                        <a href="papers/MLG2020_paper_20.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=n7-XdEl_Ehs" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Vikram Waradpande, Daniel Kudenko and Megha Khosla</i><br />

                    <div id="pid20" class="collapse">
                        <strong>Abstract:</strong> Deep RL approaches build much of their success on the ability of the
                        deep neural network to generate useful internal representations. Nevertheless, they suffer from
                        a high sample-complexity and starting with a good input representation can have a significant
                        impact on the performance. In this paper, we exploit the fact that the underlying Markov
                        decision process (MDP) represents a graph, which enables us to incorporate the topological
                        information for effective state representation learning.

                        Motivated by the recent success of node representations for several graph analytical tasks we
                        specifically investigate the capability of node representation learning methods to effectively
                        encode the topology of the underlying MDP in Deep RL. To this end, we perform a comparative
                        analysis of several models chosen from different classes of representation learning algorithms
                        for policy learning in grid-world navigation tasks, which are representative of a large class of
                        RL problems. We find that all embedding methods outperform the commonly used matrix
                        representation of grid-world environments in all of the studied cases. Moreoever, graph
                        convolution based methods are outperformed by simpler random walk based methods and graph linear
                        autoencoders.
                        <br /><br /><strong>Keywords:</strong> Deep Reinforcement Learning, Deep Q-Learning, Markov
                        Decision Processes, Unsupervised Node Embeddings, Graph Neural Networks, Graph representation
                        <hr />
                    </div>

                    <div id="bib20" class="collapse">
                        @inproceedings{mlg2020_20,<br />
                        title={Graph-based State Representation for Deep Reinforcement Learning},<br />
                        author={Vikram Waradpande, Daniel Kudenko and Megha Khosla},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Heterogeneous Threshold Estimation for Linear Threshold Modeling</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid23">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib23">BibTex</button>
                        <a href="papers/MLG2020_paper_23.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=3sjCsQkq7ho" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Christopher Tran and Elena Zheleva</i><br />

                    <div id="pid23" class="collapse">
                        <strong>Abstract:</strong> Social networks play a central role in the spread of diseases, ideas,
                        and beliefs. The Linear Threshold Model (LTM) is a prominent model which describes the process
                        of diffusion through the network and how nodes become "infected" based on a threshold of number
                        of neighbors who are already "infected." LTM is often used with the assumption that node
                        thresholds are globally unique or randomly distributed. In many cases, however, thresholds can
                        differ between individuals, and knowing individual-level thresholds can lead to better diffusion
                        predictions. In this work, we propose a causal inference approach for estimating node
                        thresholds. We develop a Structural Causal Model to show the identifiability of causal effects
                        in the Linear Threshold Model, and map the threshold estimation problem to heterogeneous
                        treatment effect estimation. Through experimental results on real-world and synthetic datasets,
                        we show that individualized thresholds play an important part in reliable long-term diffusion
                        prediction.
                        <br /><br /><strong>Keywords:</strong> heterogeneous treatment effects, linear threshold model,
                        causal inference, information diffusion
                        <hr />
                    </div>

                    <div id="bib23" class="collapse">
                        @inproceedings{mlg2020_23,<br />
                        title={Heterogeneous Threshold Estimation for Linear Threshold Modeling},<br />
                        author={Christopher Tran and Elena Zheleva},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Hop Sampling: A Simple Regularized Graph Learning for Non-Stationary
                            Environments</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid43">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib43">BibTex</button>
                        <a href="papers/MLG2020_paper_43.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=7pedDukqAiU" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Young-Jin Park, Kyuyong Shin and Kyungmin Kim</i><br />

                    <div id="pid43" class="collapse">
                        <strong>Abstract:</strong> Graph representation learning is gaining popularity in a wide range
                        of applications, such as social networks analysis, computational biology, and recommender
                        systems. However, different with positive results from many academic studies, applying graph
                        neural networks (GNNs) in a real-world application is still challenging due to non-stationary
                        environments. The underlying distribution of streaming data changes unexpectedly, resulting in
                        different graph structures (a.k.a., concept drift). Therefore, it is essential to devise a
                        robust graph learning technique so that the model does not overfit to the training graphs. In
                        this work, we present Hop Sampling, a straightforward regularization method that can effectively
                        prevent GNNs from overfishing. The hop sampling randomly selects the number of propagation steps
                        rather than fixing it, and by doing so, it encourages the model to learn meaningful node
                        representation for all intermediate propagation layers and to experience a variety of plausible
                        graphs that are not in the training set. Particularly, we describe the use case of our method in
                        recommender systems, a representative example of the real-world non-stationary case. We
                        evaluated hop sampling on a large-scale real-world LINE dataset and conducted an online A/B/n
                        test in LINE Coupon recommender systems of LINE Wallet Tab. Experimental results demonstrate
                        that the proposed scheme improves the prediction accuracy of GNNs. We observed hop sampling
                        provides 7.97% and 16.93% improvements for NDCG and MAP compared to non-regularized GNN models
                        in our online service. Furthermore, models using hop sampling alleviate the oversmoothing issue
                        in GNNs enabling a deeper model as well as more diversified representation.
                        <br /><br /><strong>Keywords:</strong> Graph neural networks, Graph representation,
                        Non-stationary graphs, Recommender System, Mobile Coupon Service
                        <hr />
                    </div>

                    <div id="bib43" class="collapse">
                        @inproceedings{mlg2020_43,<br />
                        title={Hop Sampling: A Simple Regularized Graph Learning for Non-Stationary Environments},<br />
                        author={Young-Jin Park, Kyuyong Shin and Kyungmin Kim},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Influence of Asymmetry and Structural Roles on Triad Patterns in Undirected
                            Networks</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid18">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib18">BibTex</button>
                        <a href="papers/MLG2020_paper_18.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=DRc8WO-OBNw" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Milos Kudelka, Eliska Ochodkova, Jakub Plesnik and Sarka Zehnalova</i><br />

                    <div id="pid18" class="collapse">
                        <strong>Abstract:</strong> Triads, i.e., variously interconnected triplets of nodes,
                        significantly affect the network structure. Closed triads, for instance, are the building blocks
                        of communities. Our study focuses on the analysis of triads in which the ego is connected to two
                        alters, with the alters not having to be connected; therefore, the triads that are studied need
                        not be closed. The analysis uses two approaches based on asymmetric relationships between pairs
                        of nodes. In the first approach, we work with three different node roles, in which the ego and
                        its alters can appear in triads. We get a total of eighteen different role-based triad patterns.
                        The second approach allows us to work with a total of four different types of ties and six
                        different alter-pair patterns. In experiments with four different types of real-world networks,
                        we show how the properties of these networks differ in terms of role-based triad patterns. In
                        some of these networks, we further show that the triad-based properties remain stable during
                        network growth. The main contribution of our paper is the use of asymmetric relations for the
                        definition of four types of dependency-based tie strengths between nodes and the analysis of
                        their influence on the occurrence of different triad-based patterns in networks.
                        <br /><br /><strong>Keywords:</strong> social network, triadic closure, structural role,
                        asymmetric dependency, triad pattern
                        <hr />
                    </div>

                    <div id="bib18" class="collapse">
                        @inproceedings{mlg2020_18,<br />
                        title={Influence of Asymmetry and Structural Roles on Triad Patterns in Undirected
                        Networks},<br />
                        author={Milos Kudelka, Eliska Ochodkova, Jakub Plesnik and Sarka Zehnalova},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Karate Club: An API Oriented Open-Source Python Framework for Unsupervised Learning on
                            Graphs</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid8">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib8">BibTex</button>
                        <a href="papers/MLG2020_paper_8.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=t212-ntxu2U" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Benedek Rozemberczki, Olivér Kiss and Rik Sarkar</i><br />

                    <div id="pid8" class="collapse">
                        <strong>Abstract:</strong> Graphs encode important structural properties of complex systems.
                        Machine learning on graphs has therefore emerged as an important technique in research and
                        applications. We present Karate Club - a Python framework combining more than 30
                        state-of-the-art graph mining algorithms. These unsupervised techniques make it easy to identify
                        and represent common graph features. The primary goal of the package is to make community
                        detection, node and whole graph embedding available to a wide audience of machine learning
                        researchers and practitioners. Karate Club is designed with an emphasis on a consistent
                        application interface, scalability, ease of use, sensible out of the box model behaviour,
                        standardized dataset ingestion, and output generation. This paper discusses the design
                        principles behind the framework with practical examples. We show Karate Club's efficiency in
                        learning performance on a wide range of real world clustering problems and classification tasks
                        along with supporting evidence of its competitive speed.
                        <br /><br /><strong>Keywords:</strong> community detection, graph embedding, node embedding,
                        graph classification, node classification, Python, implicit factorization, graph clustering
                        <hr />
                    </div>

                    <div id="bib8" class="collapse">
                        @inproceedings{mlg2020_8,<br />
                        title={Karate Club: An API Oriented Open-Source Python Framework for Unsupervised Learning on
                        Graphs},<br />
                        author={Benedek Rozemberczki, Olivér Kiss and Rik Sarkar},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Learning Distributed Representations of Graphs with Geo2DR</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid10">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib10">BibTex</button>
                        <a href="papers/MLG2020_paper_10.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=X2AwBcyqtuk" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Paul Scherer and Pietro Lio</i><br />

                    <div id="pid10" class="collapse">
                        <strong>Abstract:</strong> We present Geo2DR (Geometric to Distributed Representations), a GPU
                        ready Python library for unsupervised learning on graph-structured data using discrete
                        substructure patterns and neural language models. It contains efficient implementations of
                        popular graph decomposition algorithms and neural language models in PyTorch which can be
                        combined to learn representations of graphs using the distributive hypothesis. Furthermore,
                        Geo2DR comes with general data processing and loading methods to bring substantial speed-up in
                        the training of the neural language models. Through this we provide a modular set of tools and
                        building blocks to quickly construct methods capable of learning distributed representations of
                        graphs. This is useful for replication of existing methods, modification, and development of
                        completely new methods. This paper serves to present the Geo2DR library and perform a
                        comprehensive comparative analysis of existing methods re-implemented using Geo2DR across widely
                        used graph classification benchmarks. Geo2DR displays a high reproducibility of results of
                        published methods and interoperability with other libraries useful for distributive language
                        modelling, making it a useful addition to the graph representation learning toolkit.
                        <br /><br /><strong>Keywords:</strong> Graph Representation Learning, Research Toolkit,
                        Reproducibility, Distributed Representations, Neural Language Model, Graph Kernel
                        <hr />
                    </div>

                    <div id="bib10" class="collapse">
                        @inproceedings{mlg2020_10,<br />
                        title={Learning Distributed Representations of Graphs with Geo2DR},<br />
                        author={Paul Scherer and Pietro Lio},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Learning Generic Representations for Dynamic Social Interaction</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid6">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib6">BibTex</button>
                        <a href="papers/MLG2020_paper_6.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=i0uxMh0RBrQ" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Yanbang Wang, Pan Li, Chongyang Bai, V.S. Subrahmanian and Jure Leskovec</i><br />

                    <div id="pid6" class="collapse">
                        <strong>Abstract:</strong> Social interaction, such as eye contact, speaking and listening, are
                        ubiquitous in our life and carries important clues of human's social status and psychological
                        state. With evolving dynamics fundamentally different from people's social relationships, the
                        complex interactions among a group of people are another informative resource to analyze
                        patterns of humans' social behaviors and characteristics. Despite the great importance, previous
                        approaches on extracting patterns from such dynamic social interactions are still underdeveloped
                        and overly task-specific. We fill this gap by proposing a temporal network formulation of the
                        problem, combined with a novel representation learning framework, temporal network-diffusion
                        convolution networks (TNDCN) that accommodates the many downstream tasks with a unified
                        structure: we creatively propagate people's fast-changing descriptive traits among their
                        evolving gazing networks with specially designed (1) network diffusion scheme and (2)
                        hierarchical pooling to learn high-quality embeddings for downstream tasks using a consistent
                        structure and minimal feature engineering. Analysis show that (1) can not only capture patterns
                        from existed interactions but also people's avoidance of interactions that turn out just as
                        critical. (2) allows us to flexibly collect different fine-grained critical interaction features
                        scattered over an extremely long time span, which is also key to success but essentially fails
                        all the previous temporal GNNs based on recurrent structures. We evaluate our model over three
                        different prediction tasks, detecting deception, dominance and nervousness. Our model not only
                        consistently outperforms previous baselines but also provides good interpretation by implying
                        two important pieces of social insight derived from the learned coefficients.
                        <br /><br /><strong>Keywords:</strong> Social Interaction, Dynamic Network, Representation
                        Learning, Deception Detection
                        <hr />
                    </div>

                    <div id="bib6" class="collapse">
                        @inproceedings{mlg2020_6,<br />
                        title={Learning Generic Representations for Dynamic Social Interaction},<br />
                        author={Yanbang Wang, Pan Li, Chongyang Bai, V.S. Subrahmanian and Jure Leskovec},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Link Predictions in an Online Health Community for Smoking Cessation</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid25">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib25">BibTex</button>
                        <a href="papers/MLG2020_paper_25.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=W_nJG5x_fPw" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Sulyun Lee, Hankyu Jang, Kang Zhao, Michael S. Amato and Amanda L. Graham</i><br />

                    <div id="pid25" class="collapse">
                        <strong>Abstract:</strong> Effective link predictions in online social networks can help to
                        improve user experience and engagement, which are often associated with better health outcomes
                        for users of online health communities (OHCs). However, limited attention has been paid to
                        predicting social network links in OHCs. This paper explores link predictions in an OHC for
                        smoking cessation by considering it as a multi-relational social network that incorporates
                        multiple types of social relationships. We demonstrate that leveraging information from multiple
                        networks built based on different types of relationships is superior to using only information
                        from a single network or the aggregated network. In addition, adding community structures and
                        nodal similarities based on network embedding can help link predictions in different ways. Our
                        work has implications for the design and management of a successful online health community.
                        <br /><br /><strong>Keywords:</strong> Social Network, Network Embedding, Multi-Relational
                        Network, Supervised Learning, Smoking Cessation
                        <hr />
                    </div>

                    <div id="bib25" class="collapse">
                        @inproceedings{mlg2020_25,<br />
                        title={Link Predictions in an Online Health Community for Smoking Cessation},<br />
                        author={Sulyun Lee, Hankyu Jang, Kang Zhao, Michael S. Amato and Amanda L. Graham},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Little Ball of Fur: A Python Library for Graph Sampling</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid9">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib9">BibTex</button>
                        <a href="papers/MLG2020_paper_9.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=5OpjBqlPWME" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Benedek Rozemberczki, Olivér Kiss and Rik Sarkar</i><br />

                    <div id="pid9" class="collapse">
                        <strong>Abstract:</strong> Sampling graphs is an important task in data mining. In this paper,
                        we describe Little Ball of Fur a Python library that includes more than twenty graph sampling
                        algorithms. Our goal is to make node, edge, and exploration-based network sampling techniques
                        accessible to a large number of professionals, researchers, and students in a single streamlined
                        framework. We created this framework with a focus on a coherent application public interface
                        which has a convenient design, generic input data requirements, and reasonable baseline settings
                        of algorithms. Here we overview these design foundations of the framework in detail with
                        illustrative code snippets. We show the practical usability of the library by estimating various
                        global statistics of social networks and web graphs. Experiments demonstrate that Little Ball of
                        Fur can speed up node and whole graph embedding techniques considerably with mildly
                        deteriorating the predictive value of distilled features.
                        <br /><br /><strong>Keywords:</strong> network sampling, graph sampling, subsampling, network
                        analytics, graph mining, Python
                        <hr />
                    </div>

                    <div id="bib9" class="collapse">
                        @inproceedings{mlg2020_9,<br />
                        title={Little Ball of Fur: A Python Library for Graph Sampling},<br />
                        author={Benedek Rozemberczki, Olivér Kiss and Rik Sarkar},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>MIDAS: Microcluster-Based Detector of Anomalies in Edge Streams </strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid41">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib41">BibTex</button>
                        <a href="papers/MLG2020_paper_41.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=DPmN-uPW8qU" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Siddharth Bhatia, Bryan Hooi, Minji Yoon, Kijung Shin and Christos Faloutsos</i><br />

                    <div id="pid41" class="collapse">
                        <strong>Abstract:</strong> Given a stream of graph edges from a dynamic graph, how can we assign
                        anomaly scores to edges in an online manner, for the purpose of detecting unusual behavior,
                        using constant time and memory? Existing approaches aim to detect individually surprising edges.
                        In this work, we propose MIDAS, which focuses on detecting microcluster anomalies, or suddenly
                        arriving groups of suspiciously similar edges, such as lockstep behavior, including denial of
                        service attacks in network traffic data. MIDAS has the following properties: (a) it detects
                        microcluster anomalies while providing theoretical guarantees about its false positive
                        probability; (b) it is online, thus processing each edge in constant time and constant memory,
                        and also processes the data 162-644 times faster than state-of-the-art approaches; (c) it
                        provides 42%-48% higher accuracy (in terms of AUC) than state-of-the-art approaches. Category:
                        Relevant work that has been previously published at AAAI '20.
                        <br /><br /><strong>Keywords:</strong> Edge Streams, Microcluster, Dynamic Graphs, Anomaly
                        Detection
                        <hr />
                    </div>

                    <div id="bib41" class="collapse">
                        @inproceedings{mlg2020_41,<br />
                        title={MIDAS: Microcluster-Based Detector of Anomalies in Edge Streams },<br />
                        author={Siddharth Bhatia, Bryan Hooi, Minji Yoon, Kijung Shin and Christos Faloutsos},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Mining Persistent Activity in Continually Evolving Networks</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid14">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib14">BibTex</button>
                        <a href="papers/MLG2020_paper_14.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=0ue2wQSUaDg" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Caleb Belth, Xinyi Zheng and Danai Koutra</i><br />

                    <div id="pid14" class="collapse">
                        <strong>Abstract:</strong> Work that will be presented at the main conference. Frequent pattern
                        mining is a key area of study that gives insights into the structure and dynamics of evolving
                        networks, such as social or road networks.
                        However, not only does a network evolve, but often the way that it evolves, itself evolves.
                        Thus, knowing, in addition to patterns' frequencies, for how long and how regularly they have
                        occurred—i.e., their persistence—can add to our understanding of evolving networks. In this
                        work, we propose the problem of mining activity that persists through time in continually
                        evolving networks—i.e., activity that repeatedly and consistently occurs. We extend the notion
                        of temporal motifs to capture activity among specific nodes, in what we call activity snippets,
                        which are small sequences of edge-updates that reoccur. We propose axioms and properties that a
                        measure of persistence should satisfy, and develop such a persistence measure. We also propose
                        PENminer, an efficient framework for mining activity snippets' Persistence in Evolving Networks,
                        and
                        design both offline and streaming algorithms. We apply PENminer to numerous real, large-scale
                        evolving networks and edge streams, and find activity that is surprisingly regular over a long
                        period of time, but too infrequent to be discovered by aggregate count alone, and bursts of
                        activity exposed by their lack of persistence. Our findings with PENminer include neighborhoods
                        in NYC where taxi traffic persisted through Hurricane Sandy, the opening of new bike-stations,
                        characteristics of social network users, and more. Moreover, we use PENminer to identify subtle
                        anomalies in a bike network and catch attacks in an IP-network, outperforming baselines by 8% in
                        AUC.
                        <br /><br /><strong>Keywords:</strong> Persistence, Evolving Networks, Edge Streams
                        <hr />
                    </div>

                    <div id="bib14" class="collapse">
                        @inproceedings{mlg2020_14,<br />
                        title={Mining Persistent Activity in Continually Evolving Networks},<br />
                        author={Caleb Belth, Xinyi Zheng and Danai Koutra},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Network Embedding with Attribute Refinement</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid19">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib19">BibTex</button>
                        <a href="papers/MLG2020_paper_19.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=4E9-kVVlggc" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Tong Xiao, Yuan Fang, Hongxia Yang and Vincent W. Zheng</i><br />

                    <div id="pid19" class="collapse">
                        <strong>Abstract:</strong> Network embedding has been an active research area given its
                        effectiveness in mapping nodes to low-dimensional representations.
                        While previous studies mostly focus on network topology, recent
                        advances have shown that rich node-level information, known as
                        attributes, often exist and can substantially benefit embedding based
                        on the assumption of homophily: nodes often connect to other nodes
                        similar to themselves. However, we find that inconsistencies often
                        occur in node attributes in real-world data, which can undermine the
                        homophily assumption and thus degrade the performance of attributed network embedding. To
                        address this drawback, in this paper,
                        we present a novel framework for unsupervised network embedding
                        with attribute refinement. In particular, we propose a learnable filter
                        to automatically refine the individual attributes of every node. To
                        overcome the challenge of no supervision, we leverage homophily to
                        guide the refinement—attributes should be fine-tuned in a way to reinforce the correlation with
                        topology. Finally, we conduct extensive
                        experiments on three benchmark real-world datasets, which show
                        that our model significantly outperforms state-of-the-art methods
                        on both node classification and link prediction tasks. Furthermore,
                        we perform model analysis to demonstrate that our framework can
                        effectively refine attributes.
                        <br /><br /><strong>Keywords:</strong> Network embedding, attribute refinement, homophily
                        <hr />
                    </div>

                    <div id="bib19" class="collapse">
                        @inproceedings{mlg2020_19,<br />
                        title={Network Embedding with Attribute Refinement},<br />
                        author={Tong Xiao, Yuan Fang, Hongxia Yang and Vincent W. Zheng},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Network Experiment Design for Estimating Direct Treatment Effects</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid34">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib34">BibTex</button>
                        <a href="papers/MLG2020_paper_34.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=nA32p03Whxo" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Zahra Fatemi and Elena Zheleva</i><br />

                    <div id="pid34" class="collapse">
                        <strong>Abstract:</strong> Network experiment design refers to the design of controlled
                        experiments for interacting units with the goal of estimating a causal effect of interest.
                        Estimating the effect of treatment alone on units' outcome, known as direct treatment effect, in
                        network experiments is challenging due to information spillover between peers through shared
                        edges. Prominent methods for network experiment design mostly focus on estimating total
                        treatment effects, the combination of peer effects and direct treatment effects. Less focus has
                        been given to approaches that provide an unbiased estimation of direct treatment effect.
                        We present a framework that takes advantage of independent sets and assigns treatment and
                        control only to a set of non-adjacent nodes in a graph, in order to disentangle peer effects
                        from direct treatment effect estimation. Randomizing over independent set nodes removes peer
                        effects between nodes in the experiment while canceling out the peer effects from nodes outside
                        the experiment.
                        Through a series of simulated experiments on synthetic and real-world network datasets, we show
                        that our framework significantly increases the accuracy of direct treatment effect estimation in
                        network experiments.
                        <br /><br /><strong>Keywords:</strong> Causal Inference, Network experiment design, Peer effect,
                        Direct treatment effect
                        <hr />
                    </div>

                    <div id="bib34" class="collapse">
                        @inproceedings{mlg2020_34,<br />
                        title={Network Experiment Design for Estimating Direct Treatment Effects},<br />
                        author={Zahra Fatemi and Elena Zheleva},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>On Structural vs. Proximity-based Temporal Node Embeddings</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid37">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib37">BibTex</button>
                        <a href="papers/MLG2020_paper_37.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=EvQlYmgRt-8" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Puja Trivedi, Alican Büyükçakır, Yin Lin, Yinlong Qian, Di Jin and Danai Koutra</i><br />

                    <div id="pid37" class="collapse">
                        <strong>Abstract:</strong> We investigate the representation power of static node embeddings in
                        dynamic or temporal settings. To this end, we introduce a framework that incorporates different
                        design options for extending static node embeddings to temporal settings: temporal combination
                        schemes to introduce dynamics in otherwise static approaches, alignment methods that lead to
                        comparability of embedding dimensions across time steps, and different edge operators for
                        generating edge embeddings from node embeddings. In our empirical analysis, we evaluate the
                        performance of both proximity-based and structural node embedding methods in a temporal link
                        prediction task over four time-evolving networks. Our results show that proper choice over these
                        designs yields up to 20% absolute improvement over baselines that do not leverage temporal
                        combination and embedding alignment. We further present broad trends to guide design decisions
                        for embedding methods in temporal settings.
                        <br /><br /><strong>Keywords:</strong> temporal graphs, graph embeddings, temporal link
                        prediction
                        <hr />
                    </div>

                    <div id="bib37" class="collapse">
                        @inproceedings{mlg2020_37,<br />
                        title={On Structural vs. Proximity-based Temporal Node Embeddings},<br />
                        author={Puja Trivedi, Alican Büyükçakır, Yin Lin, Yinlong Qian, Di Jin and Danai Koutra},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Robust Unsupervised Mining of Dense Sub-Graphs at Multiple Resolutions</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid36">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib36">BibTex</button>
                        <a href="papers/MLG2020_paper_36.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=3J1W5CYy4dw " target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Neil Gupta, Gunjan Gupta, Joydeep Ghosh, Sheshank Shankar and Alex Mallen</i><br />

                    <div id="pid36" class="collapse">
                        <strong>Abstract:</strong> Category: Novel research paper. Whereas in traditional partitional
                        clustering, each data point belongs to a cluster, there are several applications where only some
                        of the points form relatively homogenous or "dense" groups, and points that don't seem to belong
                        to any cluster need to be ignored. Moreover, different clusters may emerge at different scales
                        or density levels. This makes it difficult to identify them using a single density threshold,
                        especially if we also want to ignore the non-clustering data. If data is represented in a metric
                        space, then recent extensions of a classical approach called Hierarchical Mode Analysis (HMA)
                        are able to identify clusters at multiple resolutions, while ignoring "non-dense" areas.
                        However, this approach does not apply when the relations between pairs of data points can only
                        be represented as a (sparse) similarity or affinity graph. Motivated by two complex, real-life
                        applications where one needs to identify dense subgraphs at multiple resolutions, while ignoring
                        nodes that are not well connected in the similarity graph, we introduce a novel algorithm called
                        HIMAG (Hierarchical Incremental Mode Analysis for Graphs) that provides capabilities analogous
                        to HMA based methods but applicable to graphs. We also provide a powerful multi-resolution
                        visualization tool customized for the new algorithm. We present results on the two motivating
                        real-world applications as well as two standard benchmark social graph datasets, to show the
                        power of our approach and compare it with some standard graph partitioning algorithms that were
                        retrofitted to produce dense clusters by pruning non-dense data in a non-trivial manner. We are
                        also open-sourcing the new dense graph datasets and tools to the community.
                        <br /><br /><strong>Keywords:</strong> graph learning, dense graphs, hierarchical clusters,
                        visualization, automated cluster selection, social graphs, hierarchical mode analysis
                        <hr />
                    </div>

                    <div id="bib36" class="collapse">
                        @inproceedings{mlg2020_36,<br />
                        title={Robust Unsupervised Mining of Dense Sub-Graphs at Multiple Resolutions},<br />
                        author={Neil Gupta, Gunjan Gupta, Joydeep Ghosh, Sheshank Shankar and Alex Mallen},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>SNAPSKETCH: Graph Representation Approach for Intrusion Detection in a Streaming
                            Graph</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid1">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib1">BibTex</button>
                        <a href="papers/MLG2020_paper_1.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=wi9DISFQXLo" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Ramesh Paudel and William Eberle</i><br />

                    <div id="pid1" class="collapse">
                        <strong>Abstract:</strong> In this paper, we propose a novel unsupervised graph representation
                        approach in a graph stream called SNAPSKETCH that can be used for anomaly detection. It first
                        performs a fixed-length random walk from each node in a network and constructs n-shingles from a
                        walk path. The top discriminative n-shingles identified using a frequency measure are projected
                        into a dimensional projection vector chosen uniformly at random. Finally, a graph is sketched
                        into a low-dimensional sketch vector using a simplified hashing of the projection vector and the
                        cost of shingles. Using the learned sketch vector, anomaly detection is done using the
                        state-of-the-art anomaly detection approach called RRCF [1]. SNAPSKETCH has several advantages,
                        including fully unsupervised learning, constant memory space usage, entire-graph embedding, and
                        real-time anomaly detection.
                        <br /><br /><strong>Keywords:</strong> Graph Representation, Anomaly Detection, DoS Attack,
                        Intrusion Detection, Graph Sketching
                        <hr />
                    </div>

                    <div id="bib1" class="collapse">
                        @inproceedings{mlg2020_1,<br />
                        title={SNAPSKETCH: Graph Representation Approach for Intrusion Detection in a Streaming
                        Graph},<br />
                        author={Ramesh Paudel and William Eberle},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Scalable and Consistent Estimation in Continuous-time Networks of Relational
                            Events</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid27">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib27">BibTex</button>
                        <a href="papers/MLG2020_paper_27.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=kaqMGrMWXcI " target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Makan Arastuie, Subhadeep Paul and Kevin S. Xu</i><br />

                    <div id="pid27" class="collapse">
                        <strong>Abstract:</strong> In many application settings involving networks, such as messages
                        between users of an on-line social network or transactions between traders in financial markets,
                        the observed data consist of timestamped relational events, which form a continuous-time
                        network. We propose the Community Hawkes Independent Pairs (CHIP) generative model for such
                        networks. We show that applying spectral clustering to adjacency matrices constructed from
                        relational events generated by the CHIP model provides consistent community detection for a
                        growing number of nodes. We also develop consistent and computationally efficient estimators for
                        the model parameters. We demonstrate that our proposed CHIP model and estimation procedure
                        scales to large networks with tens of thousands of nodes and provides superior fits than
                        existing continuous-time network models on several real networks.
                        This submission is a novel research paper.
                        <br /><br /><strong>Keywords:</strong> Community Hawkes Independent Pairs model, event-based
                        network, continuous-time network, timestamped network, relational events, spectral clustering,
                        Hawkes process
                        <hr />
                    </div>

                    <div id="bib27" class="collapse">
                        @inproceedings{mlg2020_27,<br />
                        title={Scalable and Consistent Estimation in Continuous-time Networks of Relational
                        Events},<br />
                        author={Makan Arastuie, Subhadeep Paul and Kevin S. Xu},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Scale-Free, Attributed and Class-Assortative Graph Generation to Facilitate
                            Introspection of Graph Neural Networks</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid33">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib33">BibTex</button>
                        <a href="papers/MLG2020_paper_33.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=tj6H4cvbP5Y" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Neil Shah</i><br />

                    <div id="pid33" class="collapse">
                        <strong>Abstract:</strong> Semi-supervised node classification on graphs is a complex interplay
                        between graph structure, node features and class-assortative (homophily) properties, and the
                        flexibility of a model to capture these nuances. Modern datasets used to push the frontier for
                        these tasks exhibit diverse properties across these fronts, making it challenging to study how
                        these properties individually and jointly influence performance of modern embedding-based
                        methods like graph neural networks (GNNs) for this task. In this work-in-progress, we propose an
                        intuitive and flexible scale-free graph generation model, CaBaM, which enables simulation of
                        class-assortative and attributed graphs via the well-known Barabasi-Albert model. We show
                        empirically and theoretically how our model can easily describe a variety of graph types, while
                        imbuing the generated graphs with the necessary ingredients for attribute, topology, and
                        label-aware semi-supervised node-classification.
                        <br /><br /><strong>Keywords:</strong> semi-supervised learning, graph generation, barabasi
                        albert, graphs
                        <hr />
                    </div>

                    <div id="bib33" class="collapse">
                        @inproceedings{mlg2020_33,<br />
                        title={Scale-Free, Attributed and Class-Assortative Graph Generation to Facilitate Introspection
                        of Graph Neural Networks},<br />
                        author={Neil Shah},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Substitution Techniques for Grocery Fulfillment and Assortment Optimization Using
                            Product Graphs</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid7">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib7">BibTex</button>
                        <a href="papers/MLG2020_paper_7.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=NdxX6Djfddw" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Amit Pande, Aparupa Das Gupta, Kai Ni, Rahul Biswas and Sayon Majumdar</i><br />

                    <div id="pid7" class="collapse">
                        <strong>Abstract:</strong> Identifying substitutable pairs or groups of products is key to
                        building relevant product assortment for brick-and-mortar stores as well as to efficiently
                        handle out of stock scenarios. In this work, we describe the unique challenges with a retailer’s
                        data to identify substitutable product pairs from a large catalog and nationwide store
                        transactions. We apply some of the well established approaches in data mining and machine
                        learning to customer store purchase data and product attributes data to generate networks of
                        substitutable products. This paper presents a novel application of substitutable product
                        networks integrated with an assortment optimization engine that was developed in-house to select
                        the optimal assortment of products for the stores. The outcomes from a large scale experiment
                        conducted across 120 stores within United States demonstrates a unit sale lift in excess of 11%.
                        In another set of tests, we analyze the performance of various algorithms for product
                        substitution and fulfillment when customers encounter Out of Stock (OOS) scenario while shopping
                        groceries for same day delivery.
                        <br /><br /><strong>Keywords:</strong> Product Substitutes, Data Mining, Graph, Assortment
                        Optimization
                        <hr />
                    </div>

                    <div id="bib7" class="collapse">
                        @inproceedings{mlg2020_7,<br />
                        title={Substitution Techniques for Grocery Fulfillment and Assortment Optimization Using Product
                        Graphs},<br />
                        author={Amit Pande, Aparupa Das Gupta, Kai Ni, Rahul Biswas and Sayon Majumdar},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>TIES: Temporal Interaction Embeddings For Enhancing Social Media Integrity At
                            Facebook</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid38">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib38">BibTex</button>
                        <a href="papers/MLG2020_paper_38.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=ZI7flmqxV20" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Nima Noorshams, Saurabh Verma and Aude Hofleitner</i><br />

                    <div id="pid38" class="collapse">
                        <strong>Abstract:</strong> Since its inception, Facebook has become an integral part of the
                        online social community. People rely on Facebook to connect with others and build communities.
                        As a result, it is paramount to protect the integrity of such a large network in a fast and
                        scalable manner. In this paper, we present our efforts to protect various social media entities
                        at Facebook from people who try to abuse our platform. We present a novel Temporal Interaction
                        EmbeddingS (TIES) model that is designed to capture rogue social interactions and flag them for
                        further suitable actions. TIES is a supervised, deep learning, production ready model at
                        Facebook-scale networks. Prior works on integrity problems are mostly focused on capturing
                        either only static or certain dynamic features of social entities. In contrast, TIES can capture
                        both these variant behaviors in a unified model owing to the recent strides made in the domains
                        of graph embedding and deep sequential pattern learning. To show the real-world impact of TIES,
                        we present a few applications especially for preventing spread of misinformation, fake account
                        detection, and reducing ads payment risks in order to enhance Facebook platform’s integrity.
                        <br /><br /><strong>Keywords:</strong> temporal embeddings, sequence modeling, social media
                        integrity
                        <hr />
                    </div>

                    <div id="bib38" class="collapse">
                        @inproceedings{mlg2020_38,<br />
                        title={TIES: Temporal Interaction Embeddings For Enhancing Social Media Integrity At
                        Facebook},<br />
                        author={Nima Noorshams, Saurabh Verma and Aude Hofleitner},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Understanding and Evaluating Structural Node Embeddings</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid29">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib29">BibTex</button>
                        <a href="papers/MLG2020_paper_29.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=Y-YKgsETx3A" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Junchen Jin, Mark Heimann, Di Jin and Danai Koutra</i><br />

                    <div id="pid29" class="collapse">
                        <strong>Abstract:</strong> While most network embedding techniques model the proximity between
                        nodes in a network, recently there has been significant interest in structural embeddings that
                        are based on node equivalences, a notion rooted in sociology: equivalences or positions are
                        collections of nodes that have similar roles—i.e., similar functions, ties or interactions with
                        nodes in other positions—irrespective of their distance or reachability in the network. Unlike
                        the proximity-based methods that are rigorously evaluated in the literature, the evaluation of
                        structural embeddings is less mature. or real networks with labels that are arbitrarily defined,
                        and its connection to sociological equivalences has hitherto been vague and tenuous. To fill in
                        this gap, we set out to understand what types of equivalences structural embeddings capture. We
                        are the first to contribute rigorous intrinsic and extrinsic evaluation methodology for
                        structural embeddings, along with carefully-designed, diverse datasets of varying sizes. We
                        observe a number of different evaluation variables that can lead to different results (e.g.,
                        choice of similarity measure or label definitions). We find that degree distributions within
                        nodes’ local neighborhoods can lead to simple yet effective baselines. We hope that our findings
                        can influence the design of further node embedding methods and also pave the way for future
                        evaluation of existing methods. **Category: appraisal paper**
                        <br /><br /><strong>Keywords:</strong> structural node embeddings, network embedding, role
                        equivalence, intrinsic evaluation, extrinsic evaluation
                        <hr />
                    </div>

                    <div id="bib29" class="collapse">
                        @inproceedings{mlg2020_29,<br />
                        title={Understanding and Evaluating Structural Node Embeddings},<br />
                        author={Junchen Jin, Mark Heimann, Di Jin and Danai Koutra},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <p class="large text-muted">
                        <strong>Unsupervised Hierarchical Graph Representation Learning by Mutual Information
                            Maximization</strong>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#pid13">Abstract</button>
                        <button class="btn btn-primary btn-xs" data-toggle="collapse"
                            data-target="#bib13">BibTex</button>
                        <a href="papers/MLG2020_paper_13.pdf" target=_blank class="btn btn-primary btn-xs"
                            role="button">PDF</a>
                        <a href="https://www.youtube.com/watch?v=2Ox0QURMCRA" target=_blank
                            class="btn btn-primary btn-xs" role="button">Video</a>
                        <br />
                        <i>Fei Ding, Xiaohong Zhang, Justin Sybrandt and Ilya Safro</i><br />

                    <div id="pid13" class="collapse">
                        <strong>Abstract:</strong> Graph representation learning based on graph neural networks (GNNs)
                        can greatly improve the performance of downstream tasks, such as node and graph classification.
                        However, the general GNN models do not aggregate node information in a hierarchical manner, and
                        can miss key higher-order structural features of many graphs. The hierarchical aggregation also
                        enables the graph representations to be explainable. In addition, supervised graph
                        representation learning requires labeled data, which is expensive and error-prone. To address
                        these issues, we present an unsupervised graph representation learning method, Unsupervised
                        Hierarchical Graph Representation (UHGR), which can generate hierarchical representations of
                        graphs. Our method focuses on maximizing mutual information between "local" and high-level
                        "global" representations, which enables us to learn the node embeddings and graph embeddings
                        without any labeled data. To demonstrate the effectiveness of the proposed method, we perform
                        the node and graph classification using the learned node and graph embeddings. The results show
                        that the proposed method achieves comparable results to state-of-the-art supervised methods on
                        several benchmarks. In addition, our visualization of hierarchical representations indicates
                        that our method can capture meaningful and interpretable clusters.
                        <br /><br /><strong>Keywords:</strong> graph neural networks, representation learning,
                        unsupervised learning, hierarchical representation, mutual information
                        <hr />
                    </div>

                    <div id="bib13" class="collapse">
                        @inproceedings{mlg2020_13,<br />
                        title={Unsupervised Hierarchical Graph Representation Learning by Mutual Information
                        Maximization},<br />
                        author={Fei Ding, Xiaohong Zhang, Justin Sybrandt and Ilya Safro},<br />
                        booktitle={Proceedings of the 16th International Workshop on Mining and Learning with Graphs
                        (MLG)},<br />
                        year={2020}<br />
                        }
                        <hr />
                    </div>

                    </p>

                    <!-- End Paper List -->
                </div>
            </div>
        </div>
    </section>

    <!-- Call for Papers Section -->
    <section id="call">
        <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Call for Papers</h2>
                    <!--h3 class="section-subheading text-muted">Will be announced soon!</h3-->
                </div>
                <div class="row text-justify">
                    <div class="col-md-12">
                        <p class="large text-muted">
                            Due to public health concerns in light of the unfolding COVID-19 outbreak. We will follow
                            exactly the option that ACM SIGKDD and the KDD 2020 organizing committee will suggest and
                            will follow the style that the KDD conference adopts. Please check this website regularly
                            for updates.
                        </p>
                        <p class="large text-muted">
                            This workshop is a forum for exchanging ideas and methods for mining and learning with
                            graphs, developing new common understandings of the problems at hand, sharing of data sets
                            where applicable, and leveraging existing knowledge from different disciplines. The goal is
                            to bring together researchers from academia, industry, and government, to create a forum for
                            discussing recent advances in graph analysis. In doing so, we aim to better understand the
                            overarching principles and the limitations of our current methods and to inspire research on
                            new algorithms and techniques for mining and learning with graphs.
                        </p>
                        <p class="large text-muted">
                            To reflect the broad scope of work on mining and learning with graphs, we encourage
                            submissions that span the spectrum from theoretical analysis to algorithms and
                            implementation, to applications and empirical studies. As an example, the growth of
                            user-generated content on blogs, microblogs, discussion forums, product reviews, etc., has
                            given rise to a host of new opportunities for graph mining in the analysis of social media.
                            We encourage submissions on theory, methods, and applications focusing on a broad range of
                            graph-based approaches in various domains.
                        </p>
                        <p class="large text-muted">
                            Topics of interest include, but are not limited to:
                        </p>

                        <ul class="large text-muted">
                            <li><b>Theoretical aspects:</b>
                                <ul class="large text-muted">
                                    <li>Computational or statistical learning theory related to graphs</li>
                                    <li>Theoretical analysis of graph algorithms or models</li>
                                    <li>Sampling and evaluation issues in graph algorithms</li>
                                    <li>Analysis of dynamic graphs</li>
                                </ul>
                            </li>
                            <li><b>Algorithms and methods:</b>
                                <ul class="large text-muted">
                                    <li>Graph mining</li>
                                    <li>Probabilistic and graphical models for structured data</li>
                                    <li>Heterogeneous/multi-model graph analysis</li>
                                    <li>Network embedding models</li>
                                    <li>Statistical models of graph structure</li>
                                    <li>Combinatorial graph methods</li>
                                    <li>Semi-supervised learning, active learning, transductive inference, and transfer
                                        learning in the context of graph</li>
                                </ul>
                            </li>
                            <li><b>Applications and analysis:</b>
                                <ul class="large text-muted">
                                    <li>Analysis of social media</li>
                                    <li>Analysis of biological networks</li>
                                    <li>Knowledge graph construction</li>
                                    <li>Large-scale analysis and modeling</li>
                                </ul>
                            </li>
                        </ul>

                        <p class="large text-muted">
                            We welcome many kinds of papers, such as, but not limited to:
                        </p>

                        <ul class="large text-muted">
                            <li>Novel research papers
                            </li>
                            <li>Demo papers
                            </li>
                            <li>Work-in-progress papers
                            </li>
                            <li>Visionary papers (white papers)
                            </li>
                            <li>Appraisal papers of existing methods and tools (e.g., lessons learned)
                            </li>
                            <li>Relevant work that has been previously published
                            </li>
                            <li>Work that will be presented at the main conference
                            </li>
                        </ul>

                        <p class="large text-muted">
                            Authors should <strong>clearly indicate</strong> in their abstracts the kinds of submissions
                            that the papers belong to, to help reviewers better understand their contributions. <br />
                            All papers will be peer reviewed, single-blinded.
                            Submissions must be in PDF, <strong>no more than 8 pages long</strong> — shorter papers are
                            welcome — and formatted according to the standard double-column <a
                                href="http://www.acm.org/publications/proceedings-template#aL2" target=_blank>ACM
                                Proceedings Style</a>. <br />
                            The accepted papers will be published on the workshop’s website and will not be considered
                            archival for resubmission purposes. <br />
                            Authors whose papers are accepted to the workshop will have the opportunity to participate
                            in a spotlight and poster session, and some set will also be chosen for oral presentation.

                        </p>

                        <p class="large text-muted">
                            <strong>For paper submission, please proceed to the <a
                                    href="https://easychair.org/conferences/?conf=mlg2020" target=_blank>submission
                                    website</a>.</strong>
                        </p>

                        <p class="large text-muted">
                            This year MLG will be held jointly with the <a
                                href="https://deep-learning-graphs.bitbucket.io/dlg-kdd20/">International Workshop on
                                Deep Learning on Graphs (KDD-DLG)</a>. DLG will maintain a separate submission website
                            and program committee.
                        </p>

                        <p class="large text-muted">
                            <strong>Please send enquiries to chair@mlgworkshop.org.</strong>
                        </p>

                        <p class="large text-muted">
                            To receive updates about the current and future workshops and the Graph Mining community,
                            please join the <a href="https://groups.google.com/d/forum/mlg-list" target=_blank>Mailing
                                List</a>, or follow the <a href="https://twitter.com/mlgworkshop" target=_blank>Twitter
                                Account</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Dates Section -->
    <section id="dates" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Important Dates</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 text-left">
                    &nbsp;
                </div>
                <div class="col-lg-6 text-left">
                    <div class="col-md-12">
                        <!--p class="large text-muted">
                      <b>Paper Submission Open:</b> TBD
                    </p-->
                        <!--p class="large text-muted">
                      <b>Paper Abstract Deadline:</b> <strike>May 20, 2020</strike>
                    </p-->
                        <p class="large text-muted">
                            <b>Paper Submission Deadline:</b> <strike>June 15, 2020</strike>
                        </p>
                        <p class="large text-muted">
                            <b>Author Notification:</b> <strike>July 15, 2020</strike>
                        </p>
                        <p class="large text-muted">
                            <b>Camera Ready:</b> <strike>August 1, 2020</strike>
                        </p>
                        <p class="large text-muted">
                            <b>Workshop:</b> August 24, 2020
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Organization Section -->
    <section id="organization">
        <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Workshop Organizers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">


                <div class="col-md-1">
                    &nbsp;
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/2_shobeir.jpg" class="img-responsive img-circle" alt="Shobeir Fakhraei">
                        <h4>Shobeir Fakhraei</h4>
                        <p class="text-muted">Machine Learning Scientist<br />Amazon</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://www.cs.umd.edu/~shobeir/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/shobeirf" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="http://www.linkedin.com/in/shobeir" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=6vJwj_QAAAAJ"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/aude.jpg" class="img-responsive img-circle" alt="Aude Hofleitner">
                        <h4>Aude Hofleitner</h4>
                        <p class="text-muted">Research Scientist Manager<br />Facebook</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="https://research.fb.com/people/hofleitner-aude/" target="_blank"><i
                                        class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/hofleitner?lang=en" target=_blank><i
                                        class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/audehofleitner" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=w-xdg4sAAAAJ&hl=en"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/5_julian.jpg" class="img-responsive img-circle" alt="Julian McAuley">
                        <h4>Julian McAuley</h4>
                        <p class="text-muted">Associate Professor<br />University of California San Diego</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://cseweb.ucsd.edu/~jmcauley/" target="_blank"><i
                                        class="fa fa-home"></i></a>
                            </li>
                            <li><a class="inactive" href="#organization"><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/julianmcauley" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=icbo4M0AAAAJ"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/bryan.jpg" class="img-responsive img-circle" alt="Bryan Perozzi">
                        <h4>Bryan Perozzi</h4>
                        <p class="text-muted">Research Scientist<br />Google Research<br />&nbsp;</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://www.perozzi.net/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/phanein" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/bryanperozzi/" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank
                                    href="https://scholar.google.com/citations?user=rZgbMs4AAAAJ&hl=en&oi=ao"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/tim.jpg" class="img-responsive img-circle" alt="Tim Weninger">
                        <h4>Tim Weninger</h4>
                        <p class="text-muted">Associate Professor<br />University of Notre Dame</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a target=_blank href="https://www3.nd.edu/~tweninge/"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a target=_blank href="https://twitter.com/tim_weninger"><i
                                        class="fa fa-twitter"></i></a>
                            </li>
                            <li><a target=_blank href="https://www.linkedin.com/in/tim-weninger-b462277b/"><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=V1js0MUAAAAJ&hl=en"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>

                    <div class="col-md-1">
                        &nbsp;
                    </div>


                </div>
            </div>
            <div class="row" style="margin-top:60px;">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Program Committee</h2>
                    <!--h3 class="section-subheading text-muted">More will be announced soon!</h3-->
                    <div class="col-md-1">
                        &nbsp;
                    </div>
                    <div class="col-md-5 text-left">
                        <p class="large text-muted">
                            Aris Anagnostopoulos (Sapienza University of Rome) <br />
                            Ana Paula Appel (IBM Research Brazil) <br />
                            Christian Bauckhage (Fraunhofer)<br />
                            Austin Benson (Cornell University)<br />
                            Siddharth Bhatia (National University of Singapore)<br />
                            Aleksandar Bojchevski (Technical University of Munich)<br />
                            Ulf Brefeld (Leuphana Universität Lüneburg)<br />
                            Marco Bressan (Sapienza University of Rome)<br />
                            Ivan Brugere (University of Illinois at Chicago)<br />
                            Ting Chen (University of California, Los Angeles)<br />
                            Hocine Cherifi (University of Burgundy)<br />
                            Aaron Clauset (University of Colorado Boulder)<br />
                            Alessandro Epasto (Google)<br />
                            Dhivya Eswaran (Amazon)<br />
                            Yuan Fang (Singapore Management University)<br />
                            William Hamilton (Stanford University)<br />
                            Larry Holder (Washington State University)<br />
                        </p>
                    </div>
                    <div class="col-md-5 text-left">
                        <p class="large text-muted">
                            Bryan Hooi (National University of Singapore)<br />
                            Jin Kyu Kim (Facebook)<br />
                            Danai Koutra (University of Michigan)<br />
                            Stefano Leucci (University of L'Aquila)<br />
                            Jundong Li (University of Virginia)<br />
                            Fred Morstatter (University of Southern California)<br />
                            Blaz Novak (Jozef Stefan Institute)<br />
                            John Palowitch (Google)<br />
                            Evangelos Papalexakis (University of California Riverside)<br />
                            Ali Pinar (Sandia National Laboratories)<br />
                            Jan Ramon (INRIA)<br />
                            Sucheta Soundarajan (Syracuse University)<br />
                            Acar Tamersoy (NortonLifeLock Research Group)<br />
                            Hanghang Tong (University of Illinois at UC)<br />
                            Stefan Wrobel (Fraunhofer IAIS & Univ. of Bonn)<br />
                            Xin-Zeng Wu (Information Sciences Institute)<br />
                            Zhongfei Zhang (SUNY Binghamton)<br />
                        </p>
                    </div>
                    <div class="col-md-1">
                        &nbsp;
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- History Section -->
    <section id="history" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Previous Workshops</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 text-left">
                    &nbsp;
                </div>

                <div class="col-lg-6 text-left">
                    <p class="large text-muted">
                        <a href="http://www.mlgworkshop.org/2019/" target=_blank class="large text-muted">2019,
                            Anchorage, USA (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2018/" target=_blank class="large text-muted">2018, London,
                            United Kingdom (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2017/" target=_blank class="large text-muted">2017, Halifax,
                            Nova Scotia, Canada (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2016/" target=_blank class="large text-muted">2016, San
                            Francisco, USA (co-located with KDD)</a></br>
                        <a href="http://snap.stanford.edu/mlg2013/" target=_blank class="large text-muted">2013,
                            Chicago, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/events/mlg2012/" target=_blank
                            class="large text-muted">2012, Edinburgh, Scotland (co-located with ICML)</a></br>
                        <a href="http://www.cs.purdue.edu/mlg2011/" target=_blank class="large text-muted">2011, San
                            Diego, USA (co-located with KDD)</a></br>
                        <a href="http://www.cs.umd.edu/mlg2010/" target=_blank class="large text-muted">2010,
                            Washington, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/ilp-mlg-srl//" target=_blank class="large text-muted">2009,
                            Leuven, Belgium (co-located with SRL and ILP)</a></br>
                        <a href="http://research.ics.aalto.fi/events/MLG08/" target=_blank
                            class="large text-muted">2008, Helsinki, Finland (co-located with ICML)</a></br>
                        <a href="http://mlg07.dsi.unifi.it/" target=_blank class="large text-muted">2007, Firenze,
                            Italy</a></br>
                        <a href="http://www.inf.uni-konstanz.de/mlg2006/index.shtml" target=_blank
                            class="large text-muted">2006, Berlin, German (co-located with ECML and PKDD)</a></br>
                        <a href="#" class="large text-muted">2005, Porto, Portugal, October 7, 2005</a></br>
                        <a href="http://hms.liacs.nl/mgts2004/" target=_blank class="large text-muted">2004, Pisa,
                            Italy, September 24, 2004</a></br>
                        <a href="http://www.ar.sanken.osaka-u.ac.jp/MGTS-2003CFP.html" target=_blank
                            class="large text-muted">2003, Cavtat-Dubrovnik, Croatia</a></br>
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-darkest-gray">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <span class="copyright" style="color:gray;">Copyright &copy; MLG Workshop 2020</span>
                </div>
                <div class="col-md-4">
                    <ul class="list-inline social-buttons">
                        <li><a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter"></i></a>
                        </li>
                        <!--li><a href="#"><i class="fa fa-facebook"></i></a>
                        </li>
                        <li><a href="#"><i class="fa fa-linkedin"></i></a>
                        </li-->
                    </ul>
                </div>
                <!--div class="col-md-4">
                    <ul class="list-inline quicklinks">
                        <li><a href="#">Privacy Policy</a>
                        </li>
                        <li><a href="#">Terms of Use</a>
                        </li>
                    </ul>
                </div-->
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>

</body>

</html>