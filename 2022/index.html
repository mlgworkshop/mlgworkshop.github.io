<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
        content="MLG 2022, 17th International Workshop on Mining and Learning with Graphs, co-located with KDD 2022, Washington, DC, USA">
    <meta name="author" content="Shobeir Fakhraei">

    <title>MLG 2022 - 17th International Workshop on Mining and Learning with Graphs</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/agency.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet'
        type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
        .tg {
            border-collapse: collapse;
            border-spacing: 0;
            width: 520px
        }

        .tg td {
            font-family: Arial, sans-serif;
            font-size: 14px;
            padding: 12px 12px;
            border-style: solid;
            border-width: 0px;
            overflow: hidden;
            word-break: normal;
            border-top-width: 1px;
            border-bottom-width: 1px;
        }

        .tg th {
            font-family: Arial, sans-serif;
            font-size: 14px;
            font-weight: normal;
            padding: 12px 12px;
            border-style: solid;
            border-width: 0px;
            overflow: hidden;
            word-break: normal;
            border-top-width: 1px;
            border-bottom-width: 1px;
        }

        .tg .tg-lqy6 {
            text-align: right;
            vertical-align: top;
            width: 100px
        }

        .tg .tg-odj0 {
            font-weight: bold;
            background-color: #ffcb2f;
            vertical-align: top
        }

        .tg .tg-yw4l {
            vertical-align: top
        }

        .tg .tg-l2oz {
            font-weight: bold;
            text-align: right;
            vertical-align: top
        }

        .tg .tg-9hbo {
            font-weight: bold;
            vertical-align: top
        }

        .tg .tg-xr8r {
            background-color: #ffffc7;
            text-align: right;
            vertical-align: top;
            width: 100px
        }

        .tg .tg-kjho {
            background-color: #ffffc7;
            vertical-align: top
        }
    </style>


</head>

<body id="page-top" class="index">
    <!-- Google Analytics -->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-75238067-1', 'auto');
        ga('require', 'linkid');
        ga('send', 'pageview');

    </script>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse"
                    data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top"><img src="img/mlg-logo.gif"
                        style="margin:0px; padding:0px; height:30px" /></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#introduction">Intro</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#program">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#keynote">Keynotes</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#papers">Accepted Papers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#call">CFP</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#organization">Organization</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#history">History</a>
                    </li>
                    <li>
                        <a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter"
                                style="font-size:20px;"></i></a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="intro-text">
                <div class="intro-lead-in">Held in conjunction with <a href="http://www.kdd.org/kdd2022/"
                        target=_blank>KDD'22</a></br>
                    Aug 15, 2022 - Washington DC, USA</div>
                <div class="intro-heading">17th International Workshop on<br />Mining and Learning with Graphs</div>
                <a href="#program" target=_blank class="page-scroll btn btn-xl">Program</a>
            </div>
        </div>
    </header>

    <!-- Introduction Section -->
    <section id="introduction">
        <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-8 text-center">
                    <h2 class="section-heading">Introduction</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">

                <div class="row text-justify">

                    <div class="col-md-8">
                        <p class="large text-muted">
                            There is a great deal of interest in analyzing data that is best represented as a graph.
                            Examples include the WWW, social networks, biological networks, communication networks,
                            transportation networks, energy grids, and many others. These graphs are typically
                            multi-modal, multi-relational and dynamic. In the era of big data, the importance of being
                            able to effectively mine and learn from such data is growing, as more and more structured
                            and semi-structured data is becoming available. The workshop serves as a forum for
                            researchers from a variety of fields working on mining and learning from graphs to share and
                            discuss their latest findings.
                            <br />
                            There are many challenges involved in effectively mining and learning from this kind of
                            data, including:
                        </p>
                        <ul class="large text-muted">
                            <li>Understanding the different techniques applicable, including graph mining algorithms,
                                network embeddings, graphical models, latent variable models, matrix factorization
                                methods and more.</li>
                            <li>Dealing with the heterogeneity of the data.</li>
                            <li>The common need for information integration and alignment.</li>
                            <li>Handling dynamic and changing data.</li>
                            <li>Addressing each of these issues at scale.</li>
                        </ul>
                        <p class="large text-muted">
                            Traditionally, a number of subareas have contributed to this space: communities in graph
                            mining, learning from structured data, statistical relational learning, inductive logic
                            programming, and, moving beyond subdisciplines in computer science, social network analysis,
                            and, more broadly network science.
                        </p>
                    </div>

                    <div class="col-md-4 text-right">
                        <p class="large text-muted">
                            <a href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw" class="twitter-follow-button"
                                data-show-count="false">Follow @mlgworkshop</a>
                            <a class="twitter-timeline" data-lang="en" data-height="600"
                                data-chrome="nofooter; noheader; transparent" data-link-color="#FAB81E"
                                href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw"></a>
                            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                        </p>
                    </div>

                </div>
            </div>
    </section>

    <!-- Program Section -->
    <section id="program" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Schedule</h2>
                    <h3 class="section-subheading text-muted"><strong>Washington DC Convention Center - 207A</strong>
                                <br /><br />
                        -Held jointly with <a href='https://deep-learning-graphs.bitbucket.io/dlg-kdd22/'
                            target=_blank>Workshop on Deep Learning on Graphs (KDD-DLG)</a>-
                    </h3>
                </div>
            </div>

            <div class="row">
                <div class="col-lg-6 text-left">
                    <table class="tg">
                        <tr>
                            <th class="tg-odj0"></th>
                            <th class="tg-odj0">Morning Sessions</th>
                        </tr>
                        <tr>
                            <th class="tg-lqy6">8:30-8:45am</th>
                            <th class="tg-yw4l">
                                Opening Remarks</th>
                        </tr>
                        <tr>
                            <td class="tg-l2oz">8:45-9:30am<br />
                                <!--img src="img/speakers/jure.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;"-->

                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Jiawei Han<br />
                                Towards Automatic Construction of Text-Rich Information Networks from Text
                            </td>
                        </tr>
                        <tr>

                        <tr>
                            <td class="tg-xr8r">9:30-10:00am</td>
                            <td class="tg-kjho">Break and Poster Setup</td>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">10:00-10:45am<br />
                                <!--img src="img/speakers/danai.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;"-->
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Neil Shah<br />
                                Scaling up Graph Neural Networks at Snap<br/>
                            </td>
                        </tr>

                        <tr>
                            <td class="tg-lqy6">10:45-11:15am</td>
                            <td class="tg-yw4l">Contributed Talks<br/><br/>
                                Christopher Musco et al.<br/>
                                How to Quantify Polarization in Models of Opinion Dynamics<br/><br/>
                                Jiaqi Ma et al.<br/>
                                Partition-Based Active Learning for Graph Neural Networks
                                <br />
                        </tr>

                        <tr>
                            <td class="tg-l2oz">11:15-12:00pm<br />
                                <!--img src="img/speakers/jimeng_sun.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;"-->
                            </td>
                            <td class="tg-9hbo">Panel:<br />
                                Jiawei Han, Lingfei Wu, Xiaojie Guo, Neil Shah, Tim Weninger<br />
                                Learning and Reasoning on Knowledge Graphs: Graph Neural Networks vs Foundation Models</td>
                        </tr>
                        
                        </tr>
                        <td class="tg-xr8r">12:00-1:30pm</td>
                        <td class="tg-kjho">Lunch Break<br /></td>
                        </tr>

                    </table>

                </div>
                <div class="col-lg-6 text-left">
                    <table class="tg">
                        <tr>
                            <th class="tg-odj0"></th>
                            <th class="tg-odj0">Afternoon Sessions</th>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">1:30-2:15 pm<br />
                                <!--img src="img/speakers/jimeng_sun.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;"-->
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Yizhou Sun<br />
                                Combining Representation Learning and Logical Rule Reasoning for Knowledge Graph Inference</td>
                        </tr>                        

                        <tr>
                            <td class="tg-lqy6">2:15-2:45 pm</td>
                            <td class="tg-yw4l">Contributed Talks<br/><br/>
                                Yu Shi et al.<br/>
                                mvn2vec: Preservation and Collaboration in Multi-View Network Embedding<br/><br/>
                                John Palowitch et al.<br/>
                                Robust Synthetic GNN Benchmarks with GraphWorld
                                <br />
                        </tr>

                        <tr>
                            <td class="tg-xr8r">2:45-3:30 pm</td>
                            <td class="tg-kjho">Break and Poster Session</td>
                        </tr>

                        <tr>
                            <td class="tg-l2oz">3:30-4:15 pm<br />
                                <!--img src="img/speakers/tyler.jpg" class="img-responsive img-circle"
                                    style="height:50px; float: right;"-->
                            </td>
                            <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br />
                                Jennifer Neville<br />
                                Social reinforcement learning for optimizing network-level goals in multi-agent systems</td>
                        </tr>

                        <tr>
                            <th class="tg-lqy6">4:15-4:45pm</th>
                            <th class="tg-yw4l">
                                Closing Remarks</th>
                        </tr>

                    </table>
                </div>

                <div class="col-lg-3 text-left">
                    &nbsp;
                </div>
            </div>

        </div>
    </section>

    <!-- Keynote Section no abstract -->

    <section id="keynote">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Keynote Speakers</h2>
                </div>
            </div>

            <div class="row">

                <div class="col-md-3">
                    <div class="team-member">
                        <img src="img/speakers/jiawei.jpg" class="img-responsive img-circle" >
                        <h4>Jiawei Han</h4>
                        <p class="text-muted">Professor<br/>UIUC</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a target=_blank href="http://hanj.cs.illinois.edu/"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a target=_blank href="https://twitter.com/JiaweiHan"><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a target=_blank href="https://www.linkedin.com/in/jiaweih/"><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=Kv9AbjMAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>

                <div class="col-md-3">
                    <div class="team-member">
                        <img src="img/speakers/jen.jpg" class="img-responsive img-circle" alt="Jennifer Neville">
                        <h4>Jennifer Neville</h4>
                        <p class="text-muted">Senior Principal Researcher/Professor<br/>Microsoft/Purdue</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a target=_blank href="https://www.cs.purdue.edu/homes/neville/"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a target=_blank href="https://twitter.com/JenLNeville"><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a target=_blank href="https://www.linkedin.com/in/jennifer-neville-2a880b5"><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=6CTPn44AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>

                <div class="col-md-3">
                    <div class="team-member">
                        <img src="img/speakers/yizhou.jpg" class="img-responsive img-circle" alt="Yizhou Sun">
                        <h4>Yizhou Sun</h4>
                        <p class="text-muted">Associate Professor<br/>UCLA</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a target=_blank href="http://web.cs.ucla.edu/~yzsun/"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a target=_blank href="https://twitter.com/YizhouSun"><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a target=_blank href="https://www.linkedin.com/in/yizhou-sun-56109b75"><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=TQgOjK0AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>

                <div class="col-md-3">
                    <div class="team-member">
                        <img src="img/team/neil.jpg" class="img-responsive img-circle" alt="Neil Shah">
                        <h4>Neil Shah</h4>
                        <p class="text-muted">Lead Research Scientist<br />Snap Inc.</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://nshah.net/" target="_blank"><i
                                        class="fa fa-home"></i></a>
                            </li>
                            <li><a class="inactive" href="#organization"><i
                                        class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/nshah171/" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=Qut69OgAAAAJ&hl=en"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>

            </div>            

    </section>

    <!-- Accepted Papers Section -->
    <section id="papers" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Accepted Papers</h2>
                    <!--h3 class="section-subheading text-muted">
                    All accepted papers will present a poster
                    </h3-->
                </div>
            </div>
            <div class="row">

                <div class="col-lg-1 text-center">
                    &nbsp;
                </div>

                <div class="col-lg-11 text-justify">
                    <!-- Begin Paper List -->

                    <p class="large text-muted">
                        <strong>ColdGuess: A General and Effective Relational Graph Convolutional Network to Tackle Cold Start Cases</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid866">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib866">BibTex</button> 
                        <a href="papers/MLG22_paper_0866.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Bo He, Xiang Song, Christos Faloutsos and Vincent Gao</i><br/>
                        
                        <div id="pid866" class="collapse">
                        <strong>Abstract:</strong> Low-quality listings and bad actor behavior in online retail web-sites threatens e-commerce business as these result in sub-optimal buying experience and erode customer trust. When a new listing is created, how to tell it has good-quality? Is the method effective, fast, and scalable? Previous approaches often have three limitations/challenges: (1) unable to handle cold start problems where new sellers/listings lack sufficient selling histories. (2) inability of scoring hundreds of millions of listings at scale, or compromise performance for scalability. (3) has space challenges from large-scale graph with giant e-commerce business size. To overcome these limitations/challenges, we proposed ColdGuess, an inductive graph-based risk predictor built upon a heterogeneous seller-product graph, which effectively identifies risky seller/product/listings at scale. ColdGuess tackles the large-scale graph by consolidated nodes, and addresses the cold start problems using homogeneous influence1. The evaluation on real data demonstrates that ColdGuess has stable performance as the number of unknown features increases. It outperforms the lightgbm by up to 34 pcp ROC AUC in a cold start case when a new seller sells a new product.The resulting system, ColdGuess, is effective, adaptable to changing risky seller behavior, and is already in production. This paper belongs to “Application and analysis – Large-scale graph and modeling”, and in the "Novel research paper" category.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib866" class="collapse">
                        @inproceedings{mlg2022_866,<br/>
                        title={ColdGuess: A General and Effective Relational Graph Convolutional Network to Tackle Cold Start Cases},<br/>
                        author={Bo He, Xiang Song, Christos Faloutsos and Vincent Gao},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>How to Quantify Polarization in Models of Opinion Dynamics</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid1202">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib1202">BibTex</button> 
                        <a href="papers/MLG22_paper_1202.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Christopher Musco, Indu Ramesh, Johan Ugander and R. Teal Witter</i><br/>
                        
                        <div id="pid1202" class="collapse">
                        <strong>Abstract:</strong> It is widely believed that society is becoming increasingly polarized around important issues, a dynamic that does not align with common mathematical models of opinion formation in social networks. In particular, measures of polarization based on opinion variance are known to decrease over time in frameworks such as the popular DeGroot model. Complementing recent work that seeks to resolve this apparent inconsistency by modifying opinion models, we instead resolve the inconsistency by proposing changes to how polarization is quantified.
                        We present a natural class of group-based polarization measures that capture the extent to which opinions are clustered into distinct groups. Using theoretical arguments and empirical evidence, we show that these group-based measures display interesting, non-monotonic dynamics, even in the simple DeGroot model. In particular, for many natural social networks, group-based metrics can increase over time, and thereby correctly capture perceptions of increasing polarization.
                        Our results build on work by DeMarzo et al., who introduced a group-based polarization metric based on ideological alignment. We show that a central tool from that work, a limit analysis of individual opinions under the DeGroot model, can be extended to the dynamics of other group-based polarization measures, including established statistical measures like bimodality. 
                        We also consider local measures of polarization that operationalize how polarization is perceived in a network setting. In conjunction with evidence from prior work that group-based measures better align with real-world perceptions of polarization, our work provides formal support for the use of these measures in place of variance-based polarization in future studies of opinion dynamics.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib1202" class="collapse">
                        @inproceedings{mlg2022_1202,<br/>
                        title={How to Quantify Polarization in Models of Opinion Dynamics},<br/>
                        author={Christopher Musco, Indu Ramesh, Johan Ugander and R. Teal Witter},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Tailored vertex ordering for faster triangle listing in large graphs</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid1980">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib1980">BibTex</button> 
                        <a href="papers/MLG22_paper_1980.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Fabrice Lécuyer, Louis Jachiet, Clémence Magnien and Lionel Tabourier</i><br/>
                        
                        <div id="pid1980" class="collapse">
                        <strong>Abstract:</strong> Listing triangles is a fundamental graph problem with many applications, and large graphs require fast algorithms. Vertex ordering allows the orientation of edges from lower to higher vertex indices, and state-of-the-art triangle listing algorithms use this to accelerate their execution and to bound their time complexity. Yet, only two basic orderings have been tested.
                        In this paper, we show that studying the precise cost of algorithms instead of their bounded complexity leads to faster solutions. We introduce cost functions that link ordering properties with the running time of a given algorithm. We prove that their minimization is NP-hard and propose heuristics to obtain new orderings with different trade-offs between cost reduction and ordering time. 
                        Using datasets with up to two billion edges, we show that our heuristics accelerate the listing of triangles by an average of 30% when the ordering is already given as an input, and 15% when the ordering time is included.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib1980" class="collapse">
                        @inproceedings{mlg2022_1980,<br/>
                        title={Tailored vertex ordering for faster triangle listing in large graphs},<br/>
                        author={Fabrice Lécuyer, Louis Jachiet, Clémence Magnien and Lionel Tabourier},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>

                        <p class="large text-muted">
                        <strong>Knowledge-aware Neural Collective Matrix Factorization for Cross-domain Recommendation</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid9580">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib9580">BibTex</button> 
                        <a href="papers/MLG22_paper_9580.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Li Zhang, Yan Ge, Jun Ma, Jianmo Ni and Haiping Lu</i><br/>
                        
                        <div id="pid9580" class="collapse">
                        <strong>Abstract:</strong> Cross-domain recommendation (CDR) can help customers find more satisfying items in different domains. Existing CDR models mainly use common users or mapping functions as bridges between domains but have very limited exploration in fully utilizing item-item relationships across domains. In this paper, we propose the incorporation of multi-domain knowledge graph (KG) to enable items in different domains sharing knowledge even without explicit common contents. To this end, we first construct a new dataset \textit{AmazonKG4CDR} from the Freebase KG and a subset of Amazon Review Data in three domains: movies, books, and music. This new dataset facilitates linking knowledge to bridge within- and cross-domain items for CDR. Then we propose a new framework, KG-aware Neural Collective Matrix Factorization (KG-NeuCMF), leveraging KG to enrich item representations. It learns item embeddings by graph convolutional autoencoder to capture both domain-specific and domain-general knowledge from adjacent and higher-order neighbours in KG. To further improve KG-aware item embedding, we maximize the mutual information between representations learned from the KG and user-item matrix to establish cross-domain relationships for better CDR. We conduct extensive experiments on the newly constructed dataset and demonstrate that our model significantly outperforms the best-performing baselines.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib9580" class="collapse">
                        @inproceedings{mlg2022_9580,<br/>
                        title={Knowledge-aware Neural Collective Matrix Factorization for Cross-domain Recommendation},<br/>
                        author={Li Zhang, Yan Ge, Jun Ma, Jianmo Ni and Haiping Lu},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>

                        <p class="large text-muted">
                        <strong>OASYS: Domain-Agnostic Automated System for Constructing Knowledge Base from Unstructured Text</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid3178">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib3178">BibTex</button> 
                        <a href="papers/MLG22_paper_3178.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Minsang Kim, Sanghyun Je and Eunjoo Park</i><br/>
                        
                        <div id="pid3178" class="collapse">
                        <strong>Abstract:</strong> In recent years, creating and managing knowledge bases have become crucial to the retail product and enterprise domains. We present an automatic knowledge base construction system that mines data from documents. This system can generate training data during the training process without human intervention. Therefore, it is domain-agnostic trainable using only the target domain text corpus and a pre-defined knowledge base. This system is called OASYS and is the first system built with the Korean language in mind. In addition, we also have constructed a new human-annotated benchmark dataset of the Korean Wikipedia corpus paired with a Korean DBpedia to aid system evaluation. The system performance results on this human-annotated benchmark dataset are meaningful and show that the generated knowledge base from OASYS trained on only auto-generated data is useful. We provide both a human-annotated test dataset and an auto-generated dataset.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib3178" class="collapse">
                        @inproceedings{mlg2022_3178,<br/>
                        title={OASYS: Domain-Agnostic Automated System for Constructing Knowledge Base from Unstructured Text},<br/>
                        author={Minsang Kim, Sanghyun Je and Eunjoo Park},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Semi-Supervised Node Classification on Graph via Inconsistent Nodes Correction</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid3678">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib3678">BibTex</button> 
                        <a href="papers/MLG22_paper_3678.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Shuhao Shi, Jian Chen, Kai Qiao, Shuai Yang, Linyuan Wang and Bin Yan</i><br/>
                        
                        <div id="pid3678" class="collapse">
                        <strong>Abstract:</strong> This article is a work-in-progress paper. In traditional graph convolutional networks (GCNs), node feature aggregation in graph convolutional learning is guided only by topology graphs. In reality, both network topology and node features offer unique and valuable information. Using topology alone cannot obtain fully and completely accurate neighborhood information. This paper advocates a representation learning method with output correction for GCNs (OC-GCN), simultaneously using topological structure and node features information. Specifically, we use two GCN encoders to extract node embeddings in feature space and topology space. Then, determine inconsistent nodes by the pseudo-labels generated by the two models. Finally, we use the representations of consistent neighbors to regenerate representations of inconsistent nodes in feature and topology views. Our experiments have shown that the OC-GCN can significantly improve the classification accuracy of inconsistent nodes in feature and topology views. We conducted extensive experiments on the benchmark datasets and demonstrated that OC-GCN is substantially better than state-of-the-art baselines at different label rates.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib3678" class="collapse">
                        @inproceedings{mlg2022_3678,<br/>
                        title={Semi-Supervised Node Classification on Graph via Inconsistent Nodes Correction},<br/>
                        author={Shuhao Shi, Jian Chen, Kai Qiao, Shuai Yang, Linyuan Wang and Bin Yan},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Graph-Assisted Tensor Disaggregation</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid4272">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib4272">BibTex</button> 
                        <a href="papers/MLG22_paper_4272.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Mariana Duarte, Evangelos Papalexakis and Jia Chen</i><br/>
                        
                        <div id="pid4272" class="collapse">
                        <strong>Abstract:</strong> Consider a multi-aspect tensor dataset which is only observed in multiple complementary aggregated versions, each one at a lower resolution than the highest available one. Recent work has demonstrated that given two such tensors, which have been aggregated in lower resolutions in complementary dimensions, we can pose and solve the disaggregation as an instance of a coupled tensor decomposition. In this work, we are exploring the scenario in which, in addition to the two complementary aggregated views, we also have access to a graph where nodes correspond to samples of the tensor mode that has not been aggregated. Given this graph, we propose a graph-assisted tensor disaggregation method. In our experimental evaluation, we demonstrate that our proposed method performs on par with the state of the art when the rank of the underlying coupled tensor decomposition is low, and significantly outperforms the state of the art in cases where the rank increases, producing more robust and higher-quality disaggregation.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib4272" class="collapse">
                        @inproceedings{mlg2022_4272,<br/>
                        title={Graph-Assisted Tensor Disaggregation},<br/>
                        author={Mariana Duarte, Evangelos Papalexakis and Jia Chen},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Attributed Labeled BTER-Based Generative Model for Benchmarking of Graph Neural Networks</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid5068">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib5068">BibTex</button> 
                        <a href="papers/MLG22_paper_5068.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Polina Andreeva, Egor Shikov and Claudie Bocheninа</i><br/>
                        
                        <div id="pid5068" class="collapse">
                        <strong>Abstract:</strong> Graph Neural Networks (GNNs) have become increasingly popular for tasks such as link prediction, node classification, and graph generation. However, a number of models show weak performance on graphs with low assortativity measure. At the same time, other graph characteristics may also influence GNN quality. Therefore, it is extremely important for benchmark datasets to cover a wide range of different graph properties, which can not be provided by real-world sources. In this paper, we present a generative model for attributed graphs based on Block Two-Level Erdos-Renyi model. Our model allows one to vary larger number of graph structural characteristics (namely, clustering coefficient, average degree, average shortest paths length, label and attribute assortativity) in a wider range. Our attribute generative method can be applied to any other non-attributed graph generative model and allows to control attribute assortativity corresponding to structure of graph. The experimental study shows that AL-BTER outperforms ADC-SBM and GenCAT under the assumption of equal importance of desired graph characteristics and provides wider ranges for attribute assortativity and average shortest paths and outperforms LFR in terms of clustering coefficient. GNN performance analysis confirms the sensitivity of the results to all topological properties except average degree and shows that benchmark graphs provided by AL-BTER are useful to discover new regimes of performance of graph convolutional networks.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib5068" class="collapse">
                        @inproceedings{mlg2022_5068,<br/>
                        title={Attributed Labeled BTER-Based Generative Model for Benchmarking of Graph Neural Networks},<br/>
                        author={Polina Andreeva, Egor Shikov and Claudie Bocheninа},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Learning Personalized Representations using Graph Convolutional Network</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid6009">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib6009">BibTex</button> 
                        <a href="papers/MLG22_paper_6009.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Hongyu Shen, Jinoh Oh, Shuai Zhao, Guoyin Wang, Tara Taghavi and Sungjin Lee</i><br/>
                        
                        <div id="pid6009" class="collapse">
                        <strong>Abstract:</strong> Generating representations that precisely reflect customers’ behavior is an important task for providing personalized skill routing experience in Alexa. Currently, Dynamic Routing (DR) team, who is responsible for routing Alexa traffic to providers/skills, relies on two features to be served as personal signals: absolute traffic count and normalized traffic count of every skill usage per customer. Neither of them considers the network-structure for interactions between customers and skills, which contain richer information for customer preferences. In this work, we first build a heterogeneous edge-attributed graph based customers’ past interactions with the invoked skills, in which the user requests (utterances) are modeled as edges. Then we propose a graph convolutional network(GCN)-based model, namely Personalized Dynamic Routing Feature Encoder (PDRFE), that generates personalized customer representations learned from the built graph. Compared with existing models, PDRFE is able to further capture contextual information in the graph convolutional function. The performance of our proposed model is evaluated by a downstream task, defect prediction, that predicts the defect label from the learned embeddings of customers and their triggered skills. We observe up to 41\% improvements on the cross-entropy metric for our proposed models compared to the baselines.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib6009" class="collapse">
                        @inproceedings{mlg2022_6009,<br/>
                        title={Learning Personalized Representations using Graph Convolutional Network},<br/>
                        author={Hongyu Shen, Jinoh Oh, Shuai Zhao, Guoyin Wang, Tara Taghavi and Sungjin Lee},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Distance-wise Prototypical Graph Neural Network for Imbalanced Node Classification</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid6707">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib6707">BibTex</button> 
                        <a href="papers/MLG22_paper_6707.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Yu Wang, Charu Aggarwal and Tyler Derr</i><br/>
                        
                        <div id="pid6707" class="collapse">
                        <strong>Abstract:</strong> Recent years have witnessed the significant success of applying graph neural networks (GNNs) in learning effective node representations for classification. However, current GNNs are mostly built under the balanced data-splitting, which is inconsistent with real-world networks where the number of training nodes can be extremely imbalanced among the classes. Thus, directly utilizing current GNNs on imbalanced data would generate coarse representations of nodes in minority classes. This therefore portends the importance of developing effective GNNs for handling imbalanced graph data. In this work, we propose a novel Distance-wise Prototypical Graph Neural Network (DPGNN), which utilizes a class prototype-driven training to balance the training loss between majority and minority classes and then leverages distance metric learning to differentiate the contributions of different dimensions of representations and fully encode the relative position of each node to each class prototype. Moreover, we design a new imbalanced label propagation mechanism to derive extra supervision from unlabeled nodes and employ self-supervised learning to smooth representations of adjacent nodes while separating inter-class prototypes. Comprehensive node classification experiments and parameter analysis on multiple networks are conducted and the proposed DPGNN almost always significantly outperforms all other baselines. The implementation of DPGNN is available at: https://github.com/YuWVandy/DPGNN.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib6707" class="collapse">
                        @inproceedings{mlg2022_6707,<br/>
                        title={Distance-wise Prototypical Graph Neural Network for Imbalanced Node Classification},<br/>
                        author={Yu Wang, Charu Aggarwal and Tyler Derr},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Understanding Self-Supervised Graph Representation Learning from a Data-Centric Perspective</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid7168">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib7168">BibTex</button> 
                        <a href="papers/MLG22_paper_7168.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Puja Trivedi, Ekdeep Singh Lubana, Mark Heimann, Danai Koutra and Jayaraman Thiagarajan</i><br/>
                        
                        <div id="pid7168" class="collapse">
                        <strong>Abstract:</strong> Recent analyses of self-supervised representation learning (SSL) find the following data-centric properties to be critical for learning high-quality representations: invariance to task-irrelevant semantics, separability of classes in some latent space, and recoverability of labels from augmented samples. However, given their discrete, non-Euclidean nature, graph datasets and graph SSL methods are unlikely to satisfy these properties. This raises the question: how do graph SSL methods work well? To systematically probe this question, we perform a generalization analysis for GGA based on dataset recoverability and separability constraints, yielding insights into task-relevance of data augmentations. As we empirically show, popularly used, generic graph augmentations (GGA) do not induce task-relevant invariances on common benchmark datasets, leading to only marginal gains over naive, untrained baselines. Our theory motivates a synthetic data generation process that enables control over both augmentation recoverability and dataset separability, enabling a better benchmark for evaluation of graph URL methods that demonstrates different training paradigms are effective in different regimes. Overall, our work rigorously contextualizes, both empirically and theoretically, the effects of data-centric properties on augmentation strategies and learning paradigms for graph SSL.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib7168" class="collapse">
                        @inproceedings{mlg2022_7168,<br/>
                        title={Understanding Self-Supervised Graph Representation Learning from a Data-Centric Perspective},<br/>
                        author={Puja Trivedi, Ekdeep Singh Lubana, Mark Heimann, Danai Koutra and Jayaraman Thiagarajan},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Coarsen, Align, Project, Refine - A General Multilevel Framework for Network Alignment</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid7903">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib7903">BibTex</button> 
                        <a href="papers/MLG22_paper_7903.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Jing Zhu, Danai Koutra and Mark Heimann</i><br/>
                        
                        <div id="pid7903" class="collapse">
                        <strong>Abstract:</strong> Network alignment, or the task of finding corresponding nodes in different networks, is an important problem formulation in many application domains. We propose CAPER, a multilevel alignment framework that coarsens the input graphs, aligns the coarsened graphs, projects the alignment solution to finer levels and refines the alignment solution. We show that CAPER can improve upon many different existing network alignment algorithms by enforcing alignment consistency across multiple graph resolutions: nodes matched at finer levels should also be matched at coarser levels. CAPER also accelerates the use of slower network alignment methods, at the modest cost of linear-time coarsening and refinement steps, by allowing them to be run on smaller coarsened versions of the input graphs. Experiments show that CAPER can improve upon diverse network alignment methods by an average of 33% in accuracy and/or anorder of magnitude faster in runtime.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib7903" class="collapse">
                        @inproceedings{mlg2022_7903,<br/>
                        title={Coarsen, Align, Project, Refine - A General Multilevel Framework for Network Alignment},<br/>
                        author={Jing Zhu, Danai Koutra and Mark Heimann},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Fast and Efficient n-Metrics for Multiple Graphs</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid8073">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib8073">BibTex</button> 
                        <a href="papers/MLG22_paper_8073.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Kimia Shayestehfard, Dana Brooks and Stratis Ioannidis</i><br/>
                        
                        <div id="pid8073" class="collapse">
                        <strong>Abstract:</strong> Graphs are widely used in diverse areas such as chemistry, engineering and network science to express relations among a set of objects. In all these fields, measuring the similarity among a group of graphs or indicating the correspondence among their nodes is of great importance. Many of the algorithms introduced for this purpose are not metrics and the few graph distance functions that do satisfy the properties of a metric are extremely slow to compute. In this work, we propose a fast and efficient framework to compute the distance among a group of graphs. Our method can improve the computation time up to 20 times over existing methods.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib8073" class="collapse">
                        @inproceedings{mlg2022_8073,<br/>
                        title={Fast and Efficient n-Metrics for Multiple Graphs},<br/>
                        author={Kimia Shayestehfard, Dana Brooks and Stratis Ioannidis},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>Ethereum Fraud Detection with Heterogeneous Graph Neural Networks</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid8513">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib8513">BibTex</button> 
                        <a href="papers/MLG22_paper_8513.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Hiroki Kanezashi, Toyotaro Suzumura, Xin Liu and Takahiro Hirofuchi</i><br/>
                        
                        <div id="pid8513" class="collapse">
                        <strong>Abstract:</strong> While transactions with cryptocurrencies such as Ethereum are becoming more prevalent, fraud and other criminal transactions are not uncommon. Graph analysis algorithms and machine learning techniques detect suspicious transactions that lead to phishing in large transaction networks. Many graph neural network (GNN) models have been proposed to apply deep learning techniques to graph structures. Although there is research on phishing detection using GNN models in the Ethereum transaction network, models that address the scale of the number of vertices and edges and the imbalance of labels have not yet been studied. In this paper, we compared the model performance of GNN models on the actual Ethereum transaction network dataset and phishing reported label data to exhaustively compare and verify which GNN models and hyperparameters produce the best accuracy. Specifically, we evaluated the model performance of representative homogeneous GNN models which consider single-type nodes and edges and heterogeneous GNN models which support different types of nodes and edges. We showed that heterogeneous models had better model performance than homogeneous models. In particular, the RGCN model achieved the best performance in the overall metrics.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib8513" class="collapse">
                        @inproceedings{mlg2022_8513,<br/>
                        title={Ethereum Fraud Detection with Heterogeneous Graph Neural Networks},<br/>
                        author={Hiroki Kanezashi, Toyotaro Suzumura, Xin Liu and Takahiro Hirofuchi},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>
                        
                        <p class="large text-muted">
                        <strong>mvn2vec: Preservation and Collaboration in Multi-View Network Embedding</strong> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid9224">Abstract</button> 
                        <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib9224">BibTex</button> 
                        <a href="papers/MLG22_paper_9224.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                        <br/>
                        <i>Yu Shi, Fangqiu Han, Xinwei He, Xinran He, Carl Yang, Luo Jie and Jiawei Han</i><br/>
                        
                        <div id="pid9224" class="collapse">
                        <strong>Abstract:</strong> Multi-view networks are broadly present in real-world applications. In the meantime, network embedding has emerged as an effective representation learning approach for networked data. Therefore, we are motivated to study the problem of multi-view network embedding with a focus on the optimization objectives that are specific and important in embedding this type of networks. In our practice of embedding real-world multi-view networks, we explicitly identify two such objectives, which we refer to as preservation and collaboration. The in-depth analysis of these two objectives are discussed throughout this paper. In addition, the novel mvn2vec algorithms are proposed to (i) study how varied extent of preservation and collaboration can impact embedding learning and (ii) explore the feasibility of achieving better embedding quality by modeling them simultaneously. With experiments on a large-scale internal Snapchat dataset, two public datasets and a series of synthetic datasets, we confirm the validity and importance of preservation and collaboration as two objectives for multi-view network embedding. These experiments further demonstrate that better embedding can be obtained by simultaneously modeling the two objectives, while not over-complicating the model or requiring additional supervision. The code and the processed datasets are available at https://yu-shi-homepage.github.io/.
                        <br/>
                        <hr/>
                        </div>
                        
                        <div id="bib9224" class="collapse">
                        @inproceedings{mlg2022_9224,<br/>
                        title={mvn2vec: Preservation and Collaboration in Multi-View Network Embedding},<br/>
                        author={Yu Shi, Fangqiu Han, Xinwei He, Xinran He, Carl Yang, Luo Jie and Jiawei Han},<br/>
                        booktitle={Proceedings of the 17th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                        year={2022}<br/>
                        }
                        <hr/>
                        </div>
                        
                        </p>                        
                    
                    <!-- End Paper List -->
                </div>
            </div>
        </div>
    </section>                    

    <!-- Call for Papers Section -->
    <section id="call">
        <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Call for Papers</h2>
                    <!--h3 class="section-subheading text-muted">Will be announced soon!</h3-->
                </div>
                <div class="row text-justify">
                    <div class="col-md-12">
                        <p class="large text-muted">
                            This workshop is a forum for exchanging ideas and methods for mining and learning with graphs, developing new common understandings of the problems at hand, sharing of data sets where applicable, and leveraging existing knowledge from different disciplines. The goal is to bring together researchers from academia, industry, and government, to create a forum for discussing recent advances in graph analysis. In doing so, we aim to better understand the overarching principles and the limitations of our current methods and to inspire research on new algorithms and techniques for mining and learning with graphs.
                        </p>
                        <p class="large text-muted">
                            To reflect the broad scope of work on mining and learning with graphs, we encourage submissions that span the spectrum from theoretical analysis to algorithms and implementation, to applications, empirical studies and reflection papers. As an example, the growth of user-generated content on blogs, microblogs, discussion forums, product reviews, etc., has given rise to a host of new opportunities for graph mining in the analysis of social media. More recently, the advent of neural methods for learning graph representations has spurred numerous works in embedding network entities for diverse applications including ranking and retrieval, traffic routing and drug-discovery.  We encourage submissions on theory, methods, and applications focusing on a broad range of graph-based approaches in various domains.
                        </p>
                        <p class="large text-muted">
                            Topics of interest include, but are not limited to:
                        </p>

                        <ul class="large text-muted">
                            <li><b>Theoretical aspects:</b>
                                <ul class="large text-muted">
                                    <li>Computational or statistical learning theory related to graphs</li>
                                    <li>Theoretical analysis of graph algorithms or models</li>
                                    <li>Sampling and evaluation issues in graph algorithms</li>
                                    <li>Analysis of dynamic graphs</li>
                                </ul>
                            </li>
                            <li><b>Algorithms and methods:</b>
                                <ul class="large text-muted">
                                    <li>Graph mining</li>
                                    <li>Probabilistic and graphical models for structured data</li>
                                    <li>Heterogeneous/multi-model graph analysis</li>
                                    <li>Graph neural networks and graph representation learning</li>
                                    <li>Statistical models of graph structure</li>
                                    <li>Combinatorial graph methods</li>
                                    <li>Semi-supervised learning, active learning, transductive inference, and transfer
                                        learning in the context of graph</li>
                                </ul>
                            </li>
                            <li><b>Applications and analysis:</b>
                                <ul class="large text-muted">
                                    <li>Analysis of social media</li>
                                    <li>Analysis of biological networks</li>
                                    <li>Knowledge graph construction</li>
                                    <li>Large-scale analysis and modeling</li>
                                </ul>
                            </li>
                        </ul>

                        <p class="large text-muted">
                            We welcome many kinds of papers, such as, but not limited to:
                        </p>

                        <ul class="large text-muted">
                            <li>Novel research papers
                            </li>
                            <li>Demo papers
                            </li>
                            <li>Work-in-progress papers
                            </li>
                            <li>Visionary papers (white papers)
                            </li>
                            <li>Appraisal papers of existing methods and tools (e.g., lessons learned)
                            </li>
                            <li>Evaluatory papers which revisit validity of domain assumptions
                            </li>
                            <li>Relevant work that has been previously published
                            </li>
                            <li>Work that will be presented at the main conference
                            </li>
                        </ul>

                        <p class="large text-muted">
                            Authors should <strong>clearly indicate</strong> in their abstracts the kinds of submissions
                            that the papers belong to, to help reviewers better understand their contributions. <br />
                            All papers will be peer reviewed, single-blinded.
                            Submissions must be in PDF, <strong>no more than 8 pages long</strong> — shorter papers are
                            welcome — and formatted according to the standard double-column <a
                                href="http://www.acm.org/publications/proceedings-template#aL2" target=_blank>ACM
                                Proceedings Style</a>. <br />
                            The accepted papers will be published on the workshop’s website and will not be considered
                            archival for resubmission purposes. <br />
                            Authors whose papers are accepted to the workshop will have the opportunity to participate
                            in a spotlight and poster session, and some set will also be chosen for oral presentation.

                        </p>

                        <p class="large text-muted">
                            <strong>For paper submission, please proceed to the <a
                                    href="https://easychair.org/conferences/?conf=mlg22" target=_blank>submission
                                    website</a>.</strong>
                        </p>

                        <p class="large text-muted">
                            <strong>Please send enquiries to chair@mlgworkshop.org.</strong>
                        </p>

                        <p class="large text-muted">
                            To receive updates about the current and future workshops and the Graph Mining community,
                            please join the <a href="https://groups.google.com/d/forum/mlg-list" target=_blank>Mailing
                                List</a>, or follow the <a href="https://twitter.com/mlgworkshop" target=_blank>Twitter
                                Account</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Dates Section -->
    <section id="dates" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Important Dates</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 text-left">
                    &nbsp;
                </div>
                <div class="col-lg-6 text-left">
                    <div class="col-md-12">
                        <p class="large text-muted">
                            <b>Paper Submission Deadline:</b> May 26, 2022
                        </p>
                        <p class="large text-muted">
                            <b>Author Notification:</b> June 20, 2022
                        </p>
                        <p class="large text-muted">
                            <b>Camera Ready:</b> July 9, 2022
                        </p>
                        <p class="large text-muted">
                            <b>Workshop:</b> August 15, 2022
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Organization Section -->
    <section id="organization">
        <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Workshop Organizers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/shobeir.jpg" class="img-responsive img-circle" alt="Shobeir Fakhraei">
                        <h4>Shobeir Fakhraei</h4>
                        <p class="text-muted">Senior Applied Scientist<br />Amazon</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://www.cs.umd.edu/~shobeir/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/shobeirf" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="http://www.linkedin.com/in/shobeir" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=6vJwj_QAAAAJ"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/tim.jpg" class="img-responsive img-circle" alt="Tim Weninger">
                        <h4>Tim Weninger</h4>
                        <p class="text-muted">Associate Professor<br />Uni. of Notre Dame</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a target=_blank href="https://www3.nd.edu/~tweninge/"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a target=_blank href="https://twitter.com/tim_weninger"><i
                                        class="fa fa-twitter"></i></a>
                            </li>
                            <li><a target=_blank href="https://www.linkedin.com/in/tim-weninger-b462277b/"><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=V1js0MUAAAAJ&hl=en"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>    
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/neil.jpg" class="img-responsive img-circle" alt="Neil Shah">
                        <h4>Neil Shah</h4>
                        <p class="text-muted">Lead Research Scientist<br />Snap Inc.</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://nshah.net/" target="_blank"><i
                                        class="fa fa-home"></i></a>
                            </li>
                            <li><a class="inactive" href="#organization"><i
                                        class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/nshah171/" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=Qut69OgAAAAJ&hl=en"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/sami.png" class="img-responsive img-circle" alt="Sami Abu-el-haija">
                        <h4>Sami Abu-el-haija</h4>
                        <p class="text-muted">Senior Scientist<br />Google Research</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://sami.haija.org/" target="_blank"><i
                                        class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/haijasami" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/samihaija/" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=t80qlTcAAAAJ&hl=en"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/Saurabh.jpeg" class="img-responsive img-circle" alt="Saurabh Verma">
                        <h4>Saurabh Verma</h4>
                        <p class="text-muted">Research Scientist<br />Meta Research</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="https://research.facebook.com/people/verma-saurabh/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a class="inactive"  href="#organization"><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/saurabh-verma-10076544/" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank
                                    href="https://scholar.google.com/citations?user=mUsHoggAAAAJ&hl=en"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/tara.jpg" class="img-responsive img-circle" alt="Tara Safavi">
                        <h4>Tara Safavi</h4>
                        <p class="text-muted">Research Scientist<br />Microsoft Research</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="https://tsafavi.github.io/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/tararootcake?lang=en" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/tsafavi/" target=_blank><i
                                        class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank
                                    href="https://scholar.google.com/citations?hl=en&user=bIWFjekAAAAJ"><i
                                        class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>

                </div>
            </div>
            <div class="row" style="margin-top:60px;">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Program Committee</h2>
                    <!--h3 class="section-subheading text-muted">More will be announced soon!</h3-->
                    <div class="col-md-1">
                        &nbsp;
                    </div>
                    <div class="col-md-5 text-left">
                        <p class="large text-muted">
                            Ana Paula Appel (IBM Research Brazil)<br />
                            David Arbour (Adobe)<br />
                            Ulf Brefeld (Leuphana Universität Lüneburg)<br />
                            Marco Bressan (University of Milan)<br />
                            Ivan Brugere (University of Illinois at Chicago)<br />
                            Hocine Cherifi (University of Burgundy)<br />
                            Tyler Derr (Vanderbilt University)<br />
                            Alessandro Epasto (Google)<br />
                            David Gleich (Purdue University)<br />
                            Stratis Ioannidis (Northeastern University)<br />
                            Noah Lee (Facebook)<br />
                            Jundong Li (University of Virginia)<br />
                        </p>
                    </div>
                    <div class="col-md-5 text-left">
                        <p class="large text-muted">
                            Yozen Liu (University of Southern California)<br />
                            John Palowitch (Google)<br />
                            Evangelos Papalexakis (University of California Riverside)<br />
                            Ali Pinar (Sandia National Laboratories)<br />
                            Jan Ramon (INRIA)<br />
                            Bhavtosh Rath (University of Minnesota -Twin Cities)<br />
                            Sucheta Soundarajan (Syracuse University)<br />
                            Stefan Wrobel (Fraunhofer IAIS & Univ. of Bonn)<br />
                            Shichang Zhang (University of California, Los Angeles)<br />
                            Lingxiao Zhao (Carnegie Mellon University)<br />
                            Tong Zhao (Snap Inc.)<br />
                        </p>    
                    </div>
                    <div class="col-md-1">
                        &nbsp;
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- History Section -->
    <section id="history" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Previous Workshops</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 text-left">
                    &nbsp;
                </div>

                <div class="col-lg-6 text-left">
                    <p class="large text-muted">
                        <a href="http://www.mlgworkshop.org/2020/" target=_blank class="large text-muted">2020,
                            Virtual (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2019/" target=_blank class="large text-muted">2019,
                            Anchorage, USA (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2018/" target=_blank class="large text-muted">2018, London,
                            United Kingdom (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2017/" target=_blank class="large text-muted">2017, Halifax,
                            Nova Scotia, Canada (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2016/" target=_blank class="large text-muted">2016, San
                            Francisco, USA (co-located with KDD)</a></br>
                        <a href="http://snap.stanford.edu/mlg2013/" target=_blank class="large text-muted">2013,
                            Chicago, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/events/mlg2012/" target=_blank
                            class="large text-muted">2012, Edinburgh, Scotland (co-located with ICML)</a></br>
                        <a href="http://www.cs.purdue.edu/mlg2011/" target=_blank class="large text-muted">2011, San
                            Diego, USA (co-located with KDD)</a></br>
                        <a href="http://www.cs.umd.edu/mlg2010/" target=_blank class="large text-muted">2010,
                            Washington, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/ilp-mlg-srl//" target=_blank class="large text-muted">2009,
                            Leuven, Belgium (co-located with SRL and ILP)</a></br>
                        <a href="http://research.ics.aalto.fi/events/MLG08/" target=_blank
                            class="large text-muted">2008, Helsinki, Finland (co-located with ICML)</a></br>
                        <a href="http://mlg07.dsi.unifi.it/" target=_blank class="large text-muted">2007, Firenze,
                            Italy</a></br>
                        <a href="http://www.inf.uni-konstanz.de/mlg2006/index.shtml" target=_blank
                            class="large text-muted">2006, Berlin, German (co-located with ECML and PKDD)</a></br>
                        <a href="#" class="large text-muted">2005, Porto, Portugal, October 7, 2005</a></br>
                        <a href="http://hms.liacs.nl/mgts2004/" target=_blank class="large text-muted">2004, Pisa,
                            Italy, September 24, 2004</a></br>
                        <a href="http://www.ar.sanken.osaka-u.ac.jp/MGTS-2003CFP.html" target=_blank
                            class="large text-muted">2003, Cavtat-Dubrovnik, Croatia</a></br>
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-darkest-gray">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <span class="copyright" style="color:gray;">Copyright &copy; MLG Workshop 2022</span>
                </div>
                <div class="col-md-4">
                    <ul class="list-inline social-buttons">
                        <li><a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter"></i></a>
                        </li>
                        <!--li><a href="#"><i class="fa fa-facebook"></i></a>
                        </li>
                        <li><a href="#"><i class="fa fa-linkedin"></i></a>
                        </li-->
                    </ul>
                </div>
                <!--div class="col-md-4">
                    <ul class="list-inline quicklinks">
                        <li><a href="#">Privacy Policy</a>
                        </li>
                        <li><a href="#">Terms of Use</a>
                        </li>
                    </ul>
                </div-->
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>

</body>

</html>