{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('/Users/shobeir/Downloads/MLG @ KDD 2023_data_EasyChair_2023-08-03/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>submitted</th>\n",
       "      <th>last updated</th>\n",
       "      <th>form fields</th>\n",
       "      <th>keywords</th>\n",
       "      <th>decision</th>\n",
       "      <th>notified</th>\n",
       "      <th>reviews sent</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Generalized Gromov Wasserstein Distance for Se...</td>\n",
       "      <td>Mengzhen Li and Mehmet Koyuturk</td>\n",
       "      <td>2023-05-22 15:56</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gromov-Wasserstein Distance\\nOptimal Transport...</td>\n",
       "      <td>reject</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Network alignment is a commonly encountered pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Sampling using Locality Sensitive Hashing...</td>\n",
       "      <td>Sarath Shekkizhar, Neslihan Bulut, Mohamed Far...</td>\n",
       "      <td>2023-05-23 10:45</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sampling\\nGraph learning\\nLocality sensitive h...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>An important step in graph-based data analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SpotTarget: Rethinking the Effect of Target Ed...</td>\n",
       "      <td>Jing Zhu, Yuhang Zhou, Vassilis Ioannidis, She...</td>\n",
       "      <td>2023-05-24 20:31</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Link Prediction\\nGraph Neural Network\\nOverfit...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Graph Neural Networks (GNNs) have demonstrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A Heterogeneous Graph-based Framework for Scal...</td>\n",
       "      <td>Phanindra Reddy Madduru and Naveed Janvekar</td>\n",
       "      <td>2023-05-24 21:54</td>\n",
       "      <td>2023-07-08 01:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graph Neural Networks\\nHeterogeneous Relationa...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>The rise of online marketplaces has led to inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Graph Model Explainer Tool</td>\n",
       "      <td>Yudi Zhang, Phanindra Reddy Madduru, Naveed Ja...</td>\n",
       "      <td>2023-05-24 22:43</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GNN\\nGNNExplainer\\nVisualization</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Graph Neural Networks (GNNs) have gained popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Multi-Task Learning on Heterogeneous Graph Neu...</td>\n",
       "      <td>Tianchen Zhou, Michinari Momma, Chaosheng Dong...</td>\n",
       "      <td>2023-05-28 15:10</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online shopping\\nRecommendation\\nGraph Neural ...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Substitute recommendation in e-commerce has at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Editable Graph Neural Network for Node Classif...</td>\n",
       "      <td>Zirui Liu, Zhimeng Jiang, Shaochen Zhong, Kaix...</td>\n",
       "      <td>2023-05-29 04:16</td>\n",
       "      <td>2023-07-13 21:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graph neural networks\\nEditable training\\nNode...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Despite Graph Neural Networks (GNNs) have achi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Computation of Node Distances on Hypergraphs</td>\n",
       "      <td>Enzhi Li and Bilal Fadlallah</td>\n",
       "      <td>2023-05-29 19:39</td>\n",
       "      <td>2023-07-19 06:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graph algorithm\\nStochastic process\\nMachine l...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>A hypergraph is a generalization of a graph th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Active Learning for Graphs with Noisy Structures</td>\n",
       "      <td>Hongliang Chi, Cong Qi, Suhang Wang and Yao Ma</td>\n",
       "      <td>2023-05-29 22:35</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graph Neural Networks\\nActive Learning\\nNoisy ...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Graph Neural Networks (GNNs) have seen signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Completing Taxonomies with Relation-Aware Mutu...</td>\n",
       "      <td>Qingkai Zeng, Zhihan Zhang, Jinfeng Lin and Me...</td>\n",
       "      <td>2023-05-30 05:22</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taxonomy completion\\nmutual attention\\nconcept...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Taxonomies serve many applications with a stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>GraphBoost: Adaptive Boosting Node Generation ...</td>\n",
       "      <td>Yuhe Gao, Sheng Zhang and Rui Song</td>\n",
       "      <td>2023-05-30 06:12</td>\n",
       "      <td>2023-05-31 03:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imbalanced Graph\\nGraph Neural Network\\nGenera...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Classification in imbalanced data, where the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>ByteGAP: A Non-continuous Distributed Graph Co...</td>\n",
       "      <td>Miaomiao Cheng, Jiujian Chen, Liang Qin, Hexia...</td>\n",
       "      <td>2023-05-30 06:20</td>\n",
       "      <td>2023-05-30 10:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graph\\ngraph Computing System\\ncheckpoint</td>\n",
       "      <td>reject</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Graph computing systems play a critical role i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Topological Representation Learning for E-comm...</td>\n",
       "      <td>Yankai Chen, Quoc-Tuan Truong, Xin Shen, Ming ...</td>\n",
       "      <td>2023-05-30 11:49</td>\n",
       "      <td>2023-05-31 18:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Topological Representation Learning\\nShopping ...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Learning compact representation from customer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>DyG2Vec: Representation Learning for Dynamic G...</td>\n",
       "      <td>Mohammad Ali Alomrani, Mahdi Biparva, Yingxue ...</td>\n",
       "      <td>2023-05-30 12:10</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dynamic graphs\\ngraph neural networks\\nself-su...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Temporal graph neural networks have shown prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>FiGURe: Simple and Efficient Unsupervised Node...</td>\n",
       "      <td>Chanakya Ekbote, Ajinkya P. Deshpande, Arun Iy...</td>\n",
       "      <td>2023-05-30 14:01</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graph neural networks\\ncontrastive learning\\nk...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Unsupervised node representations learnt using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>GEANN: Scalable Graph Augmentations for Multi-...</td>\n",
       "      <td>Sitan Yang, Malcolm Wolff, Shankar Ramasubrama...</td>\n",
       "      <td>2023-05-30 14:28</td>\n",
       "      <td>2023-05-31 13:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Time Series\\nMulti-Horizon Forecasting\\nGraph ...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Encoder-decoder deep neural networks have been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Seq-HyGAN: Sequence Classification via Hypergr...</td>\n",
       "      <td>Khaled Mohammed Saifuddin, Corey May, Farhan T...</td>\n",
       "      <td>2023-05-30 23:19</td>\n",
       "      <td>2023-05-31 16:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hypergraph attention network\\nSequence learnin...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Extracting meaningful features from sequences ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Seller Graph Model</td>\n",
       "      <td>Weilian Zhou, Shirley Zhang, Xiang Song and Vi...</td>\n",
       "      <td>2023-05-31 00:01</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graph Neural Networks\\nRelational Graph Attent...</td>\n",
       "      <td>reject</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>E-commerce stores seek to provide a high-quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>A Large Scale Synthetic Graph Dataset Generati...</td>\n",
       "      <td>Sajad Darabi, Piotr Bigaj, Dawid Majchrowski, ...</td>\n",
       "      <td>2023-05-31 00:54</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large Scale Dataset\\nGraphs\\nSynthetic Data\\nG...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Recently there has been increasing interest in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>UGGS: A Unified Graph Generation Framework Bas...</td>\n",
       "      <td>Sajad Ramezani and Soroor Motie</td>\n",
       "      <td>2023-05-31 01:07</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graph generative models\\ngraph neural network\\...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Deep learning on graphs has gained interest in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Topology-guided Hypergraph Transformer Network...</td>\n",
       "      <td>Khaled Mohammed Saifuddin and Esra Akbas</td>\n",
       "      <td>2023-05-31 02:11</td>\n",
       "      <td>2023-05-31 16:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hypergraph Transformer Network\\nHypergraph Neu...</td>\n",
       "      <td>reject</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>In recent years, hypergraphs have attracted co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Fair Online Dating Recommendations for Sexuall...</td>\n",
       "      <td>Yuying Zhao, Yu Wang, Yi Zhang, Pamela Wisniew...</td>\n",
       "      <td>2023-05-31 04:27</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair Recommendations\\nOnline Dating Networks\\n...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Novel research paper:\\r\\nOnline dating platfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Effect of Deception in Influence Maximization ...</td>\n",
       "      <td>Mehmet Aktas, Esra Akbas, Ashley Hahn and Mehm...</td>\n",
       "      <td>2023-05-31 04:49</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>information diffusion\\nsheaf Laplacian\\ninflue...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>In the contemporary era of social media and on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Compact Interpretable Tensor Graph Multi-Modal...</td>\n",
       "      <td>Dawon Ahn, William Shiao, Andrew Bauer, Arinda...</td>\n",
       "      <td>2023-05-31 04:54</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tensor decomposition\\nMulti-modal tensor graph...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Online news articles encompass a variety of mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Towards Aligned Canonical Correlation Analysis...</td>\n",
       "      <td>Biqian Cheng, Evangelos Papalexakis and Jia Chen</td>\n",
       "      <td>2023-05-31 05:33</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canonical Correlation Analysis\\nAlignment\\nMat...</td>\n",
       "      <td>reject</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Canonical Correlation Analysis (CCA) has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Semi-Supervised Embedding of Attributed Multip...</td>\n",
       "      <td>Ylli Sadikaj, Justus Rass, Yllka Velaj and Cla...</td>\n",
       "      <td>2023-05-31 06:47</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Network Embedding\\nMultiplex Networks\\nAttribu...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Complex information can be represented as netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Spectral Clustering of Attributed Multi-relati...</td>\n",
       "      <td>Ylli Sadikaj, Yllka Velaj, Sahar Behzadi and C...</td>\n",
       "      <td>2023-05-31 06:54</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graph embedding\\nSpectral clustering\\nMulti-re...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Graph clustering aims at discovering a natural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Predictive Self-Supervised Learning on Dynamic...</td>\n",
       "      <td>Raika Karimi, Mahdi Biparva, Mohammad Ali Alom...</td>\n",
       "      <td>2023-05-31 11:26</td>\n",
       "      <td>1970-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self-supervised learning\\ndynamic graphs\\ngrap...</td>\n",
       "      <td>reject</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Recently, Self-Supervised Learning (SSL) has d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>From random-walks to graph-sprints: a low-late...</td>\n",
       "      <td>Ahmad Naser Eddin, Jacopo Bono, David Aparício...</td>\n",
       "      <td>2023-05-31 11:58</td>\n",
       "      <td>2023-08-02 16:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Continuous-time dynamic graphs (CTDGs)\\nStream...</td>\n",
       "      <td>accept</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Many real-world datasets have an underlying dy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #                                              title  \\\n",
       "0    1  Generalized Gromov Wasserstein Distance for Se...   \n",
       "1    2  Data Sampling using Locality Sensitive Hashing...   \n",
       "2    3  SpotTarget: Rethinking the Effect of Target Ed...   \n",
       "3    4  A Heterogeneous Graph-based Framework for Scal...   \n",
       "4    5                         Graph Model Explainer Tool   \n",
       "5    6  Multi-Task Learning on Heterogeneous Graph Neu...   \n",
       "6    7  Editable Graph Neural Network for Node Classif...   \n",
       "7    8       Computation of Node Distances on Hypergraphs   \n",
       "8    9   Active Learning for Graphs with Noisy Structures   \n",
       "9   10  Completing Taxonomies with Relation-Aware Mutu...   \n",
       "10  11  GraphBoost: Adaptive Boosting Node Generation ...   \n",
       "11  12  ByteGAP: A Non-continuous Distributed Graph Co...   \n",
       "12  13  Topological Representation Learning for E-comm...   \n",
       "13  14  DyG2Vec: Representation Learning for Dynamic G...   \n",
       "14  15  FiGURe: Simple and Efficient Unsupervised Node...   \n",
       "15  16  GEANN: Scalable Graph Augmentations for Multi-...   \n",
       "16  17  Seq-HyGAN: Sequence Classification via Hypergr...   \n",
       "17  18                                 Seller Graph Model   \n",
       "18  19  A Large Scale Synthetic Graph Dataset Generati...   \n",
       "19  20  UGGS: A Unified Graph Generation Framework Bas...   \n",
       "20  21  Topology-guided Hypergraph Transformer Network...   \n",
       "21  22  Fair Online Dating Recommendations for Sexuall...   \n",
       "22  23  Effect of Deception in Influence Maximization ...   \n",
       "23  24  Compact Interpretable Tensor Graph Multi-Modal...   \n",
       "24  25  Towards Aligned Canonical Correlation Analysis...   \n",
       "25  26  Semi-Supervised Embedding of Attributed Multip...   \n",
       "26  27  Spectral Clustering of Attributed Multi-relati...   \n",
       "27  28  Predictive Self-Supervised Learning on Dynamic...   \n",
       "28  29  From random-walks to graph-sprints: a low-late...   \n",
       "\n",
       "                                              authors         submitted  \\\n",
       "0                     Mengzhen Li and Mehmet Koyuturk  2023-05-22 15:56   \n",
       "1   Sarath Shekkizhar, Neslihan Bulut, Mohamed Far...  2023-05-23 10:45   \n",
       "2   Jing Zhu, Yuhang Zhou, Vassilis Ioannidis, She...  2023-05-24 20:31   \n",
       "3         Phanindra Reddy Madduru and Naveed Janvekar  2023-05-24 21:54   \n",
       "4   Yudi Zhang, Phanindra Reddy Madduru, Naveed Ja...  2023-05-24 22:43   \n",
       "5   Tianchen Zhou, Michinari Momma, Chaosheng Dong...  2023-05-28 15:10   \n",
       "6   Zirui Liu, Zhimeng Jiang, Shaochen Zhong, Kaix...  2023-05-29 04:16   \n",
       "7                        Enzhi Li and Bilal Fadlallah  2023-05-29 19:39   \n",
       "8      Hongliang Chi, Cong Qi, Suhang Wang and Yao Ma  2023-05-29 22:35   \n",
       "9   Qingkai Zeng, Zhihan Zhang, Jinfeng Lin and Me...  2023-05-30 05:22   \n",
       "10                 Yuhe Gao, Sheng Zhang and Rui Song  2023-05-30 06:12   \n",
       "11  Miaomiao Cheng, Jiujian Chen, Liang Qin, Hexia...  2023-05-30 06:20   \n",
       "12  Yankai Chen, Quoc-Tuan Truong, Xin Shen, Ming ...  2023-05-30 11:49   \n",
       "13  Mohammad Ali Alomrani, Mahdi Biparva, Yingxue ...  2023-05-30 12:10   \n",
       "14  Chanakya Ekbote, Ajinkya P. Deshpande, Arun Iy...  2023-05-30 14:01   \n",
       "15  Sitan Yang, Malcolm Wolff, Shankar Ramasubrama...  2023-05-30 14:28   \n",
       "16  Khaled Mohammed Saifuddin, Corey May, Farhan T...  2023-05-30 23:19   \n",
       "17  Weilian Zhou, Shirley Zhang, Xiang Song and Vi...  2023-05-31 00:01   \n",
       "18  Sajad Darabi, Piotr Bigaj, Dawid Majchrowski, ...  2023-05-31 00:54   \n",
       "19                    Sajad Ramezani and Soroor Motie  2023-05-31 01:07   \n",
       "20           Khaled Mohammed Saifuddin and Esra Akbas  2023-05-31 02:11   \n",
       "21  Yuying Zhao, Yu Wang, Yi Zhang, Pamela Wisniew...  2023-05-31 04:27   \n",
       "22  Mehmet Aktas, Esra Akbas, Ashley Hahn and Mehm...  2023-05-31 04:49   \n",
       "23  Dawon Ahn, William Shiao, Andrew Bauer, Arinda...  2023-05-31 04:54   \n",
       "24   Biqian Cheng, Evangelos Papalexakis and Jia Chen  2023-05-31 05:33   \n",
       "25  Ylli Sadikaj, Justus Rass, Yllka Velaj and Cla...  2023-05-31 06:47   \n",
       "26  Ylli Sadikaj, Yllka Velaj, Sahar Behzadi and C...  2023-05-31 06:54   \n",
       "27  Raika Karimi, Mahdi Biparva, Mohammad Ali Alom...  2023-05-31 11:26   \n",
       "28  Ahmad Naser Eddin, Jacopo Bono, David Aparício...  2023-05-31 11:58   \n",
       "\n",
       "        last updated  form fields  \\\n",
       "0   1970-01-01 00:00          NaN   \n",
       "1   1970-01-01 00:00          NaN   \n",
       "2   1970-01-01 00:00          NaN   \n",
       "3   2023-07-08 01:08          NaN   \n",
       "4   1970-01-01 00:00          NaN   \n",
       "5   1970-01-01 00:00          NaN   \n",
       "6   2023-07-13 21:12          NaN   \n",
       "7   2023-07-19 06:38          NaN   \n",
       "8   1970-01-01 00:00          NaN   \n",
       "9   1970-01-01 00:00          NaN   \n",
       "10  2023-05-31 03:20          NaN   \n",
       "11  2023-05-30 10:14          NaN   \n",
       "12  2023-05-31 18:23          NaN   \n",
       "13  1970-01-01 00:00          NaN   \n",
       "14  1970-01-01 00:00          NaN   \n",
       "15  2023-05-31 13:25          NaN   \n",
       "16  2023-05-31 16:03          NaN   \n",
       "17  1970-01-01 00:00          NaN   \n",
       "18  1970-01-01 00:00          NaN   \n",
       "19  1970-01-01 00:00          NaN   \n",
       "20  2023-05-31 16:01          NaN   \n",
       "21  1970-01-01 00:00          NaN   \n",
       "22  1970-01-01 00:00          NaN   \n",
       "23  1970-01-01 00:00          NaN   \n",
       "24  1970-01-01 00:00          NaN   \n",
       "25  1970-01-01 00:00          NaN   \n",
       "26  1970-01-01 00:00          NaN   \n",
       "27  1970-01-01 00:00          NaN   \n",
       "28  2023-08-02 16:14          NaN   \n",
       "\n",
       "                                             keywords decision notified  \\\n",
       "0   Gromov-Wasserstein Distance\\nOptimal Transport...   reject      yes   \n",
       "1   Sampling\\nGraph learning\\nLocality sensitive h...   accept      yes   \n",
       "2   Link Prediction\\nGraph Neural Network\\nOverfit...   accept      yes   \n",
       "3   Graph Neural Networks\\nHeterogeneous Relationa...   accept      yes   \n",
       "4                    GNN\\nGNNExplainer\\nVisualization   accept      yes   \n",
       "5   Online shopping\\nRecommendation\\nGraph Neural ...   accept      yes   \n",
       "6   Graph neural networks\\nEditable training\\nNode...   accept      yes   \n",
       "7   Graph algorithm\\nStochastic process\\nMachine l...   accept      yes   \n",
       "8   Graph Neural Networks\\nActive Learning\\nNoisy ...   accept      yes   \n",
       "9   taxonomy completion\\nmutual attention\\nconcept...   accept      yes   \n",
       "10  Imbalanced Graph\\nGraph Neural Network\\nGenera...   accept      yes   \n",
       "11          graph\\ngraph Computing System\\ncheckpoint   reject      yes   \n",
       "12  Topological Representation Learning\\nShopping ...   accept      yes   \n",
       "13  dynamic graphs\\ngraph neural networks\\nself-su...   accept      yes   \n",
       "14  graph neural networks\\ncontrastive learning\\nk...   accept      yes   \n",
       "15  Time Series\\nMulti-Horizon Forecasting\\nGraph ...   accept      yes   \n",
       "16  Hypergraph attention network\\nSequence learnin...   accept      yes   \n",
       "17  Graph Neural Networks\\nRelational Graph Attent...   reject      yes   \n",
       "18  Large Scale Dataset\\nGraphs\\nSynthetic Data\\nG...   accept      yes   \n",
       "19  graph generative models\\ngraph neural network\\...   accept      yes   \n",
       "20  Hypergraph Transformer Network\\nHypergraph Neu...   reject      yes   \n",
       "21  Fair Recommendations\\nOnline Dating Networks\\n...   accept      yes   \n",
       "22  information diffusion\\nsheaf Laplacian\\ninflue...   accept      yes   \n",
       "23  Tensor decomposition\\nMulti-modal tensor graph...   accept      yes   \n",
       "24  Canonical Correlation Analysis\\nAlignment\\nMat...   reject      yes   \n",
       "25  Network Embedding\\nMultiplex Networks\\nAttribu...   accept      yes   \n",
       "26  Graph embedding\\nSpectral clustering\\nMulti-re...   accept      yes   \n",
       "27  self-supervised learning\\ndynamic graphs\\ngrap...   reject      yes   \n",
       "28  Continuous-time dynamic graphs (CTDGs)\\nStream...   accept      yes   \n",
       "\n",
       "   reviews sent                                           abstract  \n",
       "0           yes  Network alignment is a commonly encountered pr...  \n",
       "1           yes  An important step in graph-based data analysis...  \n",
       "2           yes  Graph Neural Networks (GNNs) have demonstrated...  \n",
       "3           yes  The rise of online marketplaces has led to inc...  \n",
       "4           yes  Graph Neural Networks (GNNs) have gained popul...  \n",
       "5           yes  Substitute recommendation in e-commerce has at...  \n",
       "6           yes  Despite Graph Neural Networks (GNNs) have achi...  \n",
       "7           yes  A hypergraph is a generalization of a graph th...  \n",
       "8           yes  Graph Neural Networks (GNNs) have seen signifi...  \n",
       "9           yes  Taxonomies serve many applications with a stru...  \n",
       "10          yes  Classification in imbalanced data, where the m...  \n",
       "11          yes  Graph computing systems play a critical role i...  \n",
       "12          yes  Learning compact representation from customer ...  \n",
       "13          yes  Temporal graph neural networks have shown prom...  \n",
       "14          yes  Unsupervised node representations learnt using...  \n",
       "15          yes  Encoder-decoder deep neural networks have been...  \n",
       "16          yes  Extracting meaningful features from sequences ...  \n",
       "17          yes  E-commerce stores seek to provide a high-quali...  \n",
       "18          yes  Recently there has been increasing interest in...  \n",
       "19          yes  Deep learning on graphs has gained interest in...  \n",
       "20          yes  In recent years, hypergraphs have attracted co...  \n",
       "21          yes  Novel research paper:\\r\\nOnline dating platfor...  \n",
       "22          yes  In the contemporary era of social media and on...  \n",
       "23          yes  Online news articles encompass a variety of mo...  \n",
       "24          yes  Canonical Correlation Analysis (CCA) has been ...  \n",
       "25          yes  Complex information can be represented as netw...  \n",
       "26          yes  Graph clustering aims at discovering a natural...  \n",
       "27          yes  Recently, Self-Supervised Learning (SSL) has d...  \n",
       "28          yes  Many real-world datasets have an underlying dy...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "score_ranking = [9,3,10,15,17,29,4,7,13,16,22,24,27,2,6,14,19,11,23,26,20,5,8]\n",
    "print(len(score_ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "submission_df = submission_df[submission_df.decision == 'accept']\n",
    "print(len(submission_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"large text-muted\">\n",
      "<strong>Active Learning for Graphs with Noisy Structures</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid9\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib9\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_9.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Hongliang Chi, Cong Qi, Suhang Wang and Yao Ma</i><br/>\n",
      "\n",
      "<div id=\"pid9\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Graph Neural Networks (GNNs) have seen significant success in tasks like node classification, primarily dependent on the availability of abundant labeled nodes. However, the excessive cost of labeling large-scale graphs led to a focus on active learning methods on graphs, which aim for efficient data selection. While most methods assume reliable graph topology, real-world scenarios often present noisy graphs.  Designing an active learning framework for noisy graphs is challenging, as selecting data for labeling and obtaining a clean graph are naturally interdependent: selecting high-quality data requires clean graph structure while cleaning noisy graph structure needs adequate labeled data. Considering the challenge mentioned above, we propose a robust active learning framework named GALClean that adopts an iterative approach to achieve data selection and graph purification simultaneously. Furthermore, we summarize GALClean as an instance of the Expectation-Maximization (EM) algorithm, which provides a theoretical understanding of the design and mechanisms in GALClean. Extensive experiments have demonstrated the effectiveness and robustness of our proposed method.\n",
      "<br/><br/><strong>Keywords:</strong> Graph Neural Networks, Active Learning, Noisy Learning\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib9\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_9,<br/>\n",
      "title={Active Learning for Graphs with Noisy Structures},<br/>\n",
      "author={Hongliang Chi, Cong Qi, Suhang Wang and Yao Ma},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in GNNs</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid3\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib3\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_3.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Jing Zhu, Yuhang Zhou, Vassilis Ioannidis, Shengyi Qian, Wei Ai, Xiang Song and Danai Koutra</i><br/>\n",
      "\n",
      "<div id=\"pid3\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Graph Neural Networks (GNNs) have demonstrated promising outcomes across various tasks, including node classification and link prediction. However, despite their remarkable success in various high-impact applications, we have identified three common pitfalls in message passing for link prediction, especially within industrial settings. Particularly, in prevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges (i.e., the edges being predicted) consistently exist as message passing edges in the graph during training. Consequently, this results in overfitting and distribution shift, both of which adversely impact the generalizability to test the target edges. Additionally, during test time, the failure to exclude the test target edges leads to implicit test leakage caused by neighborhood aggregation. In this paper, we analyze these three pitfalls and investigate the impact of including or excluding target edges on the performance of nodes with varying degrees during training and test phases. Our theoretical and empirical analysis demonstrates that low-degree nodes are more susceptible to these pitfalls. These pitfalls can have detrimental consequences when GNNs are implemented in production systems. To systematically address these pitfalls, we propose SppotTarget, an effective and efficient GNN training framework. During training, SpotTarget leverages our insight regarding low-degree nodes and excludes train target edges connected to at least one low-degree node. During test time, it emulates real-world scenarios of GNN usage in production and excludes all test target edges. Our experiments conducted on diverse real-world datasets, including e-commerce graphs, demonstrate that SpotTarget significantly enhances GNNs, achieving up to a 15 times increase in accuracy in sparse graphs. Furthermore, SpotTarget consistently and dramatically improves the performance of GNN models for low-degree nodes in dense graphs.\n",
      "<br/><br/><strong>Keywords:</strong> Link Prediction, Graph Neural Network, Overfitting, Distribution Shift, Data Leakage\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib3\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_3,<br/>\n",
      "title={SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in GNNs},<br/>\n",
      "author={Jing Zhu, Yuhang Zhou, Vassilis Ioannidis, Shengyi Qian, Wei Ai, Xiang Song and Danai Koutra},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Completing Taxonomies with Relation-Aware Mutual Attentions</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid10\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib10\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_10.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Qingkai Zeng, Zhihan Zhang, Jinfeng Lin and Meng Jiang</i><br/>\n",
      "\n",
      "<div id=\"pid10\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Taxonomies serve many applications with a structural representation of knowledge. To incorporate emerging concepts into existing taxonomies, the task of taxonomy completion aims to find suitable positions for emerging query concepts. Previous work captured homogeneous token-level interactions inside a concatenation of the query concept term and definition using pre-trained language models. However, they ignored the token-level interactions between the term and definition of the query concepts and their related concepts. In this work, we propose to capture heterogeneous token-level interactions between the different textual components of concepts that have different types of relations. We design a relation-aware mutual attention module (RAMA) to learn such interactions for taxonomy completion. Experimental results demonstrate that our new taxonomy completion framework based on RAMA achieves the state-of-the-art performance on six taxonomy datasets. This paper belongs to \"Application and analysis - Knowledge Graph Construction\", and in the \"Novel research paper\" category.\n",
      "<br/><br/><strong>Keywords:</strong> taxonomy completion, mutual attention, concept definition, heterogeneous interactions\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib10\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_10,<br/>\n",
      "title={Completing Taxonomies with Relation-Aware Mutual Attentions},<br/>\n",
      "author={Qingkai Zeng, Zhihan Zhang, Jinfeng Lin and Meng Jiang},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>FiGURe: Simple and Efficient Unsupervised Node Representations with Filter Augmentations</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid15\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib15\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_15.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Chanakya Ekbote, Ajinkya P. Deshpande, Arun Iyer, Ramakrishna Bairi and Sundararajan Sellamanickam</i><br/>\n",
      "\n",
      "<div id=\"pid15\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Unsupervised node representations learnt using contrastive learning-based methods have shown good performance on downstream tasks. However, these methods rely on augmentations that mimic low-pass filters, limiting their performance on tasks requiring different eigen-spectrum parts. This paper presents a simple filter-based augmentation method to capture different parts of the eigen-spectrum. We show significant improvements using these augmentations. Further, we show that sharing the same weights across these different filter augmentations is possible, reducing the computational load. In addition, previous works have shown that good performance on downstream tasks requires high dimensional representations. Working with high dimensions increases the computations, especially when multiple augmentations are involved. We mitigate this problem and recover good performance through lower dimensional embeddings using simple random Fourier feature projections. Our method, FiGURe, achieves an average gain of up to 4.4%, compared to the state-of-the-art unsupervised models, across all datasets in consideration, both homophilic and heterophilic.\n",
      "<br/><br/><strong>Keywords:</strong> graph neural networks, contrastive learning, kernel methods\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib15\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_15,<br/>\n",
      "title={FiGURe: Simple and Efficient Unsupervised Node Representations with Filter Augmentations},<br/>\n",
      "author={Chanakya Ekbote, Ajinkya P. Deshpande, Arun Iyer, Ramakrishna Bairi and Sundararajan Sellamanickam},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Seq-HyGAN: Sequence Classification via Hypergraph Attention Network</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid17\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib17\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_17.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Khaled Mohammed Saifuddin, Corey May, Farhan Tanvir, Muhammad Ifte Khairul Islam and Esra Akbas</i><br/>\n",
      "\n",
      "<div id=\"pid17\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Extracting meaningful features from sequences and devising effective similarity measures are vital for sequence data mining tasks, particularly sequence classification. While Neural Network models are commonly used to learn features of sequence automatically, they are limited to capturing adjacent structural connection information and ignore global, higher-order information between the sequences. To address these challenges, we propose a novel Hypergraph Attention Network model, namely Seq-HyGAN, for sequence classification problems. To capture the complex structural similarity between sequence data, we create a novel hypergraph model by defining higher-order relations between subsequences extracted from sequences. Subsequently, we introduce a Sequence Hypergraph Attention Network that learns sequence features by considering the significance of subsequences and sequences to one another. Through extensive experiments, we demonstrate the effectiveness of our proposed Seq-HyGAN model in accurately classifying sequence data, outperforming several state-of-the-art methods by a significant margin. This paper belongs to \"Algorithms and methods- Graph neural networks and graph representation learning\" and is in the \"Novel research papers\" category.\n",
      "<br/><br/><strong>Keywords:</strong> Hypergraph attention network, Sequence learning, Graph learning\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib17\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_17,<br/>\n",
      "title={Seq-HyGAN: Sequence Classification via Hypergraph Attention Network},<br/>\n",
      "author={Khaled Mohammed Saifuddin, Corey May, Farhan Tanvir, Muhammad Ifte Khairul Islam and Esra Akbas},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid29\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib29\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_29.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Ahmad Naser Eddin, Jacopo Bono, David Aparício, Hugo Ferreira, João Ascensão, Pedro Ribeiro and Pedro Bizarro</i><br/>\n",
      "\n",
      "<div id=\"pid29\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time. Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks.\n",
      "Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search. However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs. To overcome these limitations, we propose graph-sprints, a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models. To achieve this, a streaming, low latency approximation to the random-walk based features is proposed. In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop operations on the incoming edges. We evaluate our proposed approach on three open-source datasets and two in-house datasets, and compare with three state-of-the-art algorithms (TGN-attn, TGN-ID, Jodie). We demonstrate that our graph-sprints features, combined with a machine learning classifier, achieve competitive performance (outperforming all baselines for the node classification tasks in five datasets). Simultaneously, graph-sprints significantly reduce inference latencies, achieving up to 9 times faster inference in our experimental setting.\n",
      "<br/><br/><strong>Keywords:</strong> Continuous-time dynamic graphs (CTDGs), Streaming graphs, Graph representation learning, Graph feature engineering, Graph Neural Networks\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib29\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_29,<br/>\n",
      "title={From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs},<br/>\n",
      "author={Ahmad Naser Eddin, Jacopo Bono, David Aparício, Hugo Ferreira, João Ascensão, Pedro Ribeiro and Pedro Bizarro},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>A Heterogeneous Graph-based Framework for Scalable Fraud Detection</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid4\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib4\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_4.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Phanindra Reddy Madduru and Naveed Janvekar</i><br/>\n",
      "\n",
      "<div id=\"pid4\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> The rise of online marketplaces has led to increased concerns regarding the presence of bad actors involved in counterfeit or engage in fraudulent activities. While efforts are being made by organizations to monitor and address these issues, bad actors persistently find new ways to engage in fraudulent behavior, including creating new accounts using different credentials, account hijacking etc. To combat this issue, our study proposes the use of Heterogeneous Relational Graph Convolutional Networks (HRGCN) to identify risky relationships among entities like sellers or customers. By leveraging this advanced graph-based approach, we aim to enhance the detection and mitigation of fraudulent behavior on the e-commerce marketplaces. The HRGCN model is designed to detect sellers with risky associations with other known bad sellers by analyzing various connecting edges such as encrypted device and identity credentials. With the rapid growth of e-commerce stores, the number of sellers has witnessed an exponential increase, leading to a significant expansion in their social networks formed by sharing various relationships such as digital contact information, communication channels and devices. This has made it challenging to process the data with the direct implementation of HRGCN. This highlights the importance of model scalability in handling large datasets. To address this issue, we have introduced a novel mini-batch version of HRGCN variant that works in tandem with a neighborhood sampler, which is optimized to run on GPUs, significantly reducing the training time by 70%. This mini-batch version of HRGCN maintains and/or improves the performance of the model while addressing the scalability issue, making it an efficient solution for handling large datasets. In this paper, we compare the performance of three models: a benchmark model based on Random Forest trained on seller node features alone, HRGCN trained on Full batch, and HRGCN with mini-batch implementation. The findings of our experiments reveal that the HRGCN models outperform the benchmark model with a significant improvement in both F1-score and Recall. Specifically, the HRGCN models show an impressive increase in recall by approximately 115% compared to the baseline model. Moreover, the mini-batch HRGCN model demonstrated substantial improvement in performance over the full batch HRGCN model, achieving a 16% higher F1 score and an 8% higher PR AUC score. These results emphasize the effectiveness of using a mini-batch approach to handle large datasets and detecting related bad sellers.\n",
      "<br/><br/><strong>Keywords:</strong> Graph Neural Networks, Heterogeneous Relational Graph Convolution Networks, Neural Networks, Fraud Detection, Mini-batch, Fraudulent behavior, Risky relationships, E-commerce marketplaces, Model Scalability, Large datasets\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib4\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_4,<br/>\n",
      "title={A Heterogeneous Graph-based Framework for Scalable Fraud Detection},<br/>\n",
      "author={Phanindra Reddy Madduru and Naveed Janvekar},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Editable Graph Neural Network for Node Classifications</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid7\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib7\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_7.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Zirui Liu, Zhimeng Jiang, Shaochen Zhong, Kaixiong Zhou, Li Li, Rui Chen, Soo-Hyun Choi and Xia Hu</i><br/>\n",
      "\n",
      "<div id=\"pid7\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Despite Graph Neural Networks (GNNs) have achieved prominent success in many graph-based learning problems, such as credit risk assessment in financial networks and fake news detection in social networks. However, the trained GNNs still make errors and these errors may cause serious negative impact on society. \\textit{Model editing}, which corrects the model behavior on wrongly predicted target samples while leaving model predictions unchanged on unrelated samples, has garnered significant interest in the fields of computer vision and natural language processing. However, model editing for graph neural networks (GNNs) is rarely explored, despite GNNs' widespread applicability. \n",
      "To fill the gap, we first observe that existing model editing methods significantly deteriorate prediction accuracy (up to $50\\%$ accuracy drop) in GNNs while a slight accuracy drop in multi-layer perception (MLP). The rationale behind this observation is that the node aggregation in GNNs will spread the editing effect throughout the whole graph. This propagation pushes the node representation far from its original one.\n",
      "Motivated by this observation, we propose \\underline{E}ditable \\underline{G}raph \\underline{N}eural \\underline{N}etworks (EGNN), a neighbor propagation-free approach to correct the model prediction on misclassified nodes. Specifically, EGNN simply stitches an MLP to the underlying GNNs, where the weights of GNNs are frozen during model editing. In this way, EGNN disables the propagation during editing while still utilizing the neighbor propagation scheme for node prediction to obtain satisfactory results. \n",
      "Experiments demonstrate that EGNN outperforms existing baselines in terms of effectiveness (correcting wrong predictions with lower accuracy drop), generalizability (correcting wrong predictions for other similar nodes), and efficiency (low training time and memory) on various graph datasets.\n",
      "<br/><br/><strong>Keywords:</strong> Graph neural networks, Editable training, Node Classification\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib7\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_7,<br/>\n",
      "title={Editable Graph Neural Network for Node Classifications},<br/>\n",
      "author={Zirui Liu, Zhimeng Jiang, Shaochen Zhong, Kaixiong Zhou, Li Li, Rui Chen, Soo-Hyun Choi and Xia Hu},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Topological Representation Learning for E-commerce Shopping Behaviors</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid13\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib13\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_13.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Yankai Chen, Quoc-Tuan Truong, Xin Shen, Ming Wang, Jin Li, Jim Chan and Irwin King</i><br/>\n",
      "\n",
      "<div id=\"pid13\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Learning compact representation from customer shopping behaviors is at the core of web-scale E-commerce recommender systems. At Amazon, we put great efforts into learning embedding of customer engagements in order to fuel multiple downstream tasks for better recommendation services. In this work, we define the notion of shopping trajectory that consists of customer interactions at the categorical level of products, then construct an end-to-end model namely C-STAR which is capable of learning rich embedding for representing the variable-length customer trajectory. C-STAR explicitly captures the inter-trajectory distribution similarity and intra-trajectory semantic correlation, providing a coarse-to-fine trajectory representation learning paradigm both structurally and semantically. We evaluate the model on Amazon proprietary data as well as four public datasets, where the learned embeddings have shown to be effective for customer-centric tasks including customer segmentation and shopping trajectory completion. These tasks empower multiple personalized shopping experiences for our customers. This paper belongs to \"Application and analysis: Large-scale analysis and modeling\", and in the “Novel research papers” category.\n",
      "<br/><br/><strong>Keywords:</strong> Topological Representation Learning, Shopping Trajectory, Amazon Recommendation\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib13\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_13,<br/>\n",
      "title={Topological Representation Learning for E-commerce Shopping Behaviors},<br/>\n",
      "author={Yankai Chen, Quoc-Tuan Truong, Xin Shen, Ming Wang, Jin Li, Jim Chan and Irwin King},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid16\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib16\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_16.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Sitan Yang, Malcolm Wolff, Shankar Ramasubramanian, Ronak Mehta and Michael Mahoney</i><br/>\n",
      "\n",
      "<div id=\"pid16\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Encoder-decoder deep neural networks have been increasingly studied for multi-horizon time series forecasting especially in real-world applications. However, these sophisticated neural forecasters typically rely on a large number of time series examples with substantial history to forecast accurately. A rapidly growing topic of interest is forecasting time series which lack sufficient historical data---often referred to as the ``cold start'' problem. In this paper, we introduce a novel yet simple method to address this problem by leveraging graph neural networks (GNNs) as a data augmentation for enhancing the encoder used by such forecasters. These GNN-based features can capture complex inter-series relationships and their generation process is optimized end-to-end with the forecasting task. We show that our architecture can use either data-driven or domain knowledge defined graphs, scaling to jointly incorporate information from multiple very large graphs with millions of nodes. In our target application of demand forecasting for a large e-commerce retailer, we demonstrate on both a small dataset of 100K products and a large dataset with over 2 million products that our method improves overall performance over competitive baseline models. More importantly, we show that it brings substantially more gains to ``cold start'' products such as those newly launched or recently out-of-stock.\n",
      "<br/><br/><strong>Keywords:</strong> Time Series, Multi-Horizon Forecasting, Graph Neural Networks, Data Augmentation\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib16\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_16,<br/>\n",
      "title={GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting},<br/>\n",
      "author={Sitan Yang, Malcolm Wolff, Shankar Ramasubramanian, Ronak Mehta and Michael Mahoney},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Fair Online Dating Recommendations for Sexually Fluid Users via Leveraging Opposite Gender Interaction Ratio</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid22\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib22\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_22.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Yuying Zhao, Yu Wang, Yi Zhang, Pamela Wisniewski, Charu Aggarwal and Tyler Derr</i><br/>\n",
      "\n",
      "<div id=\"pid22\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Novel research paper:\n",
      "Online dating platforms have gained widespread popularity as a means for individuals to seek potential romantic relationships. While recommender systems have been designed to improve the user experience in dating platforms by providing personalized recommendations, increasing concerns about fairness have encouraged the development of fairness-aware recommender systems from various perspectives (e.g., gender and race). However, sexual orientation, which plays a significant role in finding a satisfying relationship, is under-investigated. To fill this crucial gap, we propose a novel metric, Opposite Gender Interaction Ratio (OGIR), as a way to investigate potential unfairness for users with varying/fluid preferences towards the opposite gender. We empirically analyze a real online dating dataset and observe existing recommender algorithms could suffer from group unfairness according to OGIR. We further investigate the potential causes for such gaps in recommendation quality, which lead to the challenges of group data imbalance and group calibration imbalance. Ultimately, we propose a fair recommender system based on re-weighting and re-ranking strategies to respectively mitigate these associated imbalance challenges. Experimental results demonstrate both strategies improve fairness while their combination achieves the best performance towards maintaining model utility while improving fairness.\n",
      "<br/><br/><strong>Keywords:</strong> Fair Recommendations, Online Dating Networks, Social Network Analysis\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib22\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_22,<br/>\n",
      "title={Fair Online Dating Recommendations for Sexually Fluid Users via Leveraging Opposite Gender Interaction Ratio},<br/>\n",
      "author={Yuying Zhao, Yu Wang, Yi Zhang, Pamela Wisniewski, Charu Aggarwal and Tyler Derr},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Compact Interpretable Tensor Graph Multi-Modal News  Embeddings</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid24\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib24\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_24.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Dawon Ahn, William Shiao, Andrew Bauer, Arindam Khaled, Stefanos Poulis and Evangelos Papalexakis</i><br/>\n",
      "\n",
      "<div id=\"pid24\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Online news articles encompass a variety of modalities such as text and images. How can we learn a representation that incorporates information from all those modalities in a compact and interpretable manner, while also being useful in a variety of downstream tasks? Recent advances in Large Language and Vision Models have made it possible to represent image and text data as embeddings, which can then be used to perform downstream tasks. Despite these developments, these embedding models tend to generate high-dimensional embeddings, making them problematic in terms of compactness and interpretability. \n",
      "\n",
      "In this paper, we propose CITEM (Compact Interpretable Tensor graph multi-modal news EMbedding), which is a novel framework for multi-modal news representations via tensor decomposition in a compact and interpretable way. CITEM generates a tensor graph consisting of a news similarity graph for each modality and employs a tensor decomposition to produce compact and interpretable embeddings, each dimension of which is a heterogeneous co-cluster of news articles and corresponding modalities. Interpretability and compactness are key, since our proposed embeddings contain few dimensions which lend themselves to inspection and explanation. Traditional tensor analysis has so far been restricted to transductive learning scenarios (e.g., in the form of semi-supervised learning), but CITEM includes two variants for inductive learning, which essentially enables us to represent unseen news articles. We extensively validate CITEM compared to baselines on two news classification tasks: misinformation news detection and news categorization. The experimental results show that CITEM performs within the same range of AUC as state-of-the-art baselines while producing 7× to 10.5× more compact embeddings. In addition, each embedding dimension of CITEM is interpretable, representing a latent co-cluster of articles.\n",
      "<br/><br/><strong>Keywords:</strong> Tensor decomposition, Multi-modal tensor graph, Interpretable news embeddings\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib24\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_24,<br/>\n",
      "title={Compact Interpretable Tensor Graph Multi-Modal News  Embeddings},<br/>\n",
      "author={Dawon Ahn, William Shiao, Andrew Bauer, Arindam Khaled, Stefanos Poulis and Evangelos Papalexakis},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Spectral Clustering of Attributed Multi-relational Graphs*</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid27\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib27\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_27.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Ylli Sadikaj, Yllka Velaj, Sahar Behzadi and Claudia Plant</i><br/>\n",
      "\n",
      "<div id=\"pid27\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Graph clustering aims at discovering a natural grouping of the nodes such that similar nodes are assigned to a common cluster. Many different algorithms have been proposed in the literature: for simple graphs, for graphs with attributes associated to nodes, and for graphs where edges represent different types of relations among nodes. However, complex data in many domains can be represented as both attributed and multi-relational networks.\n",
      "In this paper, we propose SpectralMix, a joint dimensionality reduction technique for multi-relational graphs with categorical node attributes. SpectralMix integrates all information available from the attributes, the different types of relations, and the graph structure to enable a sound interpretation of the clustering results. Moreover, it generalizes existing techniques: it reduces to spectral embedding and clustering when only applied to a single graph and to homogeneity analysis when applied to categorical data. \n",
      "Experiments conducted on several real-world datasets enable us to detect dependencies between graph structure and categorical attributes, moreover, they exhibit the superiority of SpectralMix over existing methods.\n",
      "The full version of this paper has also appeared in the Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery\n",
      "Data Mining, KDD’21, and received the Student Best Paper Award.\n",
      "\n",
      "∗This paper won the Student Best Paper Award at KDD ’21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery Data Mining, August 2021, Pages 1431–1440, https://doi.org/10.1145/3447548.34673\n",
      "<br/><br/><strong>Keywords:</strong> Graph embedding, Spectral clustering, Multi-relational graphs, Attributed graphs\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib27\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_27,<br/>\n",
      "title={Spectral Clustering of Attributed Multi-relational Graphs*},<br/>\n",
      "author={Ylli Sadikaj, Yllka Velaj, Sahar Behzadi and Claudia Plant},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Data Sampling using Locality Sensitive Hashing for Large Scale Graph Learning</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid2\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib2\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_2.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Sarath Shekkizhar, Neslihan Bulut, Mohamed Farghal, Sasan Tavakkol, Mohammadhossein Bateni and Animesh Nandi</i><br/>\n",
      "\n",
      "<div id=\"pid2\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> An important step in graph-based data analysis and processing is the construction of similarity graphs. Recent works, such as [7, 23 ], have focused on the semi-supervised setting to learn an optimal similarity function for constructing a task-optimal graph. However, in many scenarios with billions of data points and trillions of potential edges, the run-time and computational requirements for training the similarity model make these approaches impractical. In this work, we consider data sampling as a means to overcome this issue. Unlike typical sampling use-cases which only seek diversity, the similarity-learning for graph construction problem requires data samples that are both diverse and representative of highly similar data points. We present an efficient sampling approach by taking an adaptive partition view of locality sensitive hashing. Theoretically, we show that, though the samples obtained are correlated with sampling probabilities that do not sum to one, the training loss estimated for learning the graph similarity model using our approach is unbiased with a smaller variance compared to random sampling. Experiments on public datasets demonstrate the superior generalization of similarity models learned via our sampling. In a real large-scale industrial abuse-detection example, we observe ≈10× increase in identifying abusive items while having a lower false positive rate compared to the baseline.\n",
      "<br/><br/><strong>Keywords:</strong> Sampling, Graph learning, Locality sensitive hashing\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib2\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_2,<br/>\n",
      "title={Data Sampling using Locality Sensitive Hashing for Large Scale Graph Learning},<br/>\n",
      "author={Sarath Shekkizhar, Neslihan Bulut, Mohamed Farghal, Sasan Tavakkol, Mohammadhossein Bateni and Animesh Nandi},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Multi-Task Learning on Heterogeneous Graph Neural Network for Substitute Recommendation</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid6\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib6\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_6.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Tianchen Zhou, Michinari Momma, Chaosheng Dong, Fan Yang, Chenghuan Guo, Jin Shang and Jia Liu</i><br/>\n",
      "\n",
      "<div id=\"pid6\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Substitute recommendation in e-commerce has attracted increasing \n",
      "attention in recent years, to help improve customer experience. In \n",
      "this work, we propose a multi-task graph learning framework that \n",
      "jointly learns from supervised and unsupervised objectives with \n",
      "heterogeneous graphs. Particularly, we propose a new contrastive \n",
      "method that extracts global information from both positive and \n",
      "negative neighbors. By feeding substitute signal data from different \n",
      "sources to learning tasks with different focuses, our model learns \n",
      "the representation of products that can be applied for substitute \n",
      "identification under different substitutable criteria. We conduct ex- \n",
      "periments on Amazon datasets, and the experiment results demon- \n",
      "strate that our method outperforms all existing baselines in terms \n",
      "of comprehensive performance among all metrics of interest.\n",
      "<br/><br/><strong>Keywords:</strong> Online shopping, Recommendation, Graph Neural Network\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib6\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_6,<br/>\n",
      "title={Multi-Task Learning on Heterogeneous Graph Neural Network for Substitute Recommendation},<br/>\n",
      "author={Tianchen Zhou, Michinari Momma, Chaosheng Dong, Fan Yang, Chenghuan Guo, Jin Shang and Jia Liu},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>DyG2Vec: Representation Learning for Dynamic Graphs with Self-Supervision</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid14\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib14\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_14.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Mohammad Ali Alomrani, Mahdi Biparva, Yingxue Zhang and Mark Coates</i><br/>\n",
      "\n",
      "<div id=\"pid14\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Temporal graph neural networks have shown promising results in learning inductive representations by automatically extracting temporal patterns. However, previous works often rely on complex memory modules or inefficient random walk methods to construct temporal representations. In addition, the existing dynamic graph encoders are non-trivial to adapt to self-supervised paradigms, which prevents them from utilizing unlabeled data. To address these limitations, we present an efficient yet effective attention-based encoder that leverages temporal edge encodings and window-based subgraph sampling to generate task-agnostic embeddings. Moreover, we propose a joint-embedding architecture using non-contrastive SSL to learn rich temporal embeddings without labels. Experimental results on 7 benchmark datasets indicate that on average, our model outperforms SoTA baselines on the future link prediction task by 4.23% for the transductive setting and 3.30% for the inductive setting while only requiring 5-10x less training/inference time. Additionally, we empirically validate the SSL pre-training significance under two probings commonly used in language and vision modalities. Lastly, different aspects of the proposed framework are investigated through experimental analysis and ablation studies.\n",
      "<br/><br/><strong>Keywords:</strong> dynamic graphs, graph neural networks, self-supervised learning\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib14\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_14,<br/>\n",
      "title={DyG2Vec: Representation Learning for Dynamic Graphs with Self-Supervision},<br/>\n",
      "author={Mohammad Ali Alomrani, Mahdi Biparva, Yingxue Zhang and Mark Coates},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>A Large Scale Synthetic Graph Dataset Generation Framework</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid19\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib19\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_19.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Sajad Darabi, Piotr Bigaj, Dawid Majchrowski, Artur Kasymov, Pawel Morkisz and Alex Fit-Florea</i><br/>\n",
      "\n",
      "<div id=\"pid19\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Recently there has been increasing interest in developing and deploying deep graph learning algorithms for many graph analysis tasks such as node and edge classification, link prediction, and clustering with numerous practical applications such as fraud detection, drug discovery, or recommender systems. Albeit there is a limited number of publicly available graph-structured datasets, most of which are tiny compared to production-sized applications with trillions of edges and billions of nodes or are limited in their application domain.\n",
      "In this work, we tackle this shortcoming by proposing a scalable synthetic graph generation tool. This tool can be used to learn a set of parametric models from proprietary datasets that can subsequently be released to researchers to study various graph methods on the synthetic data increasing prototype development and novel applications. Finally, the performance of the graph learning algorithms depends not only on the size but also on the graph datasets structure. We show how our framework generalizes across a set of datasets, mimicking both structural and feature distributions and the ability to scale them across varying dataset sizes. Code can be found at \\href{https://github.com/}{https://github.com}\n",
      "<br/><br/><strong>Keywords:</strong> Large Scale Dataset, Graphs, Synthetic Data, Generative Modeling\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib19\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_19,<br/>\n",
      "title={A Large Scale Synthetic Graph Dataset Generation Framework},<br/>\n",
      "author={Sajad Darabi, Piotr Bigaj, Dawid Majchrowski, Artur Kasymov, Pawel Morkisz and Alex Fit-Florea},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>GraphBoost: Adaptive Boosting Node Generation for Class-Imbalanced Graphs</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid11\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib11\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_11.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Yuhe Gao, Sheng Zhang and Rui Song</i><br/>\n",
      "\n",
      "<div id=\"pid11\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Classification in imbalanced data, where the majority class has a much larger representation than the minority class, has been a significant topic in recent decades.  Two popular approaches for handling this issue are (1) rebalancing the sizes of classes through reweighting, resampling, or synthetic nodes generating, and (2) focusing on the data points that are hard to classify to enhance the classifier performance. In graphical data, several methods, such as GraphSMOTE and GraphENS, from the first type have been developed recently for class-imbalanced node classification tasks, but few adaptations of the second approach have been proposed. In response to this gap , we present a novel multi-stage boosting framework inspired by the second approach. In particular, the framework proposed in this research paper jointly generates the topological structure and features of synthetic nodes by minimizing the distance of synthetic nodes and misclassified nodes from previous training stages.  Our experiments on class-imbalanced graphs show that our novel framework outperforms standard graph neural networks. Furthermore, our framework can be combined with existing methods (such as GraphENS) resulting in further performance enhancements.\n",
      "<br/><br/><strong>Keywords:</strong> Imbalanced Graph, Graph Neural Network, Generative Model, Node Classification\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib11\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_11,<br/>\n",
      "title={GraphBoost: Adaptive Boosting Node Generation for Class-Imbalanced Graphs},<br/>\n",
      "author={Yuhe Gao, Sheng Zhang and Rui Song},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Effect of Deception in Influence Maximization and Polarization on Social Networks: A Sheaf Laplacian Approach</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid23\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib23\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_23.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Mehmet Aktas, Esra Akbas, Ashley Hahn and Mehmet Ahsen</i><br/>\n",
      "\n",
      "<div id=\"pid23\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> In the contemporary era of social media and online communication, comprehending the dynamics of information diffusion in social networks has become crucial. This research article investigates the effects of deception on information diffusion, specifically focusing on influence maximization and polarization in social networks. We propose an analytic model of deception within social networks. Building upon the sheaf Laplacian diffusion model derived from algebraic topology, we examine opinion dynamics in the presence of deception. Next, we redefine the Laplacian centrality, an influential node detection method originally designed for regular graphs, to quantify the influence of deception in influence maximization using the sheaf Laplacian. Additionally, we employ the sheaf Laplacian to model polarization in networks and investigate the impact of deception on polarization using two distinct polarization measures. Through extensive experiments conducted on synthetic and real-world networks, our findings suggest that deceptive individuals wield more influence than honest users within social networks. Furthermore, we demonstrate that deception amplifies polarization in networks, with influential individuals playing a significant role in deepening the polarization phenomenon.\n",
      "<br/><br/><strong>Keywords:</strong> information diffusion, sheaf Laplacian, influence maximization, polarization, deception\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib23\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_23,<br/>\n",
      "title={Effect of Deception in Influence Maximization and Polarization on Social Networks: A Sheaf Laplacian Approach},<br/>\n",
      "author={Mehmet Aktas, Esra Akbas, Ashley Hahn and Mehmet Ahsen},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Semi-Supervised Embedding of Attributed Multiplex Networks*</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid26\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib26\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_26.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Ylli Sadikaj, Justus Rass, Yllka Velaj and Claudia Plant</i><br/>\n",
      "\n",
      "<div id=\"pid26\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Complex information can be represented as networks (graphs) characterized by a large number of nodes, multiple types of nodes, and multiple types of relationships between them, i.e. multiplex networks. Additionally, these networks are enriched with different types of node features.\n",
      "We propose a Semi-supervised Embedding approach for Attributed Multiplex Networks (SSAMN), to jointly embed nodes, node attributes, and node labels of multiplex networks in a low dimensional space. Network embedding techniques have garnered research attention for real-world applications. However, most existing techniques solely focus on learning the node embeddings, and only a few learn class label embeddings. Our method assumes that we have different classes of nodes and that we know the class label of some, very few nodes for every class. Guided by this type of supervision, SSAMN learns a low-dimensional representation incorporating all information in a large labeled multiplex network. SSAMN integrates techniques from Spectral Embedding and Homogeneity Analysis to improve the embedding of nodes, node attributes, and node labels. Our experiments demonstrate that we only need very few labels per class in order to have a final embedding that preserves the information of the graph. To evaluate the performance of SSAMN, we run experiments on four real-world datasets. The results show that our approach outperforms state-of-the-art methods for downstream tasks such as semi-supervised node classification and node\n",
      "clustering.\n",
      "This paper has also appeared in the Proceedings of the ACM\n",
      "Web Conference 2023, former WWW.\n",
      "\n",
      "∗This paper has appeared in WWW ’23: Proceedings of the ACM Web Conference\n",
      "2023, April 2023, Pages 578–587, https://doi.org/10.1145/3543507.3583\n",
      "<br/><br/><strong>Keywords:</strong> Network Embedding, Multiplex Networks, Attributed Networks\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib26\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_26,<br/>\n",
      "title={Semi-Supervised Embedding of Attributed Multiplex Networks*},<br/>\n",
      "author={Ylli Sadikaj, Justus Rass, Yllka Velaj and Claudia Plant},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>UGGS: A Unified Graph Generation Framework Based on Self-Supervised Learning</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid20\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib20\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_20.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Sajad Ramezani and Soroor Motie</i><br/>\n",
      "\n",
      "<div id=\"pid20\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Deep learning on graphs has gained interest in recent years. The applicability of graphs to model problems in various domains, such as chemical molecules, financial transactions, parse trees, etc., has encouraged researchers to develop and extend machine learning methods from other data modalities, such as text and image, to graphs. Generative models have been used extensively in recent years and have achieved significant milestones, especially in text and image generation. However, graph generative models have not been developed as extensively, and fundamental problems are still in the discussion phase. This work addresses some of these problems, such as the lack of an integrated framework and interpretable evaluation metric, by introducing a unified framework for the graph generation task. The base of the proposed framework is on the appropriate graph and node embeddings to estimate graphs' distribution. Hence it composes of graph neural networks to embed the nodes and graphs and also enhances the quality of graph embeddings via the introduction of pseudo tasks in a self-supervised fashion. Self-supervised techniques have proven useful in enhancing generative models to be more robust and generalizable. This work proposes several pseudo tasks and evaluates their performance on common graph datasets. It also emphasizes the problem of graph decoding and speculates that graph generation strategy matters, and one can establish more complex graph generation models to generate higher-quality graphs. It also proposes a distance metric in embedding space for generated graphs to filter out poorly generated data. In the end, the proposed framework achieves competitive results compared to previously proposed models while having fewer parameters and a shorter training time. We have also made our framework implementation available.\n",
      "\n",
      "<br/><br/><strong>Keywords:</strong> graph generative models, graph neural network, self-supervised learning, generative models, machine learning on graphs\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib20\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_20,<br/>\n",
      "title={UGGS: A Unified Graph Generation Framework Based on Self-Supervised Learning},<br/>\n",
      "author={Sajad Ramezani and Soroor Motie},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Graph Model Explainer Tool</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid5\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib5\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_5.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Yudi Zhang, Phanindra Reddy Madduru, Naveed Janvekar and Nitika Bhaskar</i><br/>\n",
      "\n",
      "<div id=\"pid5\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> Graph Neural Networks (GNNs) have gained popularity in various fields, such as recommendation systems, social network analysis and fraud detection. However, despite their effectiveness, the topological nature of GNNs makes it challenging for users to understand the model predictions. To address this challenge, we built a user-friendly UI to visualize the most important relationships for both homogeneous and heterogeneous static graphs models, which a post-hoc explanation technique called GNNExplainer is implemented. This UI can be applied to a wide range of applications that use graph models. It offers an intuitive and interpretable way for users to understand the complex relationships within a graph and how they influence the model's predictions.\n",
      "<br/><br/><strong>Keywords:</strong> GNN, GNNExplainer, Visualization\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib5\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_5,<br/>\n",
      "title={Graph Model Explainer Tool},<br/>\n",
      "author={Yudi Zhang, Phanindra Reddy Madduru, Naveed Janvekar and Nitika Bhaskar},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n",
      "<p class=\"large text-muted\">\n",
      "<strong>Computation of Node Distances on Hypergraphs</strong> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid8\">Abstract</button> \n",
      "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib8\">BibTex</button> \n",
      "<a href=\"papers/MLG__KDD_2023_paper_8.pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
      "<br/>\n",
      "<i>Enzhi Li and Bilal Fadlallah</i><br/>\n",
      "\n",
      "<div id=\"pid8\" class=\"collapse\">\n",
      "<strong>Abstract:</strong> A hypergraph is a generalization of a graph that arises naturally when we consider attribute-sharing among entities. Although a hypergraph can be converted into a graph by expanding its hyperedges into fully connected subgraphs, going the reverse way is computationally complex and NP-complete. We hence hypothesize that a hypergraph contains more information than a graph. Moreover, it is more convenient to manipulate a hypergraph directly, rather than expanding it into a graph. An open problem in hypergraphs is how to accurately and efficiently calculate their node distances. Once node distances are defined, we can find a node's nearest neighbors, and perform label propagation on hypergraphs using a K-nearest neighbors (KNN) approach. In this paper, we propose two methods to achieve this. In the first, we compute expected hitting times of random walks on a hypergraph as node distances; in the second, we generalize the DeepWalk method to hypergraphs. We note that simple random walks (SRW) cannot accurately describe highly complex real-world hypergraphs, which motivates us to introduce frustrated random walks (FRW) to better describe them. Using real-world datasets, we show that FRW and DeepWalk can beat SRW with a large margin. For large and sparse hypergraphs, our method for computing the expected hitting times of random walks is approximately linear in time complexity, rendering it superior to the DeepWalk method.\n",
      "<br/><br/><strong>Keywords:</strong> Graph algorithm, Stochastic process, Machine learning algorithm, Applied mathematics, KNN algorithm\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "<div id=\"bib8\" class=\"collapse\">\n",
      "@inproceedings{mlg2023_8,<br/>\n",
      "title={Computation of Node Distances on Hypergraphs},<br/>\n",
      "author={Enzhi Li and Bilal Fadlallah},<br/>\n",
      "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
      "year={2023}<br/>\n",
      "}\n",
      "<hr/>\n",
      "</div>\n",
      "\n",
      "</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# update the workshop information\n",
    "\n",
    "for pid in score_ranking:\n",
    "    title = submission_df[submission_df['#'] == pid]['title'].iloc[0]\n",
    "    authors = submission_df[submission_df['#'] == pid]['authors'].iloc[0]\n",
    "    abstract = submission_df[submission_df['#'] == pid]['abstract'].iloc[0]    \n",
    "    keywords = submission_df[submission_df['#'] == pid]['keywords'].iloc[0].replace('\\n',', ')    \n",
    "\n",
    "    print(\"\"\"<p class=\"large text-muted\">\n",
    "<strong>\"\"\"+title+\"\"\"</strong> \n",
    "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#pid\"\"\"+str(pid)+\"\"\"\">Abstract</button> \n",
    "<button class=\"btn btn-primary btn-xs\" data-toggle=\"collapse\" data-target=\"#bib\"\"\"+str(pid)+\"\"\"\">BibTex</button> \n",
    "<a href=\"papers/MLG__KDD_2023_paper_\"\"\"+str(pid)+\"\"\".pdf\" target=_blank class=\"btn btn-primary btn-xs\" role=\"button\">PDF</a> \n",
    "<br/>\n",
    "<i>\"\"\"+authors+\"\"\"</i><br/>\n",
    "\n",
    "<div id=\"pid\"\"\"+str(pid)+\"\"\"\" class=\"collapse\">\n",
    "<strong>Abstract:</strong> \"\"\"+abstract+\"\"\"\n",
    "<br/><br/><strong>Keywords:</strong> \"\"\"+keywords+\"\"\"\n",
    "<hr/>\n",
    "</div>\n",
    "\n",
    "<div id=\"bib\"\"\"+str(pid)+\"\"\"\" class=\"collapse\">\n",
    "@inproceedings{mlg2023_\"\"\"+str(pid)+\"\"\",<br/>\n",
    "title={\"\"\"+title+\"\"\"},<br/>\n",
    "author={\"\"\"+authors+\"\"\"},<br/>\n",
    "booktitle={Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG)},<br/>\n",
    "year={2023}<br/>\n",
    "}\n",
    "<hr/>\n",
    "</div>\n",
    "\n",
    "</p>\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
